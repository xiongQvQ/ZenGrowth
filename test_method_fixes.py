#!/usr/bin/env python3
"""
æµ‹è¯•æ–¹æ³•ä¿®å¤
"""

import pandas as pd
from pathlib import Path
from tools.ga4_data_parser import GA4DataParser
from tools.data_storage_manager import DataStorageManager
from engines.event_analysis_engine import EventAnalysisEngine
from engines.retention_analysis_engine import RetentionAnalysisEngine

def test_method_fixes():
    """æµ‹è¯•æ–¹æ³•ä¿®å¤"""
    try:
        print("ğŸ§ª æµ‹è¯•æ–¹æ³•ä¿®å¤...")
        
        # 1. å‡†å¤‡æ•°æ®
        data_file = Path("data/events_ga4.ndjson")
        parser = GA4DataParser()
        raw_data = parser.parse_ndjson(str(data_file))
        
        events_data = parser.extract_events(raw_data)
        if isinstance(events_data, dict):
            all_events_list = []
            for event_type, event_df in events_data.items():
                if not event_df.empty:
                    all_events_list.append(event_df)
            combined_events = pd.concat(all_events_list, ignore_index=True)
        else:
            combined_events = events_data
        
        storage_manager = DataStorageManager()
        storage_manager.store_events(combined_events)
        
        print(f"âœ… å‡†å¤‡äº† {len(combined_events)} ä¸ªäº‹ä»¶")
        
        # 2. æµ‹è¯•äº‹ä»¶åˆ†æå¼•æ“æ–¹æ³•
        print("ğŸ” æµ‹è¯•äº‹ä»¶åˆ†æå¼•æ“...")
        event_engine = EventAnalysisEngine(storage_manager)
        
        # æµ‹è¯•ä¿®å¤åçš„ analyze_event_trends æ–¹æ³•
        try:
            trend_results = event_engine.analyze_event_trends(
                combined_events, 
                time_granularity='daily'  # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
            )
            print(f"âœ… analyze_event_trends æˆåŠŸï¼Œç»“æœæ•°: {len(trend_results)}")
        except Exception as e:
            print(f"âŒ analyze_event_trends å¤±è´¥: {e}")
            return False
        
        # 3. æµ‹è¯•ç•™å­˜åˆ†æå¼•æ“æ–¹æ³•
        print("ğŸ” æµ‹è¯•ç•™å­˜åˆ†æå¼•æ“...")
        retention_engine = RetentionAnalysisEngine(storage_manager)
        
        # æµ‹è¯•å„ç§ç•™å­˜åˆ†ææ–¹æ³•
        try:
            daily_results = retention_engine.analyze_daily_retention(combined_events)
            print(f"âœ… analyze_daily_retention æˆåŠŸ")
        except Exception as e:
            print(f"âŒ analyze_daily_retention å¤±è´¥: {e}")
        
        try:
            weekly_results = retention_engine.analyze_weekly_retention(combined_events)
            print(f"âœ… analyze_weekly_retention æˆåŠŸ")
        except Exception as e:
            print(f"âŒ analyze_weekly_retention å¤±è´¥: {e}")
        
        try:
            monthly_results = retention_engine.analyze_monthly_retention(combined_events)
            print(f"âœ… analyze_monthly_retention æˆåŠŸ")
        except Exception as e:
            print(f"âŒ analyze_monthly_retention å¤±è´¥: {e}")
        
        # æµ‹è¯•é˜Ÿåˆ—æ„å»ºæ–¹æ³•
        try:
            cohort_data = retention_engine.build_user_cohorts(
                combined_events, 
                cohort_period='monthly'  # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
            )
            print(f"âœ… build_user_cohorts æˆåŠŸ")
        except Exception as e:
            print(f"âŒ build_user_cohorts å¤±è´¥: {e}")
        
        print("\\nğŸ‰ æ–¹æ³•ä¿®å¤æµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_method_fixes()
    if success:
        print("\\nâœ… æ‰€æœ‰æ–¹æ³•ä¿®å¤æˆåŠŸï¼ç°åœ¨åº”ç”¨åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚")
    else:
        print("\\nâŒ ä»æœ‰æ–¹æ³•éœ€è¦ä¿®å¤ã€‚")