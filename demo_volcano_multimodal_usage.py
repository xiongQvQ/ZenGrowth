#!/usr/bin/env python3
"""
Volcanoå¤šæ¨¡æ€åˆ†æä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨Volcano APIè¿›è¡Œå¤šæ¨¡æ€ç”¨æˆ·è¡Œä¸ºåˆ†æï¼Œ
åŒ…æ‹¬æ–‡æœ¬å’Œå›¾åƒå†…å®¹çš„ç»¼åˆåˆ†æã€‚

ä½¿ç”¨å‰è¯·ç¡®ä¿ï¼š
1. å·²é…ç½®ARK_API_KEYç¯å¢ƒå˜é‡
2. å·²å¯ç”¨å¤šæ¨¡æ€åŠŸèƒ½
3. å›¾ç‰‡URLå¯è®¿é—®æˆ–ä½¿ç”¨æœ¬åœ°å›¾ç‰‡
"""

import os
import json
import asyncio
from datetime import datetime
from typing import Dict, List, Any, Optional

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    from config.volcano_llm_client import VolcanoLLMClient
    from config.multimodal_content_handler import MultiModalContentHandler
    from config.llm_provider_manager import LLMProviderManager
    from utils.logger import setup_logger
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…æ‰€æœ‰ä¾èµ–")
    exit(1)

# è®¾ç½®æ—¥å¿—
logger = setup_logger(__name__)

class VolcanoMultiModalDemo:
    """Volcanoå¤šæ¨¡æ€åˆ†ææ¼”ç¤ºç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºç¯å¢ƒ"""
        self.content_handler = MultiModalContentHandler()
        self.provider_manager = LLMProviderManager()
        self.results = {}
        
        # æ£€æŸ¥é…ç½®
        self._check_configuration()
    
    def _check_configuration(self):
        """æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®"""
        ark_api_key = os.getenv('ARK_API_KEY')
        if not ark_api_key:
            raise ValueError("è¯·è®¾ç½®ARK_API_KEYç¯å¢ƒå˜é‡")
        
        enable_multimodal = os.getenv('ENABLE_MULTIMODAL', 'true').lower() == 'true'
        if not enable_multimodal:
            logger.warning("å¤šæ¨¡æ€åŠŸèƒ½æœªå¯ç”¨ï¼Œå°†åªè¿›è¡Œæ–‡æœ¬åˆ†æ")
    
    def run_comprehensive_demo(self):
        """è¿è¡Œç»¼åˆæ¼”ç¤º"""
        print("ğŸš€ å¼€å§‹Volcanoå¤šæ¨¡æ€åˆ†ææ¼”ç¤º")
        print("=" * 50)
        
        # 1. åŸºç¡€è¿æ¥æµ‹è¯•
        print("\n1ï¸âƒ£ æµ‹è¯•Volcano APIè¿æ¥...")
        self._test_volcano_connection()
        
        # 2. æ–‡æœ¬åˆ†æç¤ºä¾‹
        print("\n2ï¸âƒ£ æ‰§è¡Œæ–‡æœ¬åˆ†æç¤ºä¾‹...")
        self._demo_text_analysis()
        
        # 3. å¤šæ¨¡æ€åˆ†æç¤ºä¾‹
        print("\n3ï¸âƒ£ æ‰§è¡Œå¤šæ¨¡æ€åˆ†æç¤ºä¾‹...")
        self._demo_multimodal_analysis()
        
        # 4. ç”¨æˆ·è¡Œä¸ºåˆ†æç¤ºä¾‹
        print("\n4ï¸âƒ£ æ‰§è¡Œç”¨æˆ·è¡Œä¸ºåˆ†æç¤ºä¾‹...")
        self._demo_user_behavior_analysis()
        
        # 5. æä¾›å•†åˆ‡æ¢æ¼”ç¤º
        print("\n5ï¸âƒ£ æ¼”ç¤ºæä¾›å•†è‡ªåŠ¨åˆ‡æ¢...")
        self._demo_provider_fallback()
        
        # 6. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        print("\n6ï¸âƒ£ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        self._generate_demo_report()
        
        print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    
    def _test_volcano_connection(self):
        """æµ‹è¯•Volcano APIè¿æ¥"""
        try:
            llm = self.provider_manager.get_llm(provider="volcano")
            
            test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ çš„èƒ½åŠ›"
            response = llm.invoke(test_prompt)
            
            print(f"âœ… Volcano APIè¿æ¥æˆåŠŸ")
            print(f"ğŸ“ å“åº”ç¤ºä¾‹: {response[:100]}...")
            
            self.results['connection_test'] = {
                'status': 'success',
                'response_preview': response[:200]
            }
            
        except Exception as e:
            print(f"âŒ Volcano APIè¿æ¥å¤±è´¥: {e}")
            self.results['connection_test'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    def _demo_text_analysis(self):
        """æ¼”ç¤ºæ–‡æœ¬åˆ†æåŠŸèƒ½"""
        try:
            llm = self.provider_manager.get_llm(provider="volcano")
            
            # ç¤ºä¾‹ç”¨æˆ·è¡Œä¸ºæ–‡æœ¬æ•°æ®
            user_behavior_text = """
            ç”¨æˆ·åœ¨ç”µå•†ç½‘ç«™çš„è¡Œä¸ºè®°å½•ï¼š
            - æµè§ˆäº†è¿åŠ¨é‹ç±»åˆ«é¡µé¢ï¼Œåœç•™3åˆ†é’Ÿ
            - æŸ¥çœ‹äº†5æ¬¾ä¸åŒå“ç‰Œçš„è¿åŠ¨é‹è¯¦æƒ…
            - å°†2æ¬¾é‹å­åŠ å…¥è´­ç‰©è½¦
            - æŸ¥çœ‹äº†ç”¨æˆ·è¯„ä»·å’Œå°ºç æŒ‡å—
            - æœ€ç»ˆè´­ä¹°äº†ä¸€æ¬¾Nikeè¿åŠ¨é‹
            - è´­ä¹°åæŸ¥çœ‹äº†é…é€ä¿¡æ¯
            """
            
            analysis_prompt = f"""
            è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œæä¾›æ´å¯Ÿå’Œå»ºè®®ï¼š
            
            {user_behavior_text}
            
            è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š
            1. ç”¨æˆ·è´­ä¹°æ„å›¾å¼ºåº¦
            2. å†³ç­–è¿‡ç¨‹ç‰¹ç‚¹
            3. å¯èƒ½çš„ä¼˜åŒ–å»ºè®®
            4. ç”¨æˆ·ç±»å‹åˆ¤æ–­
            
            è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–åˆ†æç»“æœã€‚
            """
            
            response = llm.invoke(analysis_prompt)
            
            print("âœ… æ–‡æœ¬åˆ†æå®Œæˆ")
            print(f"ğŸ“Š åˆ†æç»“æœ: {response[:200]}...")
            
            self.results['text_analysis'] = {
                'input': user_behavior_text,
                'analysis': response
            }
            
        except Exception as e:
            print(f"âŒ æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
            self.results['text_analysis'] = {'error': str(e)}
    
    def _demo_multimodal_analysis(self):
        """æ¼”ç¤ºå¤šæ¨¡æ€åˆ†æåŠŸèƒ½"""
        try:
            llm = self.provider_manager.get_llm(provider="volcano")
            
            if not hasattr(llm, 'supports_multimodal') or not llm.supports_multimodal():
                print("âš ï¸ å½“å‰LLMä¸æ”¯æŒå¤šæ¨¡æ€ï¼Œè·³è¿‡æ­¤æ¼”ç¤º")
                return
            
            # æ„å»ºå¤šæ¨¡æ€å†…å®¹
            multimodal_content = [
                {
                    "type": "text",
                    "text": """è¯·åˆ†æè¿™ä¸ªç”µå•†åœºæ™¯ï¼šç”¨æˆ·æ­£åœ¨æµè§ˆè¿åŠ¨é‹å•†å“é¡µé¢ã€‚
                    è¯·ç»“åˆå›¾ç‰‡å†…å®¹å’Œæ–‡æœ¬æè¿°ï¼Œåˆ†æç”¨æˆ·å¯èƒ½çš„è´­ä¹°æ„å›¾å’Œåå¥½ã€‚"""
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://example.com/sample_sneaker.jpg",  # ç¤ºä¾‹å›¾ç‰‡URL
                        "detail": "high"
                    }
                }
            ]
            
            # éªŒè¯å’Œå¤„ç†å†…å®¹
            processed_content = self.content_handler.prepare_content(multimodal_content)
            
            # æ„å»ºå¤šæ¨¡æ€åˆ†ææç¤º
            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†ç”¨æˆ·è¡Œä¸ºåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æå¤šæ¨¡æ€æ•°æ®ã€‚"
                },
                {
                    "role": "user",
                    "content": processed_content
                }
            ]
            
            # æ‰§è¡Œå¤šæ¨¡æ€åˆ†æ
            response = llm.invoke(messages)
            
            print("âœ… å¤šæ¨¡æ€åˆ†æå®Œæˆ")
            print(f"ğŸ–¼ï¸ åˆ†æç»“æœ: {response[:200]}...")
            
            self.results['multimodal_analysis'] = {
                'content_types': ['text', 'image'],
                'analysis': response
            }
            
        except Exception as e:
            print(f"âŒ å¤šæ¨¡æ€åˆ†æå¤±è´¥: {e}")
            print("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥å›¾ç‰‡URLæ˜¯å¦å¯è®¿é—®ï¼Œæˆ–ä½¿ç”¨æœ¬åœ°å›¾ç‰‡")
            self.results['multimodal_analysis'] = {'error': str(e)}
    
    def _demo_user_behavior_analysis(self):
        """æ¼”ç¤ºç”¨æˆ·è¡Œä¸ºåˆ†æ"""
        try:
            # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºæ•°æ®
            user_behavior_data = {
                "user_id": "user_12345",
                "session_data": {
                    "duration_minutes": 25,
                    "page_views": 12,
                    "events": [
                        {"event": "page_view", "page": "homepage", "timestamp": "2024-01-15T10:00:00"},
                        {"event": "search", "query": "è¿åŠ¨é‹", "timestamp": "2024-01-15T10:02:00"},
                        {"event": "product_view", "product_id": "shoe_001", "timestamp": "2024-01-15T10:05:00"},
                        {"event": "add_to_cart", "product_id": "shoe_001", "timestamp": "2024-01-15T10:15:00"},
                        {"event": "checkout", "total": 299.99, "timestamp": "2024-01-15T10:20:00"}
                    ]
                },
                "user_profile": {
                    "age_group": "25-34",
                    "gender": "male",
                    "location": "åŒ—äº¬",
                    "previous_purchases": 3
                }
            }
            
            # åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼
            analysis_result = self._analyze_user_behavior_pattern(user_behavior_data)
            
            print("âœ… ç”¨æˆ·è¡Œä¸ºåˆ†æå®Œæˆ")
            print(f"ğŸ‘¤ ç”¨æˆ·ç±»å‹: {analysis_result.get('user_type', 'unknown')}")
            print(f"ğŸ¯ è´­ä¹°æ„å›¾: {analysis_result.get('purchase_intent', 'unknown')}")
            
            self.results['user_behavior_analysis'] = analysis_result
            
        except Exception as e:
            print(f"âŒ ç”¨æˆ·è¡Œä¸ºåˆ†æå¤±è´¥: {e}")
            self.results['user_behavior_analysis'] = {'error': str(e)}
    
    def _analyze_user_behavior_pattern(self, behavior_data: Dict) -> Dict:
        """åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼"""
        try:
            llm = self.provider_manager.get_llm(provider="volcano")
            
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œè¯†åˆ«ç”¨æˆ·ç±»å‹å’Œè´­ä¹°æ¨¡å¼ï¼š
            
            {json.dumps(behavior_data, indent=2, ensure_ascii=False)}
            
            è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
            1. ç”¨æˆ·ç±»å‹åˆ†ç±»ï¼ˆå¦‚ï¼šç›®æ ‡æ˜ç¡®å‹ã€æ¯”è¾ƒå‹ã€å†²åŠ¨å‹ç­‰ï¼‰
            2. è´­ä¹°æ„å›¾å¼ºåº¦ï¼ˆ1-10åˆ†ï¼‰
            3. å†³ç­–é€Ÿåº¦è¯„ä¼°
            4. ä¸ªæ€§åŒ–æ¨èç­–ç•¥
            5. æ½œåœ¨æµå¤±é£é™©è¯„ä¼°
            
            è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–ç»“æœã€‚
            """
            
            response = llm.invoke(prompt)
            
            # å°è¯•è§£æJSONå“åº”
            try:
                import re
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
                else:
                    return {"raw_analysis": response}
            except:
                return {"raw_analysis": response}
                
        except Exception as e:
            return {"error": str(e)}
    
    def _demo_provider_fallback(self):
        """æ¼”ç¤ºæä¾›å•†è‡ªåŠ¨åˆ‡æ¢"""
        try:
            print("ğŸ”„ æµ‹è¯•æä¾›å•†è‡ªåŠ¨åˆ‡æ¢æœºåˆ¶...")
            
            # å°è¯•ä½¿ç”¨ä¸å­˜åœ¨çš„æä¾›å•†ï¼Œè§¦å‘fallback
            try:
                llm = self.provider_manager.get_llm(provider="nonexistent")
                response = llm.invoke("æµ‹è¯•fallbackæœºåˆ¶")
                print("âœ… Fallbackæœºåˆ¶å·¥ä½œæ­£å¸¸")
                
                self.results['fallback_test'] = {
                    'status': 'success',
                    'fallback_triggered': True
                }
                
            except Exception as e:
                print(f"âš ï¸ Fallbackæµ‹è¯•: {e}")
                
                # å°è¯•æ­£å¸¸çš„fallbackåœºæ™¯
                llm = self.provider_manager.get_llm()  # ä½¿ç”¨é»˜è®¤æä¾›å•†
                response = llm.invoke("æµ‹è¯•é»˜è®¤æä¾›å•†")
                print("âœ… é»˜è®¤æä¾›å•†å·¥ä½œæ­£å¸¸")
                
                self.results['fallback_test'] = {
                    'status': 'partial_success',
                    'default_provider_works': True
                }
                
        except Exception as e:
            print(f"âŒ æä¾›å•†åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}")
            self.results['fallback_test'] = {'error': str(e)}
    
    def _generate_demo_report(self):
        """ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š"""
        try:
            report = {
                "demo_info": {
                    "timestamp": datetime.now().isoformat(),
                    "demo_version": "1.0.0",
                    "volcano_integration": "enabled"
                },
                "test_results": self.results,
                "summary": self._generate_summary()
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_filename = f"volcano_multimodal_demo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            report_path = os.path.join("reports", report_filename)
            
            # ç¡®ä¿reportsç›®å½•å­˜åœ¨
            os.makedirs("reports", exist_ok=True)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“„ æ¼”ç¤ºæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
            # æ‰“å°æ‘˜è¦
            print("\nğŸ“Š æ¼”ç¤ºæ‘˜è¦:")
            for key, value in report["summary"].items():
                print(f"  {key}: {value}")
                
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _generate_summary(self) -> Dict:
        """ç”Ÿæˆæ¼”ç¤ºæ‘˜è¦"""
        summary = {
            "æ€»æµ‹è¯•é¡¹ç›®": len(self.results),
            "æˆåŠŸé¡¹ç›®": 0,
            "å¤±è´¥é¡¹ç›®": 0,
            "éƒ¨åˆ†æˆåŠŸé¡¹ç›®": 0
        }
        
        for test_name, result in self.results.items():
            if isinstance(result, dict):
                if result.get('status') == 'success':
                    summary["æˆåŠŸé¡¹ç›®"] += 1
                elif result.get('status') == 'failed' or 'error' in result:
                    summary["å¤±è´¥é¡¹ç›®"] += 1
                elif result.get('status') == 'partial_success':
                    summary["éƒ¨åˆ†æˆåŠŸé¡¹ç›®"] += 1
                else:
                    summary["æˆåŠŸé¡¹ç›®"] += 1  # é»˜è®¤è®¤ä¸ºæˆåŠŸ
            else:
                summary["æˆåŠŸé¡¹ç›®"] += 1
        
        return summary

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
        demo = VolcanoMultiModalDemo()
        
        # è¿è¡Œæ¼”ç¤º
        demo.run_comprehensive_demo()
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")
        print("\nğŸ’¡ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥ARK_API_KEYç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®")
        print("2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
        print("3. éªŒè¯Volcano APIæœåŠ¡çŠ¶æ€")
        print("4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—")

if __name__ == "__main__":
    main()