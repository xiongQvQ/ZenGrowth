#!/usr/bin/env python3
"""
æµ‹è¯•é›†æˆç®¡ç†å™¨ä¿®å¤
"""

import pandas as pd
from pathlib import Path
from tools.ga4_data_parser import GA4DataParser
from tools.data_storage_manager import DataStorageManager
from system.integration_manager import IntegrationManager, WorkflowConfig

def test_integration_fix():
    """æµ‹è¯•é›†æˆç®¡ç†å™¨ä¿®å¤"""
    try:
        print("ğŸ§ª æµ‹è¯•é›†æˆç®¡ç†å™¨ä¿®å¤...")
        
        # 1. å‡†å¤‡æ•°æ®
        data_file = Path("data/events_ga4.ndjson")
        parser = GA4DataParser()
        raw_data = parser.parse_ndjson(str(data_file))
        
        # 2. å¤„ç†æ•°æ®
        events_data = parser.extract_events(raw_data)
        if isinstance(events_data, dict):
            all_events_list = []
            for event_type, event_df in events_data.items():
                if not event_df.empty:
                    all_events_list.append(event_df)
            combined_events = pd.concat(all_events_list, ignore_index=True)
        else:
            combined_events = events_data
        
        print(f"âœ… å‡†å¤‡äº† {len(combined_events)} ä¸ªäº‹ä»¶")
        
        # 3. åˆ›å»ºå­˜å‚¨ç®¡ç†å™¨å¹¶å­˜å‚¨æ•°æ®
        storage_manager = DataStorageManager()
        storage_manager.store_events(combined_events)
        
        # éªŒè¯å­˜å‚¨
        stored_events = storage_manager.get_data('events')
        if stored_events.empty:
            print("âŒ å­˜å‚¨ç®¡ç†å™¨ä¸­æ²¡æœ‰æ•°æ®")
            return False
        
        print(f"âœ… å­˜å‚¨ç®¡ç†å™¨æœ‰ {len(stored_events)} ä¸ªäº‹ä»¶")
        
        # 4. åˆ›å»ºé›†æˆç®¡ç†å™¨
        config = WorkflowConfig(
            enable_parallel_processing=False,
            max_workers=2,
            timeout_minutes=5,
            enable_caching=True,
            auto_cleanup=True
        )
        
        integration_manager = IntegrationManager(config)
        
        # 5. æµ‹è¯•åˆå§‹çŠ¶æ€ï¼ˆåº”è¯¥ä¸ºç©ºï¼‰
        initial_events = integration_manager.storage_manager.get_data('events')
        print(f"ğŸ” é›†æˆç®¡ç†å™¨åˆå§‹äº‹ä»¶æ•°: {len(initial_events)}")
        
        # 6. åˆ·æ–°å­˜å‚¨ç®¡ç†å™¨
        print("ğŸ”„ åˆ·æ–°é›†æˆç®¡ç†å™¨çš„å­˜å‚¨ç®¡ç†å™¨...")
        integration_manager.refresh_storage_manager(storage_manager)
        
        # 7. éªŒè¯åˆ·æ–°åçš„çŠ¶æ€
        refreshed_events = integration_manager.storage_manager.get_data('events')
        print(f"âœ… åˆ·æ–°åé›†æˆç®¡ç†å™¨äº‹ä»¶æ•°: {len(refreshed_events)}")
        
        if refreshed_events.empty:
            print("âŒ åˆ·æ–°åä»ç„¶æ²¡æœ‰æ•°æ®")
            return False
        
        # 8. æµ‹è¯•åˆ†ææ‰§è¡Œ
        print("ğŸ§ª æµ‹è¯•åˆ†ææ‰§è¡Œ...")
        try:
            result = integration_manager._execute_single_analysis('event_analysis')
            print(f"âœ… äº‹ä»¶åˆ†æçŠ¶æ€: {result.status}")
            
            if result.status == 'failed':
                print(f"âŒ åˆ†æå¤±è´¥: {result.error_message}")
                return False
                
        except Exception as e:
            print(f"âŒ åˆ†ææ‰§è¡Œå¼‚å¸¸: {e}")
            return False
        
        print("\\nğŸ‰ é›†æˆç®¡ç†å™¨ä¿®å¤æµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_integration_fix()
    if success:
        print("\\nâœ… ä¿®å¤æˆåŠŸï¼ç°åœ¨é›†æˆç®¡ç†å™¨åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚")
    else:
        print("\\nâŒ ä¿®å¤å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")