"""
ç›‘æ§ç³»ç»Ÿæµ‹è¯•
æµ‹è¯•ç›‘æ§å’Œæ—¥å¿—å¢å¼ºåŠŸèƒ½
"""

import os
import sys
import time
import json
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.monitoring_system import (
    PerformanceMonitor, 
    RequestType, 
    ResponseStatus,
    get_performance_monitor,
    reset_performance_monitor
)
from config.volcano_llm_client_monitored import MonitoredVolcanoLLMClient
from config.llm_provider_manager import get_provider_manager, reset_provider_manager
from config.settings import settings

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_performance_monitor():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨åŸºæœ¬åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨åŸºæœ¬åŠŸèƒ½ ===")
    
    # é‡ç½®ç›‘æ§å™¨
    reset_performance_monitor()
    monitor = get_performance_monitor()
    
    # æ¨¡æ‹Ÿè¯·æ±‚è®°å½•
    metrics = monitor.record_request_start(
        request_id="test-001",
        provider="volcano",
        prompt="Hello, world!",
        request_type=RequestType.TEXT_ONLY,
        model="doubao-seed-1-6-250615"
    )
    
    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    time.sleep(0.1)
    
    # è®°å½•æˆåŠŸç»“æœ
    monitor.record_request_end(
        metrics=metrics,
        response="Hello! How can I help you today?",
        status=ResponseStatus.SUCCESS,
        tokens_used=25
    )
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = monitor.get_provider_stats("volcano")
    print(f"æä¾›å•†ç»Ÿè®¡: {stats}")
    
    # è·å–æœ€è¿‘è¯·æ±‚
    recent_requests = monitor.get_recent_requests(limit=5)
    print(f"æœ€è¿‘è¯·æ±‚æ•°é‡: {len(recent_requests)}")
    
    # è·å–æ€§èƒ½æ¯”è¾ƒ
    comparison = monitor.get_performance_comparison()
    print(f"æ€§èƒ½æ¯”è¾ƒ: {json.dumps(comparison, indent=2, ensure_ascii=False)}")
    
    print("âœ… æ€§èƒ½ç›‘æ§å™¨åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")


def test_monitoring_with_different_scenarios():
    """æµ‹è¯•ä¸åŒåœºæ™¯ä¸‹çš„ç›‘æ§"""
    print("\n=== æµ‹è¯•ä¸åŒåœºæ™¯ä¸‹çš„ç›‘æ§ ===")
    
    monitor = get_performance_monitor()
    
    # åœºæ™¯1: æˆåŠŸçš„æ–‡æœ¬è¯·æ±‚
    metrics1 = monitor.record_request_start(
        request_id="test-text-001",
        provider="volcano",
        prompt="What is AI?",
        request_type=RequestType.TEXT_ONLY
    )
    time.sleep(0.05)
    monitor.record_request_end(
        metrics=metrics1,
        response="AI stands for Artificial Intelligence...",
        status=ResponseStatus.SUCCESS,
        tokens_used=50
    )
    
    # åœºæ™¯2: å¤šæ¨¡æ€è¯·æ±‚
    metrics2 = monitor.record_request_start(
        request_id="test-multimodal-001",
        provider="volcano",
        prompt="Describe this image",
        request_type=RequestType.MULTIMODAL,
        image_count=1
    )
    time.sleep(0.08)
    monitor.record_request_end(
        metrics=metrics2,
        response="This image shows...",
        status=ResponseStatus.SUCCESS,
        tokens_used=75
    )
    
    # åœºæ™¯3: å¤±è´¥çš„è¯·æ±‚
    metrics3 = monitor.record_request_start(
        request_id="test-error-001",
        provider="volcano",
        prompt="Test error",
        request_type=RequestType.TEXT_ONLY
    )
    time.sleep(0.02)
    monitor.record_request_end(
        metrics=metrics3,
        status=ResponseStatus.ERROR,
        error_message="API rate limit exceeded",
        retry_count=2
    )
    
    # åœºæ™¯4: è¶…æ—¶è¯·æ±‚
    metrics4 = monitor.record_request_start(
        request_id="test-timeout-001",
        provider="volcano",
        prompt="Test timeout",
        request_type=RequestType.TEXT_ONLY
    )
    time.sleep(0.03)
    monitor.record_request_end(
        metrics=metrics4,
        status=ResponseStatus.TIMEOUT,
        error_message="Request timeout after 30 seconds"
    )
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = monitor.get_provider_stats("volcano")
    print(f"æ€»è¯·æ±‚æ•°: {stats.total_requests}")
    print(f"æˆåŠŸè¯·æ±‚æ•°: {stats.successful_requests}")
    print(f"å¤±è´¥è¯·æ±‚æ•°: {stats.failed_requests}")
    print(f"æˆåŠŸç‡: {stats.success_rate:.2%}")
    print(f"å¹³å‡å“åº”æ—¶é—´: {stats.average_response_time:.3f}s")
    print(f"è¯·æ±‚ç±»å‹åˆ†å¸ƒ: {stats.request_count_by_type}")
    print(f"é”™è¯¯ç±»å‹åˆ†å¸ƒ: {stats.error_count_by_type}")
    
    print("âœ… ä¸åŒåœºæ™¯ç›‘æ§æµ‹è¯•é€šè¿‡")


def test_system_health_monitoring():
    """æµ‹è¯•ç³»ç»Ÿå¥åº·ç›‘æ§"""
    print("\n=== æµ‹è¯•ç³»ç»Ÿå¥åº·ç›‘æ§ ===")
    
    monitor = get_performance_monitor()
    
    # è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€
    health = monitor.get_system_health()
    print(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {json.dumps(health, indent=2, ensure_ascii=False)}")
    
    # è·å–æŒ‰å°æ—¶ç»Ÿè®¡
    hourly_stats = monitor.get_hourly_stats(hours=1)
    print(f"æŒ‰å°æ—¶ç»Ÿè®¡: {json.dumps(hourly_stats, indent=2, ensure_ascii=False)}")
    
    print("âœ… ç³»ç»Ÿå¥åº·ç›‘æ§æµ‹è¯•é€šè¿‡")


def test_monitoring_export():
    """æµ‹è¯•ç›‘æ§æ•°æ®å¯¼å‡º"""
    print("\n=== æµ‹è¯•ç›‘æ§æ•°æ®å¯¼å‡º ===")
    
    monitor = get_performance_monitor()
    
    # å¯¼å‡ºç›‘æ§æŒ‡æ ‡
    metrics_json = monitor.export_metrics()
    print(f"å¯¼å‡ºçš„ç›‘æ§æŒ‡æ ‡é•¿åº¦: {len(metrics_json)} å­—ç¬¦")
    
    # éªŒè¯JSONæ ¼å¼
    try:
        metrics_data = json.loads(metrics_json)
        print(f"å¯¼å‡ºæ•°æ®åŒ…å«çš„é”®: {list(metrics_data.keys())}")
        print("âœ… ç›‘æ§æ•°æ®å¯¼å‡ºæµ‹è¯•é€šè¿‡")
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")


def test_monitored_volcano_client():
    """æµ‹è¯•å¸¦ç›‘æ§çš„Volcanoå®¢æˆ·ç«¯"""
    print("\n=== æµ‹è¯•å¸¦ç›‘æ§çš„Volcanoå®¢æˆ·ç«¯ ===")
    
    # æ£€æŸ¥APIå¯†é’¥é…ç½®
    if not settings.ark_api_key:
        print("âš ï¸  Volcano APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡å®¢æˆ·ç«¯æµ‹è¯•")
        return
    
    try:
        # åˆ›å»ºç›‘æ§å¢å¼ºçš„å®¢æˆ·ç«¯
        client = MonitoredVolcanoLLMClient(
            api_key=settings.ark_api_key,
            base_url=settings.ark_base_url,
            model=settings.ark_model
        )
        
        # æ‰§è¡Œå¥åº·æ£€æŸ¥
        health_result = client.health_check()
        print(f"å¥åº·æ£€æŸ¥ç»“æœ: {json.dumps(health_result, indent=2, ensure_ascii=False)}")
        
        # è·å–ç›‘æ§ç»Ÿè®¡
        stats = client.get_monitoring_stats()
        print(f"å®¢æˆ·ç«¯ç›‘æ§ç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
        # è·å–æœ€è¿‘è¯·æ±‚
        recent_requests = client.get_recent_requests(limit=3)
        print(f"æœ€è¿‘è¯·æ±‚æ•°é‡: {len(recent_requests)}")
        
        print("âœ… å¸¦ç›‘æ§çš„Volcanoå®¢æˆ·ç«¯æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âš ï¸  Volcanoå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        print("è¿™å¯èƒ½æ˜¯ç”±äºAPIå¯†é’¥é…ç½®æˆ–ç½‘ç»œè¿æ¥é—®é¢˜")


def test_provider_manager_monitoring():
    """æµ‹è¯•æä¾›å•†ç®¡ç†å™¨çš„ç›‘æ§åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æä¾›å•†ç®¡ç†å™¨çš„ç›‘æ§åŠŸèƒ½ ===")
    
    try:
        # é‡ç½®æä¾›å•†ç®¡ç†å™¨
        reset_provider_manager()
        manager = get_provider_manager()
        
        # è·å–ç›‘æ§ç»Ÿè®¡
        monitoring_stats = manager.get_monitoring_stats()
        print(f"æä¾›å•†ç®¡ç†å™¨ç›‘æ§ç»Ÿè®¡é”®: {list(monitoring_stats.keys())}")
        
        # è·å–ç‰¹å®šæä¾›å•†çš„ç›‘æ§ç»Ÿè®¡
        volcano_stats = manager.get_provider_monitoring_stats("volcano")
        if volcano_stats:
            print(f"Volcanoæä¾›å•†ç›‘æ§ç»Ÿè®¡: {json.dumps(volcano_stats, indent=2, ensure_ascii=False)}")
        else:
            print("Volcanoæä¾›å•†ç›‘æ§ç»Ÿè®¡: æ— æ•°æ®")
        
        # å¯¼å‡ºç›‘æ§æŠ¥å‘Š
        report = manager.export_monitoring_report()
        print(f"ç›‘æ§æŠ¥å‘Šé•¿åº¦: {len(report)} å­—ç¬¦")
        
        print("âœ… æä¾›å•†ç®¡ç†å™¨ç›‘æ§åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âš ï¸  æä¾›å•†ç®¡ç†å™¨ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")


def test_log_files_creation():
    """æµ‹è¯•æ—¥å¿—æ–‡ä»¶åˆ›å»º"""
    print("\n=== æµ‹è¯•æ—¥å¿—æ–‡ä»¶åˆ›å»º ===")
    
    log_dir = Path("logs/monitoring")
    
    expected_files = ["requests.log", "performance.log", "errors.log"]
    
    for filename in expected_files:
        log_file = log_dir / filename
        if log_file.exists():
            print(f"âœ… æ—¥å¿—æ–‡ä»¶å­˜åœ¨: {log_file}")
            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
            size = log_file.stat().st_size
            print(f"   æ–‡ä»¶å¤§å°: {size} å­—èŠ‚")
        else:
            print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
    
    print("âœ… æ—¥å¿—æ–‡ä»¶åˆ›å»ºæµ‹è¯•å®Œæˆ")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ç›‘æ§ç³»ç»Ÿæµ‹è¯•...")
    
    try:
        # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
        test_performance_monitor()
        test_monitoring_with_different_scenarios()
        test_system_health_monitoring()
        test_monitoring_export()
        
        # é›†æˆæµ‹è¯•
        test_monitored_volcano_client()
        test_provider_manager_monitoring()
        
        # æ—¥å¿—æµ‹è¯•
        test_log_files_creation()
        
        print("\nğŸ‰ æ‰€æœ‰ç›‘æ§ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()