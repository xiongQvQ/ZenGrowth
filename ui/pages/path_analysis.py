"""
è·¯å¾„åˆ†æé¡µé¢
åˆ†æç”¨æˆ·è¡Œä¸ºè·¯å¾„å’Œæµè½¬
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import networkx as nx
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import numpy as np

from engines.path_analysis_engine import PathAnalysisEngine
from visualization.chart_generator import ChartGenerator
from visualization.advanced_visualizer import AdvancedVisualizer
from utils.i18n import t
from ui.components.common import render_no_data_warning, render_data_status_check

class PathAnalysisPage:
    """è·¯å¾„åˆ†æé¡µé¢ç±»"""
    
    def __init__(self):
        self._initialize_engines()
    
    def _initialize_engines(self):
        """åˆå§‹åŒ–åˆ†æå¼•æ“å’Œå¯è§†åŒ–ç»„ä»¶"""
        if 'path_engine' not in st.session_state:
            st.session_state.path_engine = PathAnalysisEngine()
        if 'chart_generator' not in st.session_state:
            st.session_state.chart_generator = ChartGenerator()
        if 'advanced_visualizer' not in st.session_state:
            st.session_state.advanced_visualizer = AdvancedVisualizer()
    
    def render(self):
        """æ¸²æŸ“è·¯å¾„åˆ†æé¡µé¢"""
        from ui.state import get_state_manager
        
        # æ£€æŸ¥æ•°æ®çŠ¶æ€
        state_manager = get_state_manager()
        if not state_manager.is_data_loaded():
            render_no_data_warning()
            return
        
        st.header("ğŸ›¤ï¸ " + t("pages.path_analysis.title", "è·¯å¾„åˆ†æ"))
        st.markdown("---")
        
        # åˆ†æé…ç½®é¢æ¿
        config = self._render_analysis_config()
        
        # æ‰§è¡Œåˆ†ææŒ‰é’®
        if st.button(t('analysis.start_path_analysis', 'å¼€å§‹è·¯å¾„åˆ†æ'), type="primary"):
            self._execute_path_analysis(config)
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        if 'path_analysis_results' in st.session_state:
            self._render_analysis_results()
    
    def _render_analysis_config(self) -> Dict[str, Any]:
        """æ¸²æŸ“åˆ†æé…ç½®é¢æ¿"""
        with st.expander(t('analysis.path_config', 'è·¯å¾„åˆ†æé…ç½®'), expanded=False):
            
            # åŸºç¡€é…ç½®
            col1, col2, col3 = st.columns(3)
            
            with col1:
                date_range = st.date_input(
                    t('analysis.time_range_label', 'æ—¶é—´èŒƒå›´'),
                    value=(datetime.now() - timedelta(days=30), datetime.now()),
                    help=t('analysis.time_range_help', 'é€‰æ‹©åˆ†æçš„æ—¶é—´èŒƒå›´')
                )
            
            with col2:
                analysis_type = st.selectbox(
                    t('analysis.path_analysis_type', 'åˆ†æç±»å‹'),
                    options=[
                        t('analysis.session_reconstruction', 'ä¼šè¯é‡æ„'),
                        t('analysis.pattern_mining', 'æ¨¡å¼æŒ–æ˜'),
                        t('analysis.flow_analysis', 'æµç¨‹åˆ†æ'),
                        t('analysis.comprehensive_path', 'ç»¼åˆè·¯å¾„åˆ†æ')
                    ],
                    index=3,
                    help=t('analysis.path_type_help', 'é€‰æ‹©è·¯å¾„åˆ†æçš„ç±»å‹')
                )
            
            with col3:
                session_timeout = st.slider(
                    t('analysis.session_timeout', 'ä¼šè¯è¶…æ—¶(åˆ†é’Ÿ)'),
                    min_value=5,
                    max_value=120,
                    value=30,
                    help=t('analysis.session_timeout_help', 'ä¼šè¯é—´éš”è¶…è¿‡æ­¤æ—¶é—´è§†ä¸ºæ–°ä¼šè¯')
                )
            
            # é«˜çº§é…ç½®
            with st.expander(t('analysis.advanced_config', 'é«˜çº§é…ç½®'), expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    min_path_length = st.slider(
                        t('analysis.min_path_length', 'æœ€å°è·¯å¾„é•¿åº¦'),
                        min_value=1,
                        max_value=20,
                        value=2,
                        help=t('analysis.min_path_help', 'åˆ†æçš„æœ€å°è·¯å¾„æ­¥æ•°')
                    )
                    
                    max_path_length = st.slider(
                        t('analysis.max_path_length', 'æœ€å¤§è·¯å¾„é•¿åº¦'),
                        min_value=3,
                        max_value=50,
                        value=15,
                        help=t('analysis.max_path_help', 'åˆ†æçš„æœ€å¤§è·¯å¾„æ­¥æ•°')
                    )
                
                with col2:
                    min_pattern_frequency = st.slider(
                        t('analysis.min_pattern_freq', 'æœ€å°æ¨¡å¼é¢‘æ¬¡'),
                        min_value=1,
                        max_value=100,
                        value=5,
                        help=t('analysis.pattern_freq_help', 'æ¨¡å¼å‡ºç°çš„æœ€å°æ¬¡æ•°')
                    )
                    
                    include_anomalies = st.checkbox(
                        t('analysis.include_anomalies', 'åŒ…å«å¼‚å¸¸è·¯å¾„'),
                        value=True,
                        help=t('analysis.anomalies_help', 'è¯†åˆ«å’Œåˆ†æå¼‚å¸¸ç”¨æˆ·è·¯å¾„')
                    )
            
            # ç‰¹å®šè·¯å¾„åˆ†æé…ç½®
            specific_paths = []
            if analysis_type in [t('analysis.flow_analysis', 'æµç¨‹åˆ†æ'), t('analysis.comprehensive_path', 'ç»¼åˆè·¯å¾„åˆ†æ')]:
                st.subheader(t('analysis.specific_path_config', 'ç‰¹å®šè·¯å¾„é…ç½®'))
                
                # è·å–å¯ç”¨äº‹ä»¶ç±»å‹
                from ui.state import get_state_manager
                state_manager = get_state_manager()
                data_summary = state_manager.get_data_summary()
                event_types = list(data_summary.get('event_types', {}).keys()) if data_summary else []
                
                if event_types:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        start_events = st.multiselect(
                            t('analysis.start_events', 'èµ·å§‹äº‹ä»¶'),
                            options=event_types,
                            default=[],
                            help=t('analysis.start_events_help', 'é€‰æ‹©è·¯å¾„åˆ†æçš„èµ·å§‹äº‹ä»¶')
                        )
                    
                    with col2:
                        end_events = st.multiselect(
                            t('analysis.end_events', 'ç»“æŸäº‹ä»¶'),
                            options=event_types,
                            default=[],
                            help=t('analysis.end_events_help', 'é€‰æ‹©è·¯å¾„åˆ†æçš„ç»“æŸäº‹ä»¶')
                        )
                    
                    specific_paths = start_events + end_events
                else:
                    st.warning(t('analysis.no_event_types', 'æš‚æ— å¯ç”¨çš„äº‹ä»¶ç±»å‹'))
        
        return {
            'date_range': date_range,
            'analysis_type': analysis_type,
            'session_timeout': session_timeout,
            'min_path_length': min_path_length,
            'max_path_length': max_path_length,
            'min_pattern_frequency': min_pattern_frequency,
            'include_anomalies': include_anomalies,
            'specific_paths': specific_paths
        }
    
    def _execute_path_analysis(self, config: Dict[str, Any]):
        """æ‰§è¡Œè·¯å¾„åˆ†æ"""
        from ui.state import get_state_manager
        
        with st.spinner(t('analysis.path_processing', 'æ­£åœ¨æ‰§è¡Œè·¯å¾„åˆ†æ...')):
            try:
                # è·å–æ•°æ®
                state_manager = get_state_manager()
                raw_data = state_manager.get_raw_data()
                
                if raw_data.empty:
                    st.error(t('analysis.no_data', 'æ²¡æœ‰å¯ç”¨çš„æ•°æ®è¿›è¡Œåˆ†æ'))
                    return
                
                # åˆå§‹åŒ–å¼•æ“
                engine = st.session_state.path_engine
                engine.session_timeout_minutes = config.get('session_timeout', 30)
                engine.min_pattern_frequency = config.get('min_pattern_frequency', 5)
                
                # åº”ç”¨æ—¶é—´ç­›é€‰
                filtered_data = self._filter_data_by_time(raw_data, config['date_range'])
                
                # æ‰§è¡Œè·¯å¾„åˆ†æ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # æ­¥éª¤1: ä¼šè¯é‡æ„
                status_text.text(t('analysis.step_session_reconstruction', 'é‡æ„ç”¨æˆ·ä¼šè¯...'))
                progress_bar.progress(20)
                
                sessions = engine.reconstruct_user_sessions(filtered_data)
                
                # æ­¥éª¤2: è·¯å¾„æ¨¡å¼è¯†åˆ«
                status_text.text(t('analysis.step_pattern_identification', 'è¯†åˆ«è·¯å¾„æ¨¡å¼...'))
                progress_bar.progress(50)
                
                path_patterns = engine.identify_path_patterns(sessions)
                
                # æ­¥éª¤3: è·¯å¾„æŒ–æ˜
                status_text.text(t('analysis.step_path_mining', 'æŒ–æ˜ç”¨æˆ·è·¯å¾„...'))
                progress_bar.progress(70)
                
                mined_paths = engine.mine_user_paths(
                    filtered_data, 
                    min_length=config.get('min_path_length', 2),
                    max_length=config.get('max_path_length', 15)
                )
                
                # æ­¥éª¤4: ç”Ÿæˆæ´å¯Ÿ
                status_text.text(t('analysis.step_generating_insights', 'ç”Ÿæˆåˆ†ææ´å¯Ÿ...'))
                progress_bar.progress(90)
                
                insights = self._generate_path_insights(sessions, path_patterns, mined_paths)
                
                # å®Œæˆåˆ†æ
                status_text.text(t('analysis.step_completed', 'åˆ†æå®Œæˆ'))
                progress_bar.progress(100)
                
                # å­˜å‚¨åˆ†æç»“æœ
                results = {
                    'sessions': sessions,
                    'path_patterns': path_patterns,
                    'mined_paths': mined_paths,
                    'insights': insights,
                    'config': config,
                    'data_size': len(filtered_data),
                    'analysis_time': datetime.now().isoformat()
                }
                
                # ä½¿ç”¨StateManagerå­˜å‚¨ç»“æœ
                state_manager.set_analysis_results('path', results)
                st.session_state.path_analysis_results = results
                
                st.success(t('analysis.path_complete', 'âœ… è·¯å¾„åˆ†æå®Œæˆ!'))
                
            except Exception as e:
                st.error(f"{t('analysis.analysis_failed', 'è·¯å¾„åˆ†æå¤±è´¥')}: {str(e)}")
                import traceback
                st.text(t('common.detailed_error', 'Detailed error information:'))
                st.text(traceback.format_exc())
    
    def _filter_data_by_time(self, data: pd.DataFrame, date_range) -> pd.DataFrame:
        """æ ¹æ®æ—¶é—´èŒƒå›´ç­›é€‰æ•°æ®"""
        try:
            if not hasattr(date_range, '__len__') or len(date_range) != 2:
                return data
            
            start_date, end_date = date_range
            
            # ç¡®ä¿æœ‰æ—¶é—´åˆ—
            if 'event_datetime' not in data.columns:
                if 'event_timestamp' in data.columns:
                    data['event_datetime'] = pd.to_datetime(data['event_timestamp'], unit='us')
                else:
                    return data
            
            # ç­›é€‰æ—¶é—´èŒƒå›´
            filtered_data = data[
                (data['event_datetime'].dt.date >= start_date) &
                (data['event_datetime'].dt.date <= end_date)
            ].copy()
            
            return filtered_data
            
        except Exception as e:
            st.warning(f"{t('common.filter_failed', 'Filter failed')}: {e}")
            return data
    
    def _generate_path_insights(self, sessions, path_patterns, mined_paths):
        """ç”Ÿæˆè·¯å¾„åˆ†ææ´å¯Ÿ"""
        insights = {
            'basic_stats': {},
            'pattern_insights': [],
            'flow_insights': [],
            'recommendations': []
        }
        
        # åŸºæœ¬ç»Ÿè®¡
        if sessions:
            total_sessions = len(sessions)
            avg_path_length = np.mean([len(s.path_sequence) for s in sessions])
            max_path_length = max([len(s.path_sequence) for s in sessions])
            
            # å¤„ç† PathAnalysisResult å¯¹è±¡
            total_patterns = 0
            if path_patterns and hasattr(path_patterns, 'common_patterns'):
                total_patterns = (
                    len(path_patterns.common_patterns) + 
                    len(path_patterns.anomalous_patterns) + 
                    len(path_patterns.conversion_paths) + 
                    len(path_patterns.exit_patterns)
                )
            
            insights['basic_stats'] = {
                'total_sessions': total_sessions,
                'avg_path_length': avg_path_length,
                'max_path_length': max_path_length,
                'total_patterns': total_patterns
            }
        
        # æ¨¡å¼æ´å¯Ÿ
        if path_patterns and hasattr(path_patterns, 'common_patterns'):
            common_patterns = path_patterns.common_patterns
            conversion_patterns = path_patterns.conversion_paths
            
            if common_patterns:
                top_pattern = max(common_patterns, key=lambda x: x.frequency)
                insights['pattern_insights'].append(f"{t('analysis.most_common_path', 'Most common path')}: {' â†’ '.join(top_pattern.path_sequence)}")
                insights['pattern_insights'].append(f"{t('analysis.frequency', 'Frequency')}: {top_pattern.frequency} {t('common.times', 'times')}")
            
            if conversion_patterns:
                insights['pattern_insights'].append(f"{t('analysis.found_conversion_patterns', 'Found {count} conversion path patterns').format(count=len(conversion_patterns))}")
        
        # æ¨è
        insights['recommendations'] = [
            t('analysis.recommendation_optimize_paths', 'Optimize the most common user paths to improve user experience'),
            t('analysis.recommendation_analyze_anomalies', 'Analyze anomalous path patterns to discover potential user confusion points'),
            t('analysis.recommendation_focus_conversion', 'Focus on conversion path patterns to improve conversion efficiency')
        ]
        
        return insights
    
    def _render_analysis_results(self):
        """æ¸²æŸ“åˆ†æç»“æœ"""
        results = st.session_state.path_analysis_results
        
        if not results:
            st.warning(t('analysis.no_results', 'æ²¡æœ‰åˆ†æç»“æœå¯æ˜¾ç¤º'))
            return
        
        st.markdown("---")
        st.subheader("ğŸ›¤ï¸ " + t('analysis.path_results', 'è·¯å¾„åˆ†æç»“æœ'))
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ğŸ“Š " + t('analysis.overview', 'æ¦‚è§ˆ'),
            "ğŸ—ºï¸ " + t('analysis.path_patterns', 'è·¯å¾„æ¨¡å¼'),
            "ğŸ“ˆ " + t('analysis.visualizations', 'å¯è§†åŒ–'),
            "ğŸ” " + t('analysis.sessions', 'ä¼šè¯è¯¦æƒ…'),
            "ğŸ’¡ " + t('analysis.insights', 'æ´å¯Ÿä¸å»ºè®®')
        ])
        
        with tab1:
            self._render_overview(results)
        
        with tab2:
            self._render_path_patterns(results)
        
        with tab3:
            self._render_visualizations(results)
        
        with tab4:
            self._render_session_details(results)
        
        with tab5:
            self._render_insights_and_recommendations(results)
    
    def _render_overview(self, results: Dict[str, Any]):
        """æ¸²æŸ“æ¦‚è§ˆæ ‡ç­¾é¡µ"""
        st.subheader("ğŸ“Š " + t('analysis.key_metrics', 'å…³é”®æŒ‡æ ‡'))
        
        sessions = results.get('sessions', [])
        path_patterns = results.get('path_patterns', [])
        insights = results.get('insights', {})
        
        if not sessions:
            st.info(t('analysis.no_session_data', 'æš‚æ— ä¼šè¯æ•°æ®'))
            return
        
        # å…³é”®æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        basic_stats = insights.get('basic_stats', {})
        
        with col1:
            st.metric(
                t('analysis.total_sessions', 'æ€»ä¼šè¯æ•°'),
                f"{basic_stats.get('total_sessions', 0):,}",
                help=t('analysis.sessions_help', 'åˆ†æçš„ç”¨æˆ·ä¼šè¯æ€»æ•°')
            )
        
        with col2:
            st.metric(
                t('analysis.avg_path_length', 'å¹³å‡è·¯å¾„é•¿åº¦'),
                f"{basic_stats.get('avg_path_length', 0):.1f}",
                help=t('analysis.path_length_help', 'ç”¨æˆ·è·¯å¾„çš„å¹³å‡æ­¥æ•°')
            )
        
        with col3:
            st.metric(
                t('analysis.max_path_length', 'æœ€å¤§è·¯å¾„é•¿åº¦'),
                f"{basic_stats.get('max_path_length', 0)}",
                help=t('analysis.max_path_help', 'ç”¨æˆ·è·¯å¾„çš„æœ€å¤§æ­¥æ•°')
            )
        
        with col4:
            st.metric(
                t('analysis.total_patterns', 'è¯†åˆ«æ¨¡å¼æ•°'),
                f"{basic_stats.get('total_patterns', 0)}",
                help=t('analysis.patterns_help', 'è¯†åˆ«çš„è·¯å¾„æ¨¡å¼æ€»æ•°')
            )
        
        # è·¯å¾„é•¿åº¦åˆ†å¸ƒ
        st.subheader("ğŸ“ " + t('analysis.path_length_distribution', 'è·¯å¾„é•¿åº¦åˆ†å¸ƒ'))
        
        path_lengths = [len(s.path_sequence) for s in sessions if hasattr(s, 'path_sequence') and s.path_sequence]
        
        if path_lengths:
            fig = px.histogram(
                x=path_lengths,
                nbins=min(20, max(path_lengths)),
                title=t('analysis.path_length_hist', 'ç”¨æˆ·è·¯å¾„é•¿åº¦åˆ†å¸ƒ'),
                labels={'x': t('analysis.path_length', 'è·¯å¾„é•¿åº¦'), 'y': t('analysis.session_count', 'ä¼šè¯æ•°é‡')}
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        # ä¼šè¯æŒç»­æ—¶é—´åˆ†å¸ƒ
        st.subheader("â±ï¸ " + t('analysis.session_duration_distribution', 'ä¼šè¯æ—¶é•¿åˆ†å¸ƒ'))
        
        durations = [s.duration_seconds / 60 for s in sessions if hasattr(s, 'duration_seconds') and s.duration_seconds and s.duration_seconds > 0]  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        if durations:
            fig = px.histogram(
                x=durations,
                nbins=20,
                title=t('analysis.session_duration_hist', 'ä¼šè¯æŒç»­æ—¶é—´åˆ†å¸ƒ'),
                labels={'x': t('analysis.duration_minutes', 'æŒç»­æ—¶é—´(åˆ†é’Ÿ)'), 'y': t('analysis.session_count', 'ä¼šè¯æ•°é‡')}
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_path_patterns(self, results: Dict[str, Any]):
        """æ¸²æŸ“è·¯å¾„æ¨¡å¼æ ‡ç­¾é¡µ"""
        st.subheader("ğŸ—ºï¸ " + t('analysis.identified_patterns', 'è¯†åˆ«çš„è·¯å¾„æ¨¡å¼'))
        
        path_patterns = results.get('path_patterns')
        
        if not path_patterns or not hasattr(path_patterns, 'common_patterns'):
            st.info(t('analysis.no_patterns', 'æš‚æ— è·¯å¾„æ¨¡å¼'))
            return
        
        # è·å–å„ç±»å‹æ¨¡å¼
        pattern_types = {
            'common': path_patterns.common_patterns,
            'conversion': path_patterns.conversion_paths,
            'anomalous': path_patterns.anomalous_patterns,
            'exit': path_patterns.exit_patterns
        }
        
        # æ˜¾ç¤ºå„ç±»å‹æ¨¡å¼
        for pattern_type, patterns in pattern_types.items():
            if not patterns:
                continue
                
            if pattern_type == 'common':
                st.subheader("ğŸ”¥ " + t('analysis.common_patterns', 'å¸¸è§è·¯å¾„æ¨¡å¼'))
            elif pattern_type == 'conversion':
                st.subheader("ğŸ¯ " + t('analysis.conversion_patterns', 'è½¬åŒ–è·¯å¾„æ¨¡å¼'))
            elif pattern_type == 'anomalous':
                st.subheader("âš ï¸ " + t('analysis.anomalous_patterns', 'å¼‚å¸¸è·¯å¾„æ¨¡å¼'))
            elif pattern_type == 'exit':
                st.subheader("ğŸšª " + t('analysis.exit_patterns', 'é€€å‡ºè·¯å¾„æ¨¡å¼'))
            
            # æ˜¾ç¤ºæ¨¡å¼è¡¨æ ¼
            pattern_data = []
            for pattern in patterns[:10]:  # æ˜¾ç¤ºå‰10ä¸ªæ¨¡å¼
                pattern_data.append({
                    t('analysis.path_pattern', 'Path Pattern'): ' â†’ '.join(pattern.path_sequence),
                    t('analysis.frequency', 'Frequency'): pattern.frequency,
                    t('analysis.user_count', 'User Count'): pattern.user_count,
                    t('analysis.avg_duration_minutes', 'Avg Duration (minutes)'): f"{pattern.avg_duration/60:.1f}" if pattern.avg_duration else 'N/A',
                    t('analysis.conversion_rate', 'Conversion Rate'): f"{pattern.conversion_rate:.1%}" if pattern.conversion_rate else 'N/A'
                })
            
            if pattern_data:
                df = pd.DataFrame(pattern_data)
                st.dataframe(df, use_container_width=True)
                
                if len(patterns) > 10:
                    st.info(t('analysis.showing_top_patterns', 'Showing top 10 patterns, found {count} {type} patterns').format(count=len(patterns), type=pattern_type))
    
    def _render_visualizations(self, results: Dict[str, Any]):
        """æ¸²æŸ“å¯è§†åŒ–æ ‡ç­¾é¡µ"""
        st.subheader("ğŸ“ˆ " + t('analysis.path_visualizations', 'è·¯å¾„å¯è§†åŒ–'))
        
        sessions = results.get('sessions', [])
        path_patterns = results.get('path_patterns', [])
        
        if not sessions:
            st.info(t('analysis.no_visualization_data', 'æš‚æ— å¯è§†åŒ–æ•°æ®'))
            return
        
        # è·¯å¾„æµå‘å›¾
        self._create_path_flow_chart(sessions)
        
        # æ¨¡å¼é¢‘æ¬¡å›¾
        if path_patterns:
            self._create_pattern_frequency_chart(path_patterns)
        
        # è·¯å¾„æ¡‘åŸºå›¾
        self._create_path_sankey_diagram(sessions)
    
    def _create_path_flow_chart(self, sessions):
        """åˆ›å»ºè·¯å¾„æµå‘å›¾"""
        st.subheader("ğŸŒŠ " + t('analysis.path_flow_chart', 'è·¯å¾„æµå‘å›¾'))
        
        # ç»Ÿè®¡äº‹ä»¶è½¬æ¢
        transitions = {}
        
        for session in sessions:
            if hasattr(session, 'path_sequence') and session.path_sequence:
                path = session.path_sequence
                for i in range(len(path) - 1):
                    current = path[i]
                    next_event = path[i + 1]
                    transition = f"{current} â†’ {next_event}"
                    transitions[transition] = transitions.get(transition, 0) + 1
        
        if transitions:
            # å–å‰20ä¸ªæœ€å¸¸è§çš„è½¬æ¢
            top_transitions = sorted(transitions.items(), key=lambda x: x[1], reverse=True)[:20]
            
            transition_names = [item[0] for item in top_transitions]
            transition_counts = [item[1] for item in top_transitions]
            
            fig = px.bar(
                x=transition_counts,
                y=transition_names,
                orientation='h',
                title=t('analysis.top_transitions', 'æœ€å¸¸è§çš„è·¯å¾„è½¬æ¢'),
                labels={'x': t('analysis.transition_count', 'è½¬æ¢æ¬¡æ•°'), 'y': t('analysis.transition', 'è½¬æ¢')}
            )
            fig.update_layout(height=600)
            st.plotly_chart(fig, use_container_width=True)
    
    def _create_pattern_frequency_chart(self, path_patterns):
        """åˆ›å»ºæ¨¡å¼é¢‘æ¬¡å›¾"""
        st.subheader("ğŸ“Š " + t('analysis.pattern_frequency_chart', 'æ¨¡å¼é¢‘æ¬¡å›¾'))
        
        if not path_patterns or not hasattr(path_patterns, 'common_patterns'):
            st.info(t('analysis.no_pattern_data', 'æš‚æ— æ¨¡å¼æ•°æ®'))
            return
        
        # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
        pattern_type_counts = {
            'common': len(path_patterns.common_patterns),
            'conversion': len(path_patterns.conversion_paths),
            'anomalous': len(path_patterns.anomalous_patterns),
            'exit': len(path_patterns.exit_patterns)
        }
        
        # è¿‡æ»¤æ‰è®¡æ•°ä¸º0çš„ç±»å‹
        pattern_type_counts = {k: v for k, v in pattern_type_counts.items() if v > 0}
        
        if pattern_type_counts:
            type_names = list(pattern_type_counts.keys())
            type_counts = list(pattern_type_counts.values())
            
            fig = px.pie(
                values=type_counts,
                names=type_names,
                title=t('analysis.pattern_type_distribution', 'è·¯å¾„æ¨¡å¼ç±»å‹åˆ†å¸ƒ')
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # æ˜¾ç¤ºé¢‘æ¬¡æœ€é«˜çš„æ¨¡å¼
        all_patterns = (
            path_patterns.common_patterns + 
            path_patterns.conversion_paths + 
            path_patterns.anomalous_patterns + 
            path_patterns.exit_patterns
        )
        
        if all_patterns:
            top_patterns = sorted(all_patterns, key=lambda x: x.frequency, reverse=True)[:10]
            
            pattern_names = [' â†’ '.join(p.path_sequence[:3]) + '...' if len(p.path_sequence) > 3 
                           else ' â†’ '.join(p.path_sequence) for p in top_patterns]
            frequencies = [p.frequency for p in top_patterns]
            
            fig = px.bar(
                x=frequencies,
                y=pattern_names,
                orientation='h',
                title=t('analysis.top_pattern_frequencies', 'é¢‘æ¬¡æœ€é«˜çš„è·¯å¾„æ¨¡å¼'),
                labels={'x': t('analysis.frequency', 'é¢‘æ¬¡'), 'y': t('analysis.pattern', 'æ¨¡å¼')}
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
    
    def _create_path_sankey_diagram(self, sessions):
        """åˆ›å»ºè·¯å¾„æ¡‘åŸºå›¾"""
        st.subheader("ğŸŒŠ " + t('analysis.path_sankey', 'è·¯å¾„æ¡‘åŸºå›¾'))
        
        # é™åˆ¶æ˜¾ç¤ºæ­¥æ•°é¿å…å›¾è¡¨è¿‡äºå¤æ‚
        max_steps = 5
        
        # ç»Ÿè®¡æ¯æ­¥çš„äº‹ä»¶åˆ†å¸ƒ
        step_events = {}
        
        for session in sessions:
            if hasattr(session, 'path_sequence') and session.path_sequence:
                path = session.path_sequence[:max_steps]  # åªå–å‰å‡ æ­¥
                for step, event in enumerate(path):
                    if step not in step_events:
                        step_events[step] = {}
                    step_events[step][event] = step_events[step].get(event, 0) + 1
        
        if len(step_events) > 1:
            # æ„å»ºæ¡‘åŸºå›¾æ•°æ®
            all_events = set()
            for step_data in step_events.values():
                all_events.update(step_data.keys())
            
            # ä¸ºæ¯ä¸ªäº‹ä»¶åˆ›å»ºå”¯ä¸€æ ‡è¯†
            event_to_id = {event: i for i, event in enumerate(all_events)}
            
            # æ„å»ºè¿æ¥
            source = []
            target = []
            value = []
            
            for session in sessions:
                if hasattr(session, 'path_sequence') and session.path_sequence:
                    path = session.path_sequence[:max_steps]
                    for i in range(len(path) - 1):
                        current_event = path[i]
                        next_event = path[i + 1]
                        
                        source.append(event_to_id[current_event])
                        target.append(event_to_id[next_event])
                    
            # ç»Ÿè®¡è¿æ¥æƒé‡
            connections = {}
            if source and target and len(source) == len(target):
                for s, target_val in zip(source, target):
                    key = (s, target_val)
                    connections[key] = connections.get(key, 0) + 1
            
            # å‡†å¤‡æœ€ç»ˆæ•°æ®
            final_source = []
            final_target = []
            final_value = []
            
            if connections:
                for connection_key, weight in connections.items():
                    if isinstance(connection_key, tuple) and len(connection_key) == 2:
                        s, target_node = connection_key
                        if weight > 1:  # åªæ˜¾ç¤ºå‡ºç°å¤šæ¬¡çš„è¿æ¥
                            final_source.append(s)
                            final_target.append(target_node)
                            final_value.append(weight)
            
            if final_source:
                # åˆ›å»ºæ¡‘åŸºå›¾
                fig = go.Figure(data=[go.Sankey(
                    node=dict(
                        pad=15,
                        thickness=20,
                        line=dict(color="black", width=0.5),
                        label=list(all_events),
                    ),
                    link=dict(
                        source=final_source,
                        target=final_target,
                        value=final_value
                    )
                )])
                
                fig.update_layout(
                    title_text=t('analysis.user_path_flow', 'ç”¨æˆ·è·¯å¾„æµå‘'),
                    font_size=10,
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
    
    def _render_session_details(self, results: Dict[str, Any]):
        """æ¸²æŸ“ä¼šè¯è¯¦æƒ…æ ‡ç­¾é¡µ"""
        st.subheader("ğŸ” " + t('analysis.session_details', 'ä¼šè¯è¯¦æƒ…'))
        
        sessions = results.get('sessions', [])
        
        if not sessions:
            st.info(t('analysis.no_session_details', 'æš‚æ— ä¼šè¯è¯¦æƒ…'))
            return
        
        # ä¼šè¯ç­›é€‰
        col1, col2 = st.columns(2)
        
        with col1:
            min_length = st.slider(
                t('analysis.filter_min_length', 'æœ€å°è·¯å¾„é•¿åº¦'),
                min_value=1,
                max_value=20,
                value=1,
                key='session_filter_min'
            )
        
        with col2:
            max_length = st.slider(
                t('analysis.filter_max_length', 'æœ€å¤§è·¯å¾„é•¿åº¦'),
                min_value=2,
                max_value=50,
                value=20,
                key='session_filter_max'
            )
        
        # ç­›é€‰ä¼šè¯
        filtered_sessions = [
            s for s in sessions 
            if min_length <= len(s.path_sequence) <= max_length
        ]
        
        st.info(t('analysis.showing_sessions', 'Showing {shown} sessions (out of {total} total)').format(shown=len(filtered_sessions), total=len(sessions)))
        
        # æ˜¾ç¤ºä¼šè¯æ ·æœ¬
        session_data = []
        for i, session in enumerate(filtered_sessions[:20]):  # æ˜¾ç¤ºå‰20ä¸ªä¼šè¯
            path_text = ' â†’ '.join(session.path_sequence)
            session_data.append({
                t('analysis.session_id', 'Session ID'): session.session_id,
                t('analysis.user_id', 'User ID'): session.user_id,
                t('analysis.path_length', 'Path Length'): len(session.path_sequence),
                t('analysis.duration_minutes', 'Duration (minutes)'): f"{session.duration_seconds/60:.1f}" if session.duration_seconds else 'N/A',
                t('analysis.page_views', 'Page Views'): session.page_views,
                t('analysis.conversions', 'Conversions'): session.conversions,
                t('analysis.path_sequence', 'Path Sequence'): path_text[:100] + '...' if len(path_text) > 100 else path_text
            })
        
        if session_data:
            df = pd.DataFrame(session_data)
            st.dataframe(df, use_container_width=True)
        
        if len(filtered_sessions) > 20:
            st.info(t('analysis.showing_top_sessions', 'Showing top 20 sessions, filtered {count} sessions').format(count=len(filtered_sessions)))
    
    def _render_insights_and_recommendations(self, results: Dict[str, Any]):
        """æ¸²æŸ“æ´å¯Ÿä¸å»ºè®®æ ‡ç­¾é¡µ"""
        st.subheader("ğŸ’¡ " + t('analysis.insights_and_recommendations', 'æ´å¯Ÿä¸å»ºè®®'))
        
        insights = results.get('insights', {})
        
        # æ¨¡å¼æ´å¯Ÿ
        pattern_insights = insights.get('pattern_insights', [])
        if pattern_insights:
            st.subheader("ğŸ” " + t('analysis.pattern_insights', 'æ¨¡å¼æ´å¯Ÿ'))
            for insight in pattern_insights:
                st.info(insight)
        
        # æµç¨‹æ´å¯Ÿ
        flow_insights = insights.get('flow_insights', [])
        if flow_insights:
            st.subheader("ğŸŒŠ " + t('analysis.flow_insights', 'æµç¨‹æ´å¯Ÿ'))
            for insight in flow_insights:
                st.success(insight)
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = insights.get('recommendations', [])
        if recommendations:
            st.subheader("ğŸ“‹ " + t('analysis.optimization_recommendations', 'ä¼˜åŒ–å»ºè®®'))
            for i, recommendation in enumerate(recommendations, 1):
                st.write(f"**{i}.** {recommendation}")
        
        # åŸºäºæ•°æ®çš„é¢å¤–æ´å¯Ÿ
        sessions = results.get('sessions', [])
        if sessions:
            st.subheader("ğŸ“Š " + t('analysis.additional_insights', 'é¢å¤–æ´å¯Ÿ'))
            
            # è®¡ç®—ä¸€äº›é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
            total_sessions = len(sessions)
            conversion_sessions = len([s for s in sessions if s.conversions > 0])
            avg_conversions = np.mean([s.conversions for s in sessions])
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(t('analysis.conversion_session_ratio', 'Conversion Session Ratio'), f"{conversion_sessions/total_sessions:.1%}")
                st.metric(t('analysis.avg_conversions', 'Average Conversions'), f"{avg_conversions:.2f}")
            
            with col2:
                # è·¯å¾„å¤šæ ·æ€§åˆ†æ
                unique_paths = set()
                for session in sessions:
                    path_str = ' â†’ '.join(session.path_sequence)
                    unique_paths.add(path_str)
                
                path_diversity = len(unique_paths) / total_sessions if total_sessions > 0 else 0
                st.metric(t('analysis.path_diversity', 'Path Diversity'), f"{path_diversity:.2f}")
                
                # å¹³å‡é¡µé¢æµè§ˆæ•°
                avg_page_views = np.mean([s.page_views for s in sessions])
                st.metric(t('analysis.avg_page_views', 'Average Page Views'), f"{avg_page_views:.1f}")


@render_data_status_check
def show_path_analysis_page():
    """æ˜¾ç¤ºè·¯å¾„åˆ†æé¡µé¢ - ä¿æŒå‘åå…¼å®¹"""
    page = PathAnalysisPage()
    page.render()
