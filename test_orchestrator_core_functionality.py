"""
æ™ºèƒ½ä½“ç¼–æ’å™¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•

æµ‹è¯•ç¼–æ’å™¨çš„æ ¸å¿ƒé€»è¾‘ï¼Œä¸ä¾èµ–CrewAIçš„å®Œæ•´å¯¼å…¥ï¼š
- ä»»åŠ¡ä¾èµ–å…³ç³»ç®¡ç†
- æ‰§è¡Œé¡ºåºè®¡ç®—
- çŠ¶æ€ç›‘æ§
- é…ç½®ç®¡ç†
"""

import os
import sys
import json
import tempfile
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


class AgentType(Enum):
    """æ™ºèƒ½ä½“ç±»å‹æšä¸¾"""
    DATA_PROCESSOR = "data_processor"
    EVENT_ANALYST = "event_analyst"
    RETENTION_ANALYST = "retention_analyst"
    CONVERSION_ANALYST = "conversion_analyst"
    SEGMENTATION_ANALYST = "segmentation_analyst"
    PATH_ANALYST = "path_analyst"
    REPORT_GENERATOR = "report_generator"


@dataclass
class TaskResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    task_id: str
    agent_type: AgentType
    status: TaskStatus
    result_data: Dict[str, Any]
    execution_time: float
    error_message: Optional[str] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()


@dataclass
class AgentTaskDefinition:
    """æ™ºèƒ½ä½“ä»»åŠ¡å®šä¹‰"""
    task_id: str
    agent_type: AgentType
    description: str
    expected_output: str
    dependencies: List[str]
    parameters: Dict[str, Any]
    priority: int = 1
    timeout: int = 300
    retry_count: int = 2


class MockAgent:
    """æ¨¡æ‹Ÿæ™ºèƒ½ä½“ç±»"""
    
    def __init__(self, agent_type: AgentType):
        self.agent_type = agent_type
    
    def get_agent(self):
        return self
    
    def process_ga4_data(self, file_path: str):
        """æ¨¡æ‹Ÿæ•°æ®å¤„ç†"""
        return {
            "status": "success",
            "raw_data_count": 100,
            "processed_data_count": 95,
            "data": {"processed": True}
        }
    
    def comprehensive_event_analysis(self):
        """æ¨¡æ‹Ÿäº‹ä»¶åˆ†æ"""
        return {
            "status": "success",
            "frequency_analysis": {
                "summary": {"total_events_analyzed": 5}
            },
            "key_event_analysis": {
                "summary": {"total_events_analyzed": 3}
            }
        }
    
    def comprehensive_retention_analysis(self):
        """æ¨¡æ‹Ÿç•™å­˜åˆ†æ"""
        return {
            "status": "success",
            "retention_rates": {"day_1": 0.8, "day_7": 0.6}
        }
    
    def comprehensive_conversion_analysis(self):
        """æ¨¡æ‹Ÿè½¬åŒ–åˆ†æ"""
        return {
            "status": "success",
            "conversion_funnel": {"step_1": 1000, "step_2": 800, "step_3": 600}
        }
    
    def comprehensive_segmentation_analysis(self):
        """æ¨¡æ‹Ÿç”¨æˆ·åˆ†ç¾¤åˆ†æ"""
        return {
            "status": "success",
            "segments": {"segment_1": 500, "segment_2": 300}
        }
    
    def comprehensive_path_analysis(self):
        """æ¨¡æ‹Ÿè·¯å¾„åˆ†æ"""
        return {
            "status": "success",
            "common_paths": ["home->product->purchase", "home->about->contact"]
        }
    
    def generate_comprehensive_report(self, analysis_results):
        """æ¨¡æ‹ŸæŠ¥å‘Šç”Ÿæˆ"""
        return {
            "status": "success",
            "report": {"summary": "ç»¼åˆåˆ†ææŠ¥å‘Š", "insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"]}
        }


class SimplifiedOrchestrator:
    """ç®€åŒ–çš„æ™ºèƒ½ä½“ç¼–æ’å™¨ï¼ˆä¸ä¾èµ–CrewAIï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼–æ’å™¨"""
        self.agents = {}
        self.tasks = {}
        self.task_results = {}
        self.execution_history = []
        
        # åˆå§‹åŒ–æ¨¡æ‹Ÿæ™ºèƒ½ä½“
        self._initialize_mock_agents()
        
        # å®šä¹‰é»˜è®¤ä»»åŠ¡æµç¨‹
        self._define_default_workflow()
    
    def _initialize_mock_agents(self):
        """åˆå§‹åŒ–æ¨¡æ‹Ÿæ™ºèƒ½ä½“"""
        for agent_type in AgentType:
            self.agents[agent_type] = MockAgent(agent_type)
    
    def _define_default_workflow(self):
        """å®šä¹‰é»˜è®¤çš„åˆ†æå·¥ä½œæµç¨‹"""
        self.tasks = {
            "data_processing": AgentTaskDefinition(
                task_id="data_processing",
                agent_type=AgentType.DATA_PROCESSOR,
                description="è§£æå’Œé¢„å¤„ç†GA4äº‹ä»¶æ•°æ®ï¼Œç¡®ä¿æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§",
                expected_output="å¤„ç†åçš„ç»“æ„åŒ–æ•°æ®ï¼ŒåŒ…æ‹¬äº‹ä»¶ã€ç”¨æˆ·å’Œä¼šè¯ä¿¡æ¯",
                dependencies=[],
                parameters={"file_path": None},
                priority=1
            ),
            
            "event_analysis": AgentTaskDefinition(
                task_id="event_analysis",
                agent_type=AgentType.EVENT_ANALYST,
                description="åˆ†æç”¨æˆ·äº‹ä»¶æ¨¡å¼ï¼ŒåŒ…æ‹¬é¢‘æ¬¡ç»Ÿè®¡ã€è¶‹åŠ¿åˆ†æå’Œå…³è”æ€§åˆ†æ",
                expected_output="äº‹ä»¶åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬å…³é”®äº‹ä»¶è¯†åˆ«å’Œè¡Œä¸ºæ¨¡å¼æ´å¯Ÿ",
                dependencies=["data_processing"],
                parameters={},
                priority=2
            ),
            
            "retention_analysis": AgentTaskDefinition(
                task_id="retention_analysis",
                agent_type=AgentType.RETENTION_ANALYST,
                description="è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡ï¼Œåˆ†æç”¨æˆ·ç”Ÿå‘½å‘¨æœŸå’Œæµå¤±æ¨¡å¼",
                expected_output="ç•™å­˜åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ç•™å­˜æ›²çº¿å’Œæµå¤±é¢„æµ‹",
                dependencies=["data_processing"],
                parameters={},
                priority=2
            ),
            
            "conversion_analysis": AgentTaskDefinition(
                task_id="conversion_analysis",
                agent_type=AgentType.CONVERSION_ANALYST,
                description="æ„å»ºè½¬åŒ–æ¼æ–—ï¼Œè¯†åˆ«è½¬åŒ–ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼š",
                expected_output="è½¬åŒ–åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬æ¼æ–—åˆ†æå’Œä¼˜åŒ–å»ºè®®",
                dependencies=["data_processing"],
                parameters={},
                priority=2
            ),
            
            "segmentation_analysis": AgentTaskDefinition(
                task_id="segmentation_analysis",
                agent_type=AgentType.SEGMENTATION_ANALYST,
                description="åŸºäºç”¨æˆ·è¡Œä¸ºå’Œå±æ€§è¿›è¡Œæ™ºèƒ½åˆ†ç¾¤ï¼Œç”Ÿæˆç”¨æˆ·ç”»åƒ",
                expected_output="ç”¨æˆ·åˆ†ç¾¤æŠ¥å‘Šï¼ŒåŒ…æ‹¬ç¾¤ä½“ç‰¹å¾å’Œè¥é”€å»ºè®®",
                dependencies=["data_processing"],
                parameters={},
                priority=3
            ),
            
            "path_analysis": AgentTaskDefinition(
                task_id="path_analysis",
                agent_type=AgentType.PATH_ANALYST,
                description="åˆ†æç”¨æˆ·è¡Œä¸ºè·¯å¾„ï¼Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒæµç¨‹",
                expected_output="è·¯å¾„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ç”¨æˆ·æµç¨‹å›¾å’Œä½“éªŒä¼˜åŒ–å»ºè®®",
                dependencies=["data_processing"],
                parameters={},
                priority=3
            ),
            
            "report_generation": AgentTaskDefinition(
                task_id="report_generation",
                agent_type=AgentType.REPORT_GENERATOR,
                description="æ±‡æ€»æ‰€æœ‰åˆ†æç»“æœï¼Œç”Ÿæˆç»¼åˆæ€§çš„ä¸šåŠ¡æ´å¯ŸæŠ¥å‘Š",
                expected_output="ç»¼åˆåˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬å…³é”®æŒ‡æ ‡ã€æ´å¯Ÿå’Œè¡ŒåŠ¨å»ºè®®",
                dependencies=["event_analysis", "retention_analysis", "conversion_analysis", 
                            "segmentation_analysis", "path_analysis"],
                parameters={},
                priority=4
            )
        }
    
    def get_task_execution_order(self) -> List[str]:
        """æ ¹æ®ä¾èµ–å…³ç³»å’Œä¼˜å…ˆçº§è®¡ç®—ä»»åŠ¡æ‰§è¡Œé¡ºåº"""
        # æ‹“æ‰‘æ’åºç®—æ³•
        in_degree = {task_id: 0 for task_id in self.tasks}
        
        # è®¡ç®—å…¥åº¦
        for task_id, task_def in self.tasks.items():
            for dep in task_def.dependencies:
                if dep in in_degree:
                    in_degree[task_id] += 1
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºçš„é˜Ÿåˆ—
        queue = []
        for task_id, degree in in_degree.items():
            if degree == 0:
                queue.append((self.tasks[task_id].priority, task_id))
        
        queue.sort()  # æŒ‰ä¼˜å…ˆçº§æ’åº
        
        execution_order = []
        
        while queue:
            _, current_task = queue.pop(0)
            execution_order.append(current_task)
            
            # æ›´æ–°ä¾èµ–æ­¤ä»»åŠ¡çš„å…¶ä»–ä»»åŠ¡
            for task_id, task_def in self.tasks.items():
                if current_task in task_def.dependencies:
                    in_degree[task_id] -= 1
                    if in_degree[task_id] == 0:
                        queue.append((task_def.priority, task_id))
                        queue.sort()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¾ªç¯ä¾èµ–
        if len(execution_order) != len(self.tasks):
            remaining_tasks = set(self.tasks.keys()) - set(execution_order)
            raise ValueError(f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œæ— æ³•æ‰§è¡Œçš„ä»»åŠ¡: {remaining_tasks}")
        
        return execution_order
    
    def execute_single_task(self, task_id: str, **kwargs) -> TaskResult:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        try:
            start_time = datetime.now()
            
            if task_id not in self.tasks:
                raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            
            task_def = self.tasks[task_id]
            agent = self.agents[task_def.agent_type]
            
            # æ£€æŸ¥ä¾èµ–ä»»åŠ¡æ˜¯å¦å®Œæˆ
            for dep_task_id in task_def.dependencies:
                if dep_task_id not in self.task_results or \
                   self.task_results[dep_task_id].status != TaskStatus.COMPLETED:
                    raise ValueError(f"ä¾èµ–ä»»åŠ¡æœªå®Œæˆ: {dep_task_id}")
            
            # åˆå¹¶å‚æ•°
            parameters = {**task_def.parameters, **kwargs}
            
            # æ‰§è¡Œä»»åŠ¡
            if task_id == "data_processing":
                result_data = agent.process_ga4_data(parameters.get("file_path"))
            elif task_id == "event_analysis":
                result_data = agent.comprehensive_event_analysis()
            elif task_id == "retention_analysis":
                result_data = agent.comprehensive_retention_analysis()
            elif task_id == "conversion_analysis":
                result_data = agent.comprehensive_conversion_analysis()
            elif task_id == "segmentation_analysis":
                result_data = agent.comprehensive_segmentation_analysis()
            elif task_id == "path_analysis":
                result_data = agent.comprehensive_path_analysis()
            elif task_id == "report_generation":
                # æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
                analysis_results = {
                    tid: result.result_data for tid, result in self.task_results.items()
                    if result.status == TaskStatus.COMPLETED
                }
                result_data = agent.generate_comprehensive_report(analysis_results)
            else:
                raise ValueError(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task_id}")
            
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            # åˆ›å»ºä»»åŠ¡ç»“æœ
            task_result = TaskResult(
                task_id=task_id,
                agent_type=task_def.agent_type,
                status=TaskStatus.COMPLETED if result_data.get("status") == "success" else TaskStatus.FAILED,
                result_data=result_data,
                execution_time=execution_time,
                error_message=result_data.get("error_message") if result_data.get("status") != "success" else None,
                timestamp=end_time
            )
            
            # ä¿å­˜ä»»åŠ¡ç»“æœ
            self.task_results[task_id] = task_result
            
            return task_result
            
        except Exception as e:
            task_result = TaskResult(
                task_id=task_id,
                agent_type=task_def.agent_type,
                status=TaskStatus.FAILED,
                result_data={},
                execution_time=0,
                error_message=str(e),
                timestamp=datetime.now()
            )
            
            self.task_results[task_id] = task_result
            return task_result
    
    def get_execution_status(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡ŒçŠ¶æ€"""
        total_tasks = len(self.tasks)
        completed_tasks = sum(1 for result in self.task_results.values() 
                            if result.status == TaskStatus.COMPLETED)
        failed_tasks = sum(1 for result in self.task_results.values() 
                         if result.status == TaskStatus.FAILED)
        
        return {
            "total_tasks": total_tasks,
            "completed_tasks": completed_tasks,
            "failed_tasks": failed_tasks,
            "pending_tasks": total_tasks - len(self.task_results),
            "completion_rate": completed_tasks / total_tasks if total_tasks > 0 else 0,
            "task_results": {
                task_id: {
                    "status": result.status.value,
                    "execution_time": result.execution_time,
                    "timestamp": result.timestamp.isoformat(),
                    "error_message": result.error_message
                }
                for task_id, result in self.task_results.items()
            }
        }
    
    def reset_execution_state(self):
        """é‡ç½®æ‰§è¡ŒçŠ¶æ€"""
        self.task_results.clear()
    
    def export_configuration(self) -> Dict[str, Any]:
        """å¯¼å‡ºé…ç½®"""
        return {
            "tasks": {
                task_id: asdict(task_def) 
                for task_id, task_def in self.tasks.items()
            },
            "agents": [agent_type.value for agent_type in self.agents.keys()],
            "execution_history": self.execution_history
        }


def test_orchestrator_core_functionality():
    """æµ‹è¯•ç¼–æ’å™¨æ ¸å¿ƒåŠŸèƒ½"""
    print("æ™ºèƒ½ä½“ç¼–æ’å™¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºç¼–æ’å™¨
    orchestrator = SimplifiedOrchestrator()
    
    # æµ‹è¯•1: åˆå§‹åŒ–éªŒè¯
    print("\n1. åˆå§‹åŒ–éªŒè¯")
    print(f"âœ“ æ™ºèƒ½ä½“æ•°é‡: {len(orchestrator.agents)}")
    print(f"âœ“ ä»»åŠ¡æ•°é‡: {len(orchestrator.tasks)}")
    
    # æµ‹è¯•2: ä»»åŠ¡æ‰§è¡Œé¡ºåº
    print("\n2. ä»»åŠ¡æ‰§è¡Œé¡ºåºè®¡ç®—")
    execution_order = orchestrator.get_task_execution_order()
    print(f"âœ“ æ‰§è¡Œé¡ºåº: {' -> '.join(execution_order)}")
    
    # éªŒè¯ä¾èµ–å…³ç³»
    print("\n3. ä¾èµ–å…³ç³»éªŒè¯")
    for i, task_id in enumerate(execution_order):
        task_def = orchestrator.tasks[task_id]
        for dep in task_def.dependencies:
            dep_index = execution_order.index(dep)
            if dep_index >= i:
                print(f"âœ— ä¾èµ–å…³ç³»é”™è¯¯: {task_id} ä¾èµ– {dep}")
                return False
    print("âœ“ æ‰€æœ‰ä¾èµ–å…³ç³»æ­£ç¡®")
    
    # æµ‹è¯•4: å•ä¸ªä»»åŠ¡æ‰§è¡Œ
    print("\n4. å•ä¸ªä»»åŠ¡æ‰§è¡Œæµ‹è¯•")
    
    # æ‰§è¡Œæ•°æ®å¤„ç†ä»»åŠ¡
    result = orchestrator.execute_single_task("data_processing", file_path="/test/file.ndjson")
    print(f"âœ“ æ•°æ®å¤„ç†ä»»åŠ¡: {result.status.value} (è€—æ—¶: {result.execution_time:.3f}s)")
    
    # æ‰§è¡Œäº‹ä»¶åˆ†æä»»åŠ¡
    result = orchestrator.execute_single_task("event_analysis")
    print(f"âœ“ äº‹ä»¶åˆ†æä»»åŠ¡: {result.status.value} (è€—æ—¶: {result.execution_time:.3f}s)")
    
    # æµ‹è¯•5: ä¾èµ–æ£€æŸ¥
    print("\n5. ä¾èµ–æ£€æŸ¥æµ‹è¯•")
    orchestrator.reset_execution_state()
    
    try:
        result = orchestrator.execute_single_task("event_analysis")
        if result.status == TaskStatus.FAILED and "ä¾èµ–ä»»åŠ¡æœªå®Œæˆ" in str(result.error_message):
            print(f"âœ“ æ­£ç¡®æ£€æµ‹ä¾èµ–ç¼ºå¤±: {result.error_message}")
        else:
            print("âœ— åº”è¯¥æ£€æµ‹åˆ°ä¾èµ–ç¼ºå¤±")
            return False
    except ValueError as e:
        print(f"âœ“ æ­£ç¡®æ£€æµ‹ä¾èµ–ç¼ºå¤±: {e}")
    
    # æµ‹è¯•6: å®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡Œ
    print("\n6. å®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡Œ")
    orchestrator.reset_execution_state()
    
    for task_id in execution_order:
        result = orchestrator.execute_single_task(task_id, file_path="/test/file.ndjson")
        print(f"  - {task_id}: {result.status.value}")
    
    # æµ‹è¯•7: æ‰§è¡ŒçŠ¶æ€ç›‘æ§
    print("\n7. æ‰§è¡ŒçŠ¶æ€ç›‘æ§")
    status = orchestrator.get_execution_status()
    print(f"âœ“ å®Œæˆç‡: {status['completion_rate']:.1%}")
    print(f"âœ“ å·²å®Œæˆ: {status['completed_tasks']}/{status['total_tasks']}")
    
    # æµ‹è¯•8: é…ç½®å¯¼å‡º
    print("\n8. é…ç½®å¯¼å‡ºæµ‹è¯•")
    config = orchestrator.export_configuration()
    print(f"âœ“ å¯¼å‡ºä»»åŠ¡é…ç½®: {len(config['tasks'])}ä¸ª")
    print(f"âœ“ å¯¼å‡ºæ™ºèƒ½ä½“é…ç½®: {len(config['agents'])}ä¸ª")
    
    # æµ‹è¯•9: å¾ªç¯ä¾èµ–æ£€æµ‹
    print("\n9. å¾ªç¯ä¾èµ–æ£€æµ‹")
    
    # ä¿å­˜åŸå§‹ä¾èµ–
    original_deps = orchestrator.tasks["event_analysis"].dependencies.copy()
    
    try:
        # åˆ›å»ºå¾ªç¯ä¾èµ–
        orchestrator.tasks["event_analysis"].dependencies.append("retention_analysis")
        orchestrator.tasks["retention_analysis"].dependencies.append("event_analysis")
        
        orchestrator.get_task_execution_order()
        print("âœ— åº”è¯¥æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–")
        return False
    except ValueError as e:
        print(f"âœ“ æ­£ç¡®æ£€æµ‹å¾ªç¯ä¾èµ–: {e}")
    finally:
        # æ¢å¤åŸå§‹ä¾èµ–
        orchestrator.tasks["event_analysis"].dependencies = original_deps
        orchestrator.tasks["retention_analysis"].dependencies = ["data_processing"]
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)
    
    return True


if __name__ == "__main__":
    test_orchestrator_core_functionality()