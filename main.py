"""
ç”¨æˆ·è¡Œä¸ºåˆ†ææ™ºèƒ½ä½“å¹³å°ä¸»å…¥å£
åŸºäºCrewAIå’ŒStreamlitçš„å¤šæ™ºèƒ½ä½“åä½œåˆ†æç³»ç»Ÿ
"""

import streamlit as st
import sys
import os
import pandas as pd
import json
from pathlib import Path
from typing import Optional, Dict, Any
import time
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.settings import settings, validate_config
from utils.logger import setup_logger
from tools.ga4_data_parser import GA4DataParser
from tools.data_validator import DataValidator
from tools.data_storage_manager import DataStorageManager
from engines.event_analysis_engine import EventAnalysisEngine
from engines.retention_analysis_engine import RetentionAnalysisEngine
from engines.conversion_analysis_engine import ConversionAnalysisEngine
from engines.user_segmentation_engine import UserSegmentationEngine
from engines.path_analysis_engine import PathAnalysisEngine
from visualization.chart_generator import ChartGenerator
from visualization.advanced_visualizer import AdvancedVisualizer
from utils.report_exporter import ReportExporter
from utils.config_manager import config_manager
from system.integration_manager import IntegrationManager, WorkflowConfig

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title=settings.app_title,
    page_icon=settings.app_icon,
    layout="wide",
    initial_sidebar_state="expanded"
)


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger()
    
    # éªŒè¯é…ç½®
    if not validate_config():
        st.error("âš ï¸ ç³»ç»Ÿé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„APIé…ç½®")
        st.stop()
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    initialize_session_state()
    
    # åº”ç”¨æ ‡é¢˜
    st.title(f"{settings.app_icon} {settings.app_title}")
    st.markdown("---")
    
    # ä¾§è¾¹æ å¯¼èˆª
    with st.sidebar:
        st.header("ğŸš€ åŠŸèƒ½å¯¼èˆª")
        
        # æ˜¾ç¤ºæ•°æ®çŠ¶æ€
        show_data_status()
        
        page = st.selectbox(
            "é€‰æ‹©åŠŸèƒ½æ¨¡å—",
            [
                "ğŸ“ æ•°æ®ä¸Šä¼ ",
                "ğŸš€ æ™ºèƒ½åˆ†æ",
                "ğŸ“Š äº‹ä»¶åˆ†æ", 
                "ğŸ“ˆ ç•™å­˜åˆ†æ",
                "ğŸ”„ è½¬åŒ–åˆ†æ",
                "ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤",
                "ğŸ›¤ï¸ è·¯å¾„åˆ†æ",
                "ğŸ“‹ ç»¼åˆæŠ¥å‘Š",
                "âš™ï¸ ç³»ç»Ÿè®¾ç½®"
            ]
        )
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if page == "ğŸ“ æ•°æ®ä¸Šä¼ ":
        show_data_upload_page()
        
    elif page == "ğŸš€ æ™ºèƒ½åˆ†æ":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_intelligent_analysis_page()
        
    elif page == "ğŸ“Š äº‹ä»¶åˆ†æ":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_event_analysis_page()
        
    elif page == "ğŸ“ˆ ç•™å­˜åˆ†æ":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_retention_analysis_page()
        
    elif page == "ğŸ”„ è½¬åŒ–åˆ†æ":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_conversion_analysis_page()
        
    elif page == "ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_user_segmentation_page()
        
    elif page == "ğŸ›¤ï¸ è·¯å¾„åˆ†æ":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_path_analysis_page()
        
    elif page == "ğŸ“‹ ç»¼åˆæŠ¥å‘Š":
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ GA4æ•°æ®æ–‡ä»¶")
        else:
            show_comprehensive_report_page()
        
    elif page == "âš™ï¸ ç³»ç»Ÿè®¾ç½®":
        st.header("ç³»ç»Ÿé…ç½®")
        show_system_settings()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(
        "ğŸ’¡ **æç¤º**: è¯·å…ˆä¸Šä¼ GA4 NDJSONæ•°æ®æ–‡ä»¶ï¼Œç„¶åé€‰æ‹©ç›¸åº”çš„åˆ†æåŠŸèƒ½"
    )


def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    if 'raw_data' not in st.session_state:
        st.session_state.raw_data = None
    if 'processed_data' not in st.session_state:
        st.session_state.processed_data = None
    if 'data_summary' not in st.session_state:
        st.session_state.data_summary = None
    if 'validation_report' not in st.session_state:
        st.session_state.validation_report = None
    if 'storage_manager' not in st.session_state:
        st.session_state.storage_manager = DataStorageManager()
    if 'integration_manager' not in st.session_state:
        # åˆå§‹åŒ–ç³»ç»Ÿé›†æˆç®¡ç†å™¨
        config = WorkflowConfig(
            enable_parallel_processing=True,
            max_workers=4,
            memory_limit_gb=8.0,
            timeout_minutes=30,
            enable_caching=True,
            cache_ttl_hours=24,
            enable_monitoring=True,
            auto_cleanup=True
        )
        st.session_state.integration_manager = IntegrationManager(config)
    if 'workflow_results' not in st.session_state:
        st.session_state.workflow_results = None


def show_data_status():
    """æ˜¾ç¤ºæ•°æ®çŠ¶æ€"""
    st.markdown("### ğŸ“Š æ•°æ®çŠ¶æ€")
    
    if st.session_state.data_loaded:
        st.success("âœ… æ•°æ®å·²åŠ è½½")
        if st.session_state.data_summary:
            summary = st.session_state.data_summary
            st.write(f"ğŸ“… **æ—¶é—´èŒƒå›´**: {summary.get('date_range', {}).get('start', 'N/A')} - {summary.get('date_range', {}).get('end', 'N/A')}")
            st.write(f"ğŸ‘¥ **ç”¨æˆ·æ•°**: {summary.get('unique_users', 0):,}")
            st.write(f"ğŸ“ **äº‹ä»¶æ•°**: {summary.get('total_events', 0):,}")
            st.write(f"ğŸ¯ **äº‹ä»¶ç±»å‹**: {len(summary.get('event_types', {}))}")
        
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®", type="secondary"):
            clear_session_data()
            st.rerun()
    else:
        st.info("â³ æš‚æ— æ•°æ®")


def clear_session_data():
    """æ¸…é™¤ä¼šè¯æ•°æ®"""
    st.session_state.data_loaded = False
    st.session_state.raw_data = None
    st.session_state.processed_data = None
    st.session_state.data_summary = None
    st.session_state.validation_report = None
    st.session_state.storage_manager = DataStorageManager()


def get_mime_type(format_type: str) -> str:
    """è·å–MIMEç±»å‹"""
    mime_types = {
        'json': 'application/json',
        'pdf': 'application/pdf',
        'excel': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    }
    return mime_types.get(format_type, 'application/octet-stream')


def show_data_upload_page():
    """æ˜¾ç¤ºæ•°æ®ä¸Šä¼ é¡µé¢"""
    st.header("ğŸ“ GA4æ•°æ®ä¸Šä¼ ä¸å¤„ç†")
    
    # æ–‡ä»¶ä¸Šä¼ è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        - **GA4 NDJSONæ ¼å¼**: ä»Google Analytics 4å¯¼å‡ºçš„NDJSONæ–‡ä»¶
        - **æ–‡ä»¶å¤§å°é™åˆ¶**: æœ€å¤§ {max_size}MB
        
        ### æ•°æ®è¦æ±‚
        - æ–‡ä»¶å¿…é¡»åŒ…å«å®Œæ•´çš„äº‹ä»¶æ•°æ®ç»“æ„
        - æ”¯æŒçš„äº‹ä»¶ç±»å‹: page_view, sign_up, login, purchase, searchç­‰
        - å¿…éœ€å­—æ®µ: event_date, event_timestamp, event_name, user_pseudo_idç­‰
        
        ### å¤„ç†æµç¨‹
        1. ä¸Šä¼ æ–‡ä»¶å¹¶éªŒè¯æ ¼å¼
        2. è§£æäº‹ä»¶æ•°æ®å’Œç”¨æˆ·ä¿¡æ¯
        3. æ•°æ®è´¨é‡æ£€æŸ¥å’Œæ¸…æ´—
        4. ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š
        """.format(max_size=settings.max_file_size_mb))
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("ğŸ“¤ æ–‡ä»¶ä¸Šä¼ ")
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©GA4 NDJSONæ–‡ä»¶",
        type=['ndjson', 'json', 'jsonl'],
        help=f"æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .ndjson, .json, .jsonl (æœ€å¤§{settings.max_file_size_mb}MB)"
    )
    
    if uploaded_file is not None:
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size_mb = uploaded_file.size / (1024 * 1024)
        
        if file_size_mb > settings.max_file_size_mb:
            st.error(f"âŒ æ–‡ä»¶å¤§å° ({file_size_mb:.1f}MB) è¶…è¿‡é™åˆ¶ ({settings.max_file_size_mb}MB)")
            return
        
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        st.info(f"ğŸ“„ **æ–‡ä»¶å**: {uploaded_file.name}")
        st.info(f"ğŸ“ **æ–‡ä»¶å¤§å°**: {file_size_mb:.2f}MB")
        
        # å¤„ç†æŒ‰é’®
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
                process_uploaded_file(uploaded_file)
        
        with col2:
            if st.button("ğŸ” é¢„è§ˆæ–‡ä»¶"):
                preview_file(uploaded_file)
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    if st.session_state.data_loaded:
        show_processing_results()


def preview_file(uploaded_file):
    """é¢„è§ˆä¸Šä¼ çš„æ–‡ä»¶"""
    st.subheader("ğŸ” æ–‡ä»¶é¢„è§ˆ")
    
    try:
        # è¯»å–å‰å‡ è¡Œè¿›è¡Œé¢„è§ˆ
        content = uploaded_file.read().decode('utf-8')
        lines = content.split('\n')[:5]  # åªæ˜¾ç¤ºå‰5è¡Œ
        
        st.write(f"**æ–‡ä»¶æ€»è¡Œæ•°**: ~{len(content.split())}")
        st.write("**å‰5è¡Œå†…å®¹**:")
        
        for i, line in enumerate(lines, 1):
            if line.strip():
                try:
                    # å°è¯•è§£æJSONå¹¶æ ¼å¼åŒ–æ˜¾ç¤º
                    json_data = json.loads(line)
                    st.code(f"ç¬¬{i}è¡Œ: {json.dumps(json_data, indent=2, ensure_ascii=False)[:500]}...")
                except json.JSONDecodeError:
                    st.code(f"ç¬¬{i}è¡Œ: {line[:500]}...")
        
        # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        uploaded_file.seek(0)
        
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶é¢„è§ˆå¤±è´¥: {str(e)}")


def process_uploaded_file(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    progress_container = st.container()
    
    with progress_container:
        st.subheader("âš™ï¸ æ•°æ®å¤„ç†è¿›åº¦")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # æ­¥éª¤1: ä¿å­˜æ–‡ä»¶
            status_text.text("ğŸ“ æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
            progress_bar.progress(10)
            
            # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
            upload_dir = Path("data/uploads")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = upload_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # æ­¥éª¤2: è§£ææ•°æ®
            status_text.text("ğŸ” æ­£åœ¨è§£æGA4æ•°æ®...")
            progress_bar.progress(30)
            
            parser = GA4DataParser()
            raw_data = parser.parse_ndjson(str(file_path))
            
            # æ­¥éª¤3: æ•°æ®éªŒè¯
            status_text.text("âœ… æ­£åœ¨éªŒè¯æ•°æ®è´¨é‡...")
            progress_bar.progress(50)
            
            validator = DataValidator()
            validation_report = validator.validate_dataframe(raw_data)
            
            # æ­¥éª¤4: æ•°æ®å¤„ç†
            status_text.text("âš™ï¸ æ­£åœ¨å¤„ç†å’Œæ¸…æ´—æ•°æ®...")
            progress_bar.progress(70)
            
            # æå–äº‹ä»¶æ•°æ®
            events_data = parser.extract_events(raw_data)
            user_data = parser.extract_user_properties(raw_data)
            session_data = parser.extract_sessions(raw_data)
            
            # æ­¥éª¤5: å­˜å‚¨æ•°æ®
            status_text.text("ğŸ’¾ æ­£åœ¨å­˜å‚¨å¤„ç†ç»“æœ...")
            progress_bar.progress(90)
            
            # å­˜å‚¨åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.raw_data = raw_data
            st.session_state.processed_data = {
                'events': events_data,
                'users': user_data,
                'sessions': session_data
            }
            
            # å­˜å‚¨åˆ°æ•°æ®ç®¡ç†å™¨
            storage_manager = st.session_state.storage_manager
            storage_manager.store_events(raw_data)
            storage_manager.store_users(user_data)
            storage_manager.store_sessions(session_data)
            
            # ç”Ÿæˆæ•°æ®æ‘˜è¦
            data_summary = parser.validate_data_quality(raw_data)
            st.session_state.data_summary = data_summary
            st.session_state.validation_report = validation_report
            
            # å®Œæˆ
            status_text.text("âœ… æ•°æ®å¤„ç†å®Œæˆ!")
            progress_bar.progress(100)
            
            st.session_state.data_loaded = True
            
            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
            st.success("ğŸ‰ æ•°æ®å¤„ç†æˆåŠŸå®Œæˆ!")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if file_path.exists():
                file_path.unlink()
            
            time.sleep(1)
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
            progress_bar.progress(0)
            status_text.text("âŒ å¤„ç†å¤±è´¥")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'file_path' in locals() and file_path.exists():
                file_path.unlink()


def show_processing_results():
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    st.markdown("---")
    st.subheader("ğŸ“Š æ•°æ®å¤„ç†ç»“æœ")
    
    if st.session_state.data_summary:
        summary = st.session_state.data_summary
        
        # åŸºç¡€ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "æ€»äº‹ä»¶æ•°",
                f"{summary.get('total_events', 0):,}",
                help="æ•°æ®é›†ä¸­çš„æ€»äº‹ä»¶æ•°é‡"
            )
        
        with col2:
            st.metric(
                "ç‹¬ç«‹ç”¨æˆ·æ•°",
                f"{summary.get('unique_users', 0):,}",
                help="æ•°æ®é›†ä¸­çš„ç‹¬ç«‹ç”¨æˆ·æ•°é‡"
            )
        
        with col3:
            date_range = summary.get('date_range', {})
            days = (pd.to_datetime(date_range.get('end', '')) - pd.to_datetime(date_range.get('start', ''))).days
            st.metric(
                "æ•°æ®å¤©æ•°",
                f"{days}å¤©",
                help="æ•°æ®è¦†ç›–çš„æ—¶é—´èŒƒå›´"
            )
        
        with col4:
            st.metric(
                "äº‹ä»¶ç±»å‹æ•°",
                len(summary.get('event_types', {})),
                help="æ•°æ®ä¸­åŒ…å«çš„ä¸åŒäº‹ä»¶ç±»å‹æ•°é‡"
            )
        
        # è¯¦ç»†ä¿¡æ¯
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“… æ—¶é—´èŒƒå›´**")
            date_range = summary.get('date_range', {})
            st.write(f"- å¼€å§‹æ—¶é—´: {date_range.get('start', 'N/A')}")
            st.write(f"- ç»“æŸæ—¶é—´: {date_range.get('end', 'N/A')}")
            
            st.write("**ğŸ¯ äº‹ä»¶ç±»å‹åˆ†å¸ƒ**")
            event_types = summary.get('event_types', {})
            for event_type, count in list(event_types.items())[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                st.write(f"- {event_type}: {count:,}")
            if len(event_types) > 10:
                st.write(f"- ... è¿˜æœ‰ {len(event_types) - 10} ç§äº‹ä»¶ç±»å‹")
        
        with col2:
            st.write("**ğŸ“± å¹³å°åˆ†å¸ƒ**")
            platforms = summary.get('platforms', {})
            for platform, count in platforms.items():
                st.write(f"- {platform}: {count:,}")
            
            # æ•°æ®è´¨é‡é—®é¢˜
            if summary.get('data_issues'):
                st.write("**âš ï¸ æ•°æ®è´¨é‡é—®é¢˜**")
                for issue in summary.get('data_issues', []):
                    st.warning(f"- {issue}")
    
    # éªŒè¯æŠ¥å‘Š
    if st.session_state.validation_report:
        with st.expander("ğŸ” è¯¦ç»†éªŒè¯æŠ¥å‘Š", expanded=False):
            validation_report = st.session_state.validation_report
            
            if validation_report.get('validation_passed'):
                st.success("âœ… æ•°æ®éªŒè¯é€šè¿‡")
            else:
                st.error("âŒ æ•°æ®éªŒè¯å‘ç°é—®é¢˜")
            
            # é”™è¯¯ä¿¡æ¯
            if validation_report.get('errors'):
                st.write("**é”™è¯¯ä¿¡æ¯:**")
                for error in validation_report['errors']:
                    st.error(f"- {error}")
            
            # è­¦å‘Šä¿¡æ¯
            if validation_report.get('warnings'):
                st.write("**è­¦å‘Šä¿¡æ¯:**")
                for warning in validation_report['warnings']:
                    st.warning(f"- {warning}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = validation_report.get('statistics', {})
            if stats:
                st.write("**ç»Ÿè®¡ä¿¡æ¯:**")
                st.json(stats)


def show_system_settings():
    """æ˜¾ç¤ºç³»ç»Ÿè®¾ç½®é¡µé¢"""
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®ä¸é…ç½®")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”§ ç³»ç»Ÿé…ç½®", "ğŸ“Š åˆ†æå‚æ•°", "ğŸ“¥ å¯¼å‡ºè®¾ç½®", "ğŸ”„ é…ç½®ç®¡ç†"])
    
    with tab1:
        show_system_config_tab()
    
    with tab2:
        show_analysis_config_tab()
    
    with tab3:
        show_export_config_tab()
    
    with tab4:
        show_config_management_tab()


def show_system_config_tab():
    """æ˜¾ç¤ºç³»ç»Ÿé…ç½®æ ‡ç­¾é¡µ"""
    st.subheader("ğŸ”§ ç³»ç»Ÿé…ç½®")
    
    # è·å–å½“å‰é…ç½®
    system_config = config_manager.get_system_config()
    
    # APIé…ç½®
    st.write("### ğŸ”‘ APIé…ç½®")
    col1, col2 = st.columns(2)
    
    with col1:
        current_api_key = system_config.get('api_settings', {}).get('google_api_key', '')
        new_api_key = st.text_input(
            "Google APIå¯†é’¥",
            value=current_api_key[:20] + "..." if len(current_api_key) > 20 else current_api_key,
            type="password",
            help="ç”¨äºè®¿é—®Google Gemini APIçš„å¯†é’¥"
        )
        
        llm_model = st.selectbox(
            "LLMæ¨¡å‹",
            options=["gemini-2.5-pro", "gemini-1.5-pro", "gemini-1.5-flash"],
            index=0 if system_config.get('api_settings', {}).get('llm_model') == "gemini-2.5-pro" else 0
        )
    
    with col2:
        llm_temperature = st.slider(
            "æ¨¡å‹æ¸©åº¦",
            min_value=0.0,
            max_value=2.0,
            value=system_config.get('api_settings', {}).get('llm_temperature', 0.1),
            step=0.1,
            help="æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§"
        )
        
        llm_max_tokens = st.number_input(
            "æœ€å¤§Tokenæ•°",
            min_value=1000,
            max_value=8000,
            value=system_config.get('api_settings', {}).get('llm_max_tokens', 4000),
            step=500
        )
    
    # æ•°æ®å¤„ç†é…ç½®
    st.write("### ğŸ’¾ æ•°æ®å¤„ç†é…ç½®")
    col1, col2 = st.columns(2)
    
    with col1:
        max_file_size = st.number_input(
            "æœ€å¤§æ–‡ä»¶å¤§å° (MB)",
            min_value=10,
            max_value=500,
            value=system_config.get('data_processing', {}).get('max_file_size_mb', 100),
            step=10
        )
        
        chunk_size = st.number_input(
            "æ•°æ®å¤„ç†å—å¤§å°",
            min_value=1000,
            max_value=50000,
            value=system_config.get('data_processing', {}).get('chunk_size', 10000),
            step=1000
        )
    
    with col2:
        memory_limit = st.number_input(
            "å†…å­˜é™åˆ¶ (GB)",
            min_value=1,
            max_value=16,
            value=system_config.get('data_processing', {}).get('memory_limit_gb', 4),
            step=1
        )
        
        cleanup_temp = st.checkbox(
            "è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶",
            value=system_config.get('data_processing', {}).get('cleanup_temp_files', True)
        )
    
    # ç•Œé¢é…ç½®
    st.write("### ğŸ¨ ç•Œé¢é…ç½®")
    col1, col2 = st.columns(2)
    
    with col1:
        ui_theme = st.selectbox(
            "ç•Œé¢ä¸»é¢˜",
            options=["light", "dark"],
            index=0 if system_config.get('ui_settings', {}).get('theme') == "light" else 1
        )
        
        language = st.selectbox(
            "ç•Œé¢è¯­è¨€",
            options=["zh-CN", "en-US"],
            index=0 if system_config.get('ui_settings', {}).get('language') == "zh-CN" else 1
        )
    
    with col2:
        page_size = st.number_input(
            "é¡µé¢å¤§å°",
            min_value=10,
            max_value=100,
            value=system_config.get('ui_settings', {}).get('page_size', 20),
            step=5
        )
        
        show_debug = st.checkbox(
            "æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯",
            value=system_config.get('ui_settings', {}).get('show_debug_info', False)
        )
    
    # ä¿å­˜é…ç½®æŒ‰é’®
    if st.button("ğŸ’¾ ä¿å­˜ç³»ç»Ÿé…ç½®", type="primary"):
        try:
            # æ›´æ–°APIé…ç½®
            if new_api_key and new_api_key != current_api_key[:20] + "...":
                config_manager.update_system_config('api_settings', {
                    'google_api_key': new_api_key,
                    'llm_model': llm_model,
                    'llm_temperature': llm_temperature,
                    'llm_max_tokens': llm_max_tokens
                })
            else:
                config_manager.update_system_config('api_settings', {
                    'llm_model': llm_model,
                    'llm_temperature': llm_temperature,
                    'llm_max_tokens': llm_max_tokens
                })
            
            # æ›´æ–°æ•°æ®å¤„ç†é…ç½®
            config_manager.update_system_config('data_processing', {
                'max_file_size_mb': max_file_size,
                'chunk_size': chunk_size,
                'memory_limit_gb': memory_limit,
                'cleanup_temp_files': cleanup_temp
            })
            
            # æ›´æ–°ç•Œé¢é…ç½®
            config_manager.update_system_config('ui_settings', {
                'theme': ui_theme,
                'language': language,
                'page_size': page_size,
                'show_debug_info': show_debug
            })
            
            st.success("âœ… ç³»ç»Ÿé…ç½®ä¿å­˜æˆåŠŸ!")
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {str(e)}")


def show_analysis_config_tab():
    """æ˜¾ç¤ºåˆ†æå‚æ•°é…ç½®æ ‡ç­¾é¡µ"""
    st.subheader("ğŸ“Š åˆ†æå‚æ•°é…ç½®")
    
    # è·å–å½“å‰åˆ†æé…ç½®
    analysis_config = config_manager.get_analysis_config()
    
    # äº‹ä»¶åˆ†æé…ç½®
    with st.expander("ğŸ“ˆ äº‹ä»¶åˆ†æé…ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            event_granularity = st.selectbox(
                "æ—¶é—´ç²’åº¦",
                options=["day", "week", "month"],
                index=["day", "week", "month"].index(analysis_config.get('event_analysis', {}).get('time_granularity', 'day'))
            )
            
            top_events_limit = st.number_input(
                "çƒ­é—¨äº‹ä»¶æ•°é‡é™åˆ¶",
                min_value=5,
                max_value=50,
                value=analysis_config.get('event_analysis', {}).get('top_events_limit', 10),
                step=5
            )
        
        with col2:
            trend_days = st.number_input(
                "è¶‹åŠ¿åˆ†æå¤©æ•°",
                min_value=7,
                max_value=90,
                value=analysis_config.get('event_analysis', {}).get('trend_analysis_days', 30),
                step=7
            )
            
            correlation_threshold = st.slider(
                "å…³è”æ€§é˜ˆå€¼",
                min_value=0.1,
                max_value=1.0,
                value=analysis_config.get('event_analysis', {}).get('correlation_threshold', 0.5),
                step=0.1
            )
    
    # ç•™å­˜åˆ†æé…ç½®
    with st.expander("ğŸ“ˆ ç•™å­˜åˆ†æé…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            retention_periods_str = st.text_input(
                "ç•™å­˜åˆ†æå‘¨æœŸ (å¤©ï¼Œé€—å·åˆ†éš”)",
                value=",".join(map(str, analysis_config.get('retention_analysis', {}).get('retention_periods', [1, 7, 14, 30])))
            )
            
            cohort_type = st.selectbox(
                "é˜Ÿåˆ—ç±»å‹",
                options=["daily", "weekly", "monthly"],
                index=["daily", "weekly", "monthly"].index(analysis_config.get('retention_analysis', {}).get('cohort_type', 'weekly'))
            )
        
        with col2:
            min_cohort_size = st.number_input(
                "æœ€å°é˜Ÿåˆ—å¤§å°",
                min_value=10,
                max_value=1000,
                value=analysis_config.get('retention_analysis', {}).get('min_cohort_size', 100),
                step=10
            )
            
            analysis_window = st.number_input(
                "åˆ†æçª—å£ (å¤©)",
                min_value=30,
                max_value=365,
                value=analysis_config.get('retention_analysis', {}).get('analysis_window_days', 90),
                step=30
            )
    
    # è½¬åŒ–åˆ†æé…ç½®
    with st.expander("ğŸ”„ è½¬åŒ–åˆ†æé…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            conversion_window = st.number_input(
                "è½¬åŒ–çª—å£ (å°æ—¶)",
                min_value=1,
                max_value=168,
                value=analysis_config.get('conversion_analysis', {}).get('conversion_window_hours', 24),
                step=1
            )
            
            min_funnel_users = st.number_input(
                "æœ€å°æ¼æ–—ç”¨æˆ·æ•°",
                min_value=10,
                max_value=500,
                value=analysis_config.get('conversion_analysis', {}).get('min_funnel_users', 50),
                step=10
            )
        
        with col2:
            attribution_model = st.selectbox(
                "å½’å› æ¨¡å‹",
                options=["first_touch", "last_touch", "linear"],
                index=["first_touch", "last_touch", "linear"].index(analysis_config.get('conversion_analysis', {}).get('attribution_model', 'first_touch'))
            )
    
    # ç”¨æˆ·åˆ†ç¾¤é…ç½®
    with st.expander("ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤é…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            clustering_method = st.selectbox(
                "èšç±»ç®—æ³•",
                options=["kmeans", "dbscan"],
                index=["kmeans", "dbscan"].index(analysis_config.get('user_segmentation', {}).get('clustering_method', 'kmeans'))
            )
            
            n_clusters = st.slider(
                "èšç±»æ•°é‡",
                min_value=2,
                max_value=15,
                value=analysis_config.get('user_segmentation', {}).get('n_clusters', 5),
                step=1
            )
        
        with col2:
            min_cluster_size = st.number_input(
                "æœ€å°èšç±»å¤§å°",
                min_value=10,
                max_value=500,
                value=analysis_config.get('user_segmentation', {}).get('min_cluster_size', 100),
                step=10
            )
            
            feature_types = st.multiselect(
                "ç‰¹å¾ç±»å‹",
                options=["behavioral", "demographic", "temporal"],
                default=analysis_config.get('user_segmentation', {}).get('feature_types', ['behavioral', 'demographic'])
            )
    
    # è·¯å¾„åˆ†æé…ç½®
    with st.expander("ğŸ›¤ï¸ è·¯å¾„åˆ†æé…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            min_path_support = st.slider(
                "æœ€å°è·¯å¾„æ”¯æŒåº¦",
                min_value=0.001,
                max_value=0.1,
                value=analysis_config.get('path_analysis', {}).get('min_path_support', 0.01),
                step=0.001,
                format="%.3f"
            )
            
            max_path_length = st.number_input(
                "æœ€å¤§è·¯å¾„é•¿åº¦",
                min_value=3,
                max_value=20,
                value=analysis_config.get('path_analysis', {}).get('max_path_length', 10),
                step=1
            )
        
        with col2:
            session_timeout = st.number_input(
                "ä¼šè¯è¶…æ—¶ (åˆ†é’Ÿ)",
                min_value=5,
                max_value=120,
                value=analysis_config.get('path_analysis', {}).get('session_timeout_minutes', 30),
                step=5
            )
            
            include_bounce = st.checkbox(
                "åŒ…å«è·³å‡ºä¼šè¯",
                value=analysis_config.get('path_analysis', {}).get('include_bounce_sessions', False)
            )
    
    # ä¿å­˜åˆ†æé…ç½®
    if st.button("ğŸ’¾ ä¿å­˜åˆ†æé…ç½®", type="primary"):
        try:
            # è§£æç•™å­˜å‘¨æœŸ
            retention_periods = [int(x.strip()) for x in retention_periods_str.split(',') if x.strip().isdigit()]
            
            # æ›´æ–°äº‹ä»¶åˆ†æé…ç½®
            config_manager.update_analysis_config('event_analysis', {
                'time_granularity': event_granularity,
                'top_events_limit': top_events_limit,
                'trend_analysis_days': trend_days,
                'correlation_threshold': correlation_threshold
            })
            
            # æ›´æ–°ç•™å­˜åˆ†æé…ç½®
            config_manager.update_analysis_config('retention_analysis', {
                'retention_periods': retention_periods,
                'cohort_type': cohort_type,
                'min_cohort_size': min_cohort_size,
                'analysis_window_days': analysis_window
            })
            
            # æ›´æ–°è½¬åŒ–åˆ†æé…ç½®
            config_manager.update_analysis_config('conversion_analysis', {
                'conversion_window_hours': conversion_window,
                'min_funnel_users': min_funnel_users,
                'attribution_model': attribution_model
            })
            
            # æ›´æ–°ç”¨æˆ·åˆ†ç¾¤é…ç½®
            config_manager.update_analysis_config('user_segmentation', {
                'clustering_method': clustering_method,
                'n_clusters': n_clusters,
                'min_cluster_size': min_cluster_size,
                'feature_types': feature_types
            })
            
            # æ›´æ–°è·¯å¾„åˆ†æé…ç½®
            config_manager.update_analysis_config('path_analysis', {
                'min_path_support': min_path_support,
                'max_path_length': max_path_length,
                'session_timeout_minutes': session_timeout,
                'include_bounce_sessions': include_bounce
            })
            
            st.success("âœ… åˆ†æé…ç½®ä¿å­˜æˆåŠŸ!")
            
        except Exception as e:
            st.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {str(e)}")


def show_export_config_tab():
    """æ˜¾ç¤ºå¯¼å‡ºè®¾ç½®æ ‡ç­¾é¡µ"""
    st.subheader("ğŸ“¥ å¯¼å‡ºè®¾ç½®")
    
    # è·å–å½“å‰å¯¼å‡ºé…ç½®
    export_config = config_manager.get_system_config('export_settings')
    
    col1, col2 = st.columns(2)
    
    with col1:
        default_format = st.selectbox(
            "é»˜è®¤å¯¼å‡ºæ ¼å¼",
            options=["json", "pdf", "excel"],
            index=["json", "pdf", "excel"].index(export_config.get('default_format', 'json'))
        )
        
        include_raw_data = st.checkbox(
            "é»˜è®¤åŒ…å«åŸå§‹æ•°æ®",
            value=export_config.get('include_raw_data', False),
            help="åœ¨å¯¼å‡ºæŠ¥å‘Šæ—¶é»˜è®¤åŒ…å«åŸå§‹æ•°æ®"
        )
        
        compress_exports = st.checkbox(
            "å‹ç¼©å¯¼å‡ºæ–‡ä»¶",
            value=export_config.get('compress_exports', True),
            help="å¯¹å¤§å‹å¯¼å‡ºæ–‡ä»¶è¿›è¡Œå‹ç¼©"
        )
    
    with col2:
        export_dir = st.text_input(
            "å¯¼å‡ºç›®å½•",
            value=export_config.get('export_dir', 'reports'),
            help="æŠ¥å‘Šæ–‡ä»¶çš„é»˜è®¤ä¿å­˜ç›®å½•"
        )
        
        filename_template = st.text_input(
            "æ–‡ä»¶åæ¨¡æ¿",
            value=export_config.get('filename_template', 'analysis_report_{timestamp}'),
            help="ä½¿ç”¨{timestamp}ä½œä¸ºæ—¶é—´æˆ³å ä½ç¬¦"
        )
    
    # å¯¼å‡ºæ ¼å¼æ”¯æŒçŠ¶æ€
    st.write("### ğŸ“‹ å¯¼å‡ºæ ¼å¼æ”¯æŒçŠ¶æ€")
    exporter = ReportExporter()
    supported_formats = exporter.get_supported_formats()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write("**JSON**")
        st.success("âœ… æ”¯æŒ" if 'json' in supported_formats else "âŒ ä¸æ”¯æŒ")
    
    with col2:
        st.write("**PDF**")
        st.success("âœ… æ”¯æŒ" if 'pdf' in supported_formats else "âŒ ä¸æ”¯æŒ")
        if 'pdf' not in supported_formats:
            st.info("éœ€è¦å®‰è£… reportlab åº“")
    
    with col3:
        st.write("**Excel**")
        st.success("âœ… æ”¯æŒ" if 'excel' in supported_formats else "âŒ ä¸æ”¯æŒ")
        if 'excel' not in supported_formats:
            st.info("éœ€è¦å®‰è£… openpyxl åº“")
    
    # ä¿å­˜å¯¼å‡ºé…ç½®
    if st.button("ğŸ’¾ ä¿å­˜å¯¼å‡ºé…ç½®", type="primary"):
        try:
            config_manager.update_system_config('export_settings', {
                'default_format': default_format,
                'include_raw_data': include_raw_data,
                'compress_exports': compress_exports,
                'export_dir': export_dir,
                'filename_template': filename_template
            })
            
            st.success("âœ… å¯¼å‡ºé…ç½®ä¿å­˜æˆåŠŸ!")
            
        except Exception as e:
            st.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {str(e)}")


def show_config_management_tab():
    """æ˜¾ç¤ºé…ç½®ç®¡ç†æ ‡ç­¾é¡µ"""
    st.subheader("ğŸ”„ é…ç½®ç®¡ç†")
    
    # é…ç½®çŠ¶æ€æ¦‚è§ˆ
    st.write("### ğŸ“Š é…ç½®çŠ¶æ€æ¦‚è§ˆ")
    config_summary = config_manager.get_config_summary()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**åˆ†æé…ç½®**")
        analysis_summary = config_summary.get('analysis_config', {})
        st.write(f"- äº‹ä»¶åˆ†æ: {'âœ…' if analysis_summary.get('event_analysis_enabled') else 'âŒ'}")
        st.write(f"- ç•™å­˜å‘¨æœŸæ•°: {analysis_summary.get('retention_periods', 0)}")
        st.write(f"- èšç±»æ–¹æ³•: {analysis_summary.get('clustering_method', 'N/A')}")
        st.write(f"- æ¼æ–—æ­¥éª¤: {analysis_summary.get('funnel_steps_configured', 0)}")
    
    with col2:
        st.write("**ç³»ç»Ÿé…ç½®**")
        system_summary = config_summary.get('system_config', {})
        st.write(f"- APIé…ç½®: {'âœ…' if system_summary.get('api_configured') else 'âŒ'}")
        st.write(f"- æ–‡ä»¶å¤§å°é™åˆ¶: {system_summary.get('max_file_size_mb', 0)}MB")
        st.write(f"- é»˜è®¤å¯¼å‡ºæ ¼å¼: {system_summary.get('default_export_format', 'N/A')}")
        st.write(f"- ç•Œé¢ä¸»é¢˜: {system_summary.get('ui_theme', 'N/A')}")
    
    # é…ç½®éªŒè¯
    st.write("### âœ… é…ç½®éªŒè¯")
    if st.button("ğŸ” éªŒè¯é…ç½®", type="secondary"):
        validation_result = config_manager.validate_config()
        
        if validation_result['valid']:
            st.success("âœ… é…ç½®éªŒè¯é€šè¿‡!")
        else:
            st.error("âŒ é…ç½®éªŒè¯å¤±è´¥!")
            
            if validation_result['errors']:
                st.write("**é”™è¯¯:**")
                for error in validation_result['errors']:
                    st.error(f"â€¢ {error}")
        
        if validation_result['warnings']:
            st.write("**è­¦å‘Š:**")
            for warning in validation_result['warnings']:
                st.warning(f"â€¢ {warning}")
    
    # é…ç½®å¯¼å…¥å¯¼å‡º
    st.write("### ğŸ“ é…ç½®å¯¼å…¥å¯¼å‡º")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**å¯¼å‡ºé…ç½®**")
        if st.button("ğŸ“¤ å¯¼å‡ºé…ç½®æ–‡ä»¶"):
            try:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                export_path = f"config/config_backup_{timestamp}.json"
                
                if config_manager.export_config(export_path):
                    st.success(f"âœ… é…ç½®å¯¼å‡ºæˆåŠŸ: {export_path}")
                    
                    # æä¾›ä¸‹è½½
                    with open(export_path, 'r', encoding='utf-8') as f:
                        config_data = f.read()
                    
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½é…ç½®æ–‡ä»¶",
                        data=config_data,
                        file_name=f"config_backup_{timestamp}.json",
                        mime="application/json"
                    )
                else:
                    st.error("âŒ é…ç½®å¯¼å‡ºå¤±è´¥")
                    
            except Exception as e:
                st.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹å‡ºé”™: {str(e)}")
    
    with col2:
        st.write("**å¯¼å…¥é…ç½®**")
        uploaded_config = st.file_uploader(
            "é€‰æ‹©é…ç½®æ–‡ä»¶",
            type=['json'],
            help="ä¸Šä¼ ä¹‹å‰å¯¼å‡ºçš„é…ç½®æ–‡ä»¶"
        )
        
        if uploaded_config is not None:
            if st.button("ğŸ“¥ å¯¼å…¥é…ç½®", type="primary"):
                try:
                    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                    import tempfile
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_file:
                        tmp_file.write(uploaded_config.read().decode('utf-8'))
                        tmp_path = tmp_file.name
                    
                    if config_manager.import_config(tmp_path):
                        st.success("âœ… é…ç½®å¯¼å…¥æˆåŠŸ!")
                        st.info("è¯·åˆ·æ–°é¡µé¢ä»¥åº”ç”¨æ–°é…ç½®")
                    else:
                        st.error("âŒ é…ç½®å¯¼å…¥å¤±è´¥")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(tmp_path)
                    
                except Exception as e:
                    st.error(f"âŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {str(e)}")
    
    # é‡ç½®é…ç½®
    st.write("### ğŸ”„ é‡ç½®é…ç½®")
    st.warning("âš ï¸ é‡ç½®æ“ä½œå°†æ¢å¤é»˜è®¤é…ç½®ï¼Œæ— æ³•æ’¤é”€!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ é‡ç½®åˆ†æé…ç½®", type="secondary"):
            if config_manager.reset_analysis_config():
                st.success("âœ… åˆ†æé…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
                st.rerun()
            else:
                st.error("âŒ é‡ç½®åˆ†æé…ç½®å¤±è´¥")
    
    with col2:
        if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿé…ç½®", type="secondary"):
            if config_manager.reset_system_config():
                st.success("âœ… ç³»ç»Ÿé…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
                st.rerun()
            else:
                st.error("âŒ é‡ç½®ç³»ç»Ÿé…ç½®å¤±è´¥")


def show_event_analysis_page():
    """æ˜¾ç¤ºäº‹ä»¶åˆ†æç»“æœé¡µé¢"""
    st.header("ğŸ“Š äº‹ä»¶åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå¼•æ“å’Œå¯è§†åŒ–ç»„ä»¶
    if 'event_engine' not in st.session_state:
        st.session_state.event_engine = EventAnalysisEngine()
    if 'chart_generator' not in st.session_state:
        st.session_state.chart_generator = ChartGenerator()
    
    # åˆ†ææ§åˆ¶é¢æ¿
    with st.expander("ğŸ”§ åˆ†æé…ç½®", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            date_range = st.date_input(
                "é€‰æ‹©åˆ†ææ—¶é—´èŒƒå›´",
                value=(datetime.now() - timedelta(days=30), datetime.now()),
                help="é€‰æ‹©è¦åˆ†æçš„æ—¶é—´èŒƒå›´"
            )
        
        with col2:
            event_filter = st.multiselect(
                "ç­›é€‰äº‹ä»¶ç±»å‹",
                options=list(st.session_state.data_summary.get('event_types', {}).keys()),
                default=list(st.session_state.data_summary.get('event_types', {}).keys())[:5],
                help="é€‰æ‹©è¦åˆ†æçš„äº‹ä»¶ç±»å‹"
            )
        
        with col3:
            analysis_granularity = st.selectbox(
                "åˆ†æç²’åº¦",
                options=["æ—¥", "å‘¨", "æœˆ"],
                index=0,
                help="é€‰æ‹©æ—¶é—´åˆ†æçš„ç²’åº¦"
            )
    
    # æ‰§è¡Œåˆ†ææŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹äº‹ä»¶åˆ†æ", type="primary"):
        with st.spinner("æ­£åœ¨è¿›è¡Œäº‹ä»¶åˆ†æ..."):
            try:
                # è·å–æ•°æ®
                raw_data = st.session_state.raw_data
                
                # åº”ç”¨ç­›é€‰æ¡ä»¶
                if event_filter:
                    filtered_data = raw_data[raw_data['event_name'].isin(event_filter)]
                else:
                    filtered_data = raw_data
                
                # æ‰§è¡Œåˆ†æ
                engine = st.session_state.event_engine
                
                # äº‹ä»¶é¢‘æ¬¡åˆ†æ
                frequency_results = engine.analyze_event_frequency(filtered_data)
                
                # äº‹ä»¶è¶‹åŠ¿åˆ†æ
                trend_results = engine.analyze_event_trends(filtered_data, granularity=analysis_granularity)
                
                # å­˜å‚¨åˆ†æç»“æœ
                st.session_state.event_analysis_results = {
                    'frequency': frequency_results,
                    'trends': trend_results,
                    'filtered_data': filtered_data
                }
                
                st.success("âœ… äº‹ä»¶åˆ†æå®Œæˆ!")
                
            except Exception as e:
                st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if 'event_analysis_results' in st.session_state:
        results = st.session_state.event_analysis_results
        chart_gen = st.session_state.chart_generator
        
        st.markdown("---")
        st.subheader("ğŸ“ˆ åˆ†æç»“æœ")
        
        # å…³é”®æŒ‡æ ‡æ¦‚è§ˆ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_events = len(results['filtered_data'])
            st.metric("æ€»äº‹ä»¶æ•°", f"{total_events:,}")
        
        with col2:
            unique_users = results['filtered_data']['user_pseudo_id'].nunique()
            st.metric("æ´»è·ƒç”¨æˆ·æ•°", f"{unique_users:,}")
        
        with col3:
            avg_events_per_user = total_events / unique_users if unique_users > 0 else 0
            st.metric("äººå‡äº‹ä»¶æ•°", f"{avg_events_per_user:.1f}")
        
        with col4:
            event_types = results['filtered_data']['event_name'].nunique()
            st.metric("äº‹ä»¶ç±»å‹æ•°", f"{event_types}")
        
        # äº‹ä»¶æ—¶é—´çº¿å›¾è¡¨
        st.subheader("ğŸ“Š äº‹ä»¶æ—¶é—´çº¿")
        try:
            timeline_chart = chart_gen.create_event_timeline(results['filtered_data'])
            st.plotly_chart(timeline_chart, use_container_width=True)
        except Exception as e:
            st.error(f"æ—¶é—´çº¿å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # äº‹ä»¶é¢‘æ¬¡åˆ†å¸ƒ
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ äº‹ä»¶é¢‘æ¬¡åˆ†å¸ƒ")
            event_counts = results['filtered_data']['event_name'].value_counts()
            st.bar_chart(event_counts)
        
        with col2:
            st.subheader("ğŸ‘¥ ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ")
            user_activity = results['filtered_data'].groupby('user_pseudo_id').size()
            st.histogram(user_activity, bins=20)
        
        # è¯¦ç»†æ•°æ®è¡¨
        with st.expander("ğŸ“‹ è¯¦ç»†æ•°æ®", expanded=False):
            st.dataframe(
                results['filtered_data'][['event_date', 'event_name', 'user_pseudo_id', 'platform']].head(1000),
                use_container_width=True
            )


def show_retention_analysis_page():
    """æ˜¾ç¤ºç•™å­˜åˆ†æç»“æœé¡µé¢"""
    st.header("ğŸ“ˆ ç”¨æˆ·ç•™å­˜åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå¼•æ“
    if 'retention_engine' not in st.session_state:
        st.session_state.retention_engine = RetentionAnalysisEngine()
    if 'chart_generator' not in st.session_state:
        st.session_state.chart_generator = ChartGenerator()
    
    # åˆ†æé…ç½®
    with st.expander("ğŸ”§ ç•™å­˜åˆ†æé…ç½®", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            retention_type = st.selectbox(
                "ç•™å­˜ç±»å‹",
                options=["æ—¥ç•™å­˜", "å‘¨ç•™å­˜", "æœˆç•™å­˜"],
                index=0
            )
        
        with col2:
            cohort_period = st.selectbox(
                "é˜Ÿåˆ—å‘¨æœŸ",
                options=["æ—¥", "å‘¨", "æœˆ"],
                index=1
            )
        
        with col3:
            analysis_periods = st.slider(
                "åˆ†æå‘¨æœŸæ•°",
                min_value=7,
                max_value=30,
                value=14,
                help="åˆ†æå¤šå°‘ä¸ªå‘¨æœŸçš„ç•™å­˜æƒ…å†µ"
            )
    
    # æ‰§è¡Œç•™å­˜åˆ†æ
    if st.button("ğŸš€ å¼€å§‹ç•™å­˜åˆ†æ", type="primary"):
        with st.spinner("æ­£åœ¨è¿›è¡Œç•™å­˜åˆ†æ..."):
            try:
                raw_data = st.session_state.raw_data
                engine = st.session_state.retention_engine
                
                # æ‰§è¡Œç•™å­˜åˆ†æ
                retention_results = engine.analyze_user_retention(
                    raw_data, 
                    retention_type=retention_type.replace("ç•™å­˜", ""),
                    periods=analysis_periods
                )
                
                # æ„å»ºé˜Ÿåˆ—æ•°æ®
                cohort_data = engine.build_cohort_table(raw_data, period_type=cohort_period)
                
                st.session_state.retention_results = {
                    'retention_data': retention_results,
                    'cohort_data': cohort_data
                }
                
                st.success("âœ… ç•™å­˜åˆ†æå®Œæˆ!")
                
            except Exception as e:
                st.error(f"âŒ ç•™å­˜åˆ†æå¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºç•™å­˜åˆ†æç»“æœ
    if 'retention_results' in st.session_state:
        results = st.session_state.retention_results
        chart_gen = st.session_state.chart_generator
        
        st.markdown("---")
        st.subheader("ğŸ“Š ç•™å­˜åˆ†æç»“æœ")
        
        # ç•™å­˜çƒ­åŠ›å›¾
        if 'cohort_data' in results and not results['cohort_data'].empty:
            st.subheader("ğŸ”¥ ç•™å­˜çƒ­åŠ›å›¾")
            try:
                heatmap_chart = chart_gen.create_retention_heatmap(results['cohort_data'])
                st.plotly_chart(heatmap_chart, use_container_width=True)
            except Exception as e:
                st.error(f"çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # ç•™å­˜æ›²çº¿
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“ˆ æ•´ä½“ç•™å­˜æ›²çº¿")
            if 'retention_data' in results:
                retention_df = pd.DataFrame(results['retention_data'])
                if not retention_df.empty:
                    st.line_chart(retention_df.set_index('period')['retention_rate'])
        
        with col2:
            st.subheader("ğŸ“Š ç•™å­˜ç‡åˆ†å¸ƒ")
            if 'cohort_data' in results and not results['cohort_data'].empty:
                avg_retention = results['cohort_data'].groupby('period_number')['retention_rate'].mean()
                st.bar_chart(avg_retention)


def show_conversion_analysis_page():
    """æ˜¾ç¤ºè½¬åŒ–åˆ†æç»“æœé¡µé¢"""
    st.header("ğŸ”„ è½¬åŒ–æ¼æ–—åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå¼•æ“
    if 'conversion_engine' not in st.session_state:
        st.session_state.conversion_engine = ConversionAnalysisEngine()
    if 'chart_generator' not in st.session_state:
        st.session_state.chart_generator = ChartGenerator()
    
    # æ¼æ–—é…ç½®
    with st.expander("ğŸ”§ è½¬åŒ–æ¼æ–—é…ç½®", expanded=True):
        st.write("**å®šä¹‰è½¬åŒ–æ¼æ–—æ­¥éª¤**")
        
        available_events = list(st.session_state.data_summary.get('event_types', {}).keys())
        
        funnel_steps = []
        for i in range(5):  # æœ€å¤š5ä¸ªæ­¥éª¤
            col1, col2 = st.columns([3, 1])
            with col1:
                step_event = st.selectbox(
                    f"æ­¥éª¤ {i+1}",
                    options=[""] + available_events,
                    key=f"funnel_step_{i}",
                    help=f"é€‰æ‹©æ¼æ–—ç¬¬{i+1}æ­¥çš„äº‹ä»¶"
                )
            with col2:
                if step_event:
                    funnel_steps.append(step_event)
                    st.success("âœ“")
                else:
                    break
        
        if len(funnel_steps) < 2:
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©2ä¸ªæ­¥éª¤æ¥æ„å»ºè½¬åŒ–æ¼æ–—")
    
    # æ‰§è¡Œè½¬åŒ–åˆ†æ
    if st.button("ğŸš€ å¼€å§‹è½¬åŒ–åˆ†æ", type="primary") and len(funnel_steps) >= 2:
        with st.spinner("æ­£åœ¨è¿›è¡Œè½¬åŒ–åˆ†æ..."):
            try:
                raw_data = st.session_state.raw_data
                engine = st.session_state.conversion_engine
                
                # æ„å»ºè½¬åŒ–æ¼æ–—
                funnel_result = engine.build_conversion_funnel(raw_data, funnel_steps)
                
                # è¯†åˆ«ç“¶é¢ˆ
                bottlenecks = engine.identify_conversion_bottlenecks(funnel_result)
                
                st.session_state.conversion_results = {
                    'funnel_data': funnel_result,
                    'bottlenecks': bottlenecks,
                    'funnel_steps': funnel_steps
                }
                
                st.success("âœ… è½¬åŒ–åˆ†æå®Œæˆ!")
                
            except Exception as e:
                st.error(f"âŒ è½¬åŒ–åˆ†æå¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºè½¬åŒ–åˆ†æç»“æœ
    if 'conversion_results' in st.session_state:
        results = st.session_state.conversion_results
        chart_gen = st.session_state.chart_generator
        
        st.markdown("---")
        st.subheader("ğŸ“Š è½¬åŒ–åˆ†æç»“æœ")
        
        # è½¬åŒ–æ¼æ–—å›¾
        if 'funnel_data' in results:
            st.subheader("ğŸ”„ è½¬åŒ–æ¼æ–—")
            try:
                funnel_chart = chart_gen.create_funnel_chart(results['funnel_data'])
                st.plotly_chart(funnel_chart, use_container_width=True)
            except Exception as e:
                st.error(f"æ¼æ–—å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # è½¬åŒ–æŒ‡æ ‡
        col1, col2, col3 = st.columns(3)
        
        if 'funnel_data' in results and not results['funnel_data'].empty:
            funnel_df = results['funnel_data']
            
            with col1:
                overall_conversion = funnel_df.iloc[-1]['user_count'] / funnel_df.iloc[0]['user_count'] * 100
                st.metric("æ•´ä½“è½¬åŒ–ç‡", f"{overall_conversion:.1f}%")
            
            with col2:
                total_users = funnel_df.iloc[0]['user_count']
                st.metric("æ¼æ–—å…¥å£ç”¨æˆ·", f"{total_users:,}")
            
            with col3:
                converted_users = funnel_df.iloc[-1]['user_count']
                st.metric("æœ€ç»ˆè½¬åŒ–ç”¨æˆ·", f"{converted_users:,}")
        
        # ç“¶é¢ˆåˆ†æ
        if 'bottlenecks' in results:
            st.subheader("ğŸš¨ è½¬åŒ–ç“¶é¢ˆåˆ†æ")
            for bottleneck in results['bottlenecks']:
                st.warning(f"**{bottleneck['step']}**: æµå¤±ç‡ {bottleneck['drop_rate']:.1f}%")


def show_user_segmentation_page():
    """æ˜¾ç¤ºç”¨æˆ·åˆ†ç¾¤ç»“æœé¡µé¢"""
    st.header("ğŸ‘¥ æ™ºèƒ½ç”¨æˆ·åˆ†ç¾¤")
    
    # åˆå§‹åŒ–åˆ†æå¼•æ“
    if 'segmentation_engine' not in st.session_state:
        st.session_state.segmentation_engine = UserSegmentationEngine()
    if 'advanced_visualizer' not in st.session_state:
        st.session_state.advanced_visualizer = AdvancedVisualizer()
    
    # åˆ†ç¾¤é…ç½®
    with st.expander("ğŸ”§ åˆ†ç¾¤é…ç½®", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            clustering_method = st.selectbox(
                "èšç±»ç®—æ³•",
                options=["K-Means", "DBSCAN"],
                index=0
            )
        
        with col2:
            n_clusters = st.slider(
                "åˆ†ç¾¤æ•°é‡",
                min_value=2,
                max_value=10,
                value=4,
                help="K-Meansç®—æ³•çš„åˆ†ç¾¤æ•°é‡"
            )
        
        with col3:
            feature_types = st.multiselect(
                "ç‰¹å¾ç±»å‹",
                options=["è¡Œä¸ºç‰¹å¾", "è®¾å¤‡ç‰¹å¾", "åœ°ç†ç‰¹å¾", "æ—¶é—´ç‰¹å¾"],
                default=["è¡Œä¸ºç‰¹å¾", "è®¾å¤‡ç‰¹å¾"]
            )
    
    # æ‰§è¡Œç”¨æˆ·åˆ†ç¾¤
    if st.button("ğŸš€ å¼€å§‹ç”¨æˆ·åˆ†ç¾¤", type="primary"):
        with st.spinner("æ­£åœ¨è¿›è¡Œç”¨æˆ·åˆ†ç¾¤åˆ†æ..."):
            try:
                raw_data = st.session_state.raw_data
                engine = st.session_state.segmentation_engine
                
                # æå–ç”¨æˆ·ç‰¹å¾
                user_features = engine.extract_user_features(raw_data, feature_types)
                
                # æ‰§è¡Œèšç±»
                segmentation_result = engine.perform_clustering(
                    user_features, 
                    method=clustering_method.lower().replace('-', ''),
                    n_clusters=n_clusters
                )
                
                st.session_state.segmentation_results = {
                    'segments': segmentation_result,
                    'user_features': user_features
                }
                
                st.success("âœ… ç”¨æˆ·åˆ†ç¾¤å®Œæˆ!")
                
            except Exception as e:
                st.error(f"âŒ ç”¨æˆ·åˆ†ç¾¤å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºåˆ†ç¾¤ç»“æœ
    if 'segmentation_results' in st.session_state:
        results = st.session_state.segmentation_results
        visualizer = st.session_state.advanced_visualizer
        
        st.markdown("---")
        st.subheader("ğŸ“Š ç”¨æˆ·åˆ†ç¾¤ç»“æœ")
        
        # åˆ†ç¾¤æ¦‚è§ˆ
        if 'segments' in results:
            segments = results['segments']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("åˆ†ç¾¤æ•°é‡", len(segments))
            with col2:
                total_users = sum(len(seg.get('user_ids', [])) for seg in segments)
                st.metric("æ€»ç”¨æˆ·æ•°", f"{total_users:,}")
            with col3:
                avg_size = total_users / len(segments) if segments else 0
                st.metric("å¹³å‡åˆ†ç¾¤å¤§å°", f"{avg_size:.0f}")
        
        # åˆ†ç¾¤æ•£ç‚¹å›¾
        if 'user_features' in results and results['user_features'] is not None:
            st.subheader("ğŸ¯ ç”¨æˆ·åˆ†ç¾¤å¯è§†åŒ–")
            try:
                # åˆ›å»ºç¤ºä¾‹æ•£ç‚¹å›¾æ•°æ®
                scatter_data = pd.DataFrame({
                    'user_id': [f'user_{i}' for i in range(100)],
                    'segment': [f'åˆ†ç¾¤{i%4+1}' for i in range(100)],
                    'x_feature': np.random.normal(0, 1, 100),
                    'y_feature': np.random.normal(0, 1, 100)
                })
                
                scatter_chart = visualizer.create_user_segmentation_scatter(scatter_data)
                st.plotly_chart(scatter_chart, use_container_width=True)
            except Exception as e:
                st.error(f"æ•£ç‚¹å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # åˆ†ç¾¤ç‰¹å¾é›·è¾¾å›¾
        st.subheader("ğŸ•¸ï¸ åˆ†ç¾¤ç‰¹å¾å¯¹æ¯”")
        try:
            # åˆ›å»ºç¤ºä¾‹é›·è¾¾å›¾æ•°æ®
            radar_data = pd.DataFrame({
                'segment': ['åˆ†ç¾¤1', 'åˆ†ç¾¤1', 'åˆ†ç¾¤1', 'åˆ†ç¾¤2', 'åˆ†ç¾¤2', 'åˆ†ç¾¤2'],
                'feature_name': ['æ´»è·ƒåº¦', 'è½¬åŒ–ç‡', 'ç•™å­˜ç‡', 'æ´»è·ƒåº¦', 'è½¬åŒ–ç‡', 'ç•™å­˜ç‡'],
                'feature_value': [0.8, 0.3, 0.6, 0.5, 0.7, 0.4]
            })
            
            radar_chart = visualizer.create_feature_radar_chart(radar_data)
            st.plotly_chart(radar_chart, use_container_width=True)
        except Exception as e:
            st.error(f"é›·è¾¾å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")


def show_path_analysis_page():
    """æ˜¾ç¤ºè·¯å¾„åˆ†æç»“æœé¡µé¢"""
    st.header("ğŸ›¤ï¸ ç”¨æˆ·è¡Œä¸ºè·¯å¾„åˆ†æ")
    
    # åˆå§‹åŒ–åˆ†æå¼•æ“
    if 'path_engine' not in st.session_state:
        st.session_state.path_engine = PathAnalysisEngine()
    if 'advanced_visualizer' not in st.session_state:
        st.session_state.advanced_visualizer = AdvancedVisualizer()
    
    # è·¯å¾„åˆ†æé…ç½®
    with st.expander("ğŸ”§ è·¯å¾„åˆ†æé…ç½®", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            session_timeout = st.slider(
                "ä¼šè¯è¶…æ—¶(åˆ†é’Ÿ)",
                min_value=10,
                max_value=120,
                value=30,
                help="å®šä¹‰ä¼šè¯çš„è¶…æ—¶æ—¶é—´"
            )
        
        with col2:
            min_path_length = st.slider(
                "æœ€å°è·¯å¾„é•¿åº¦",
                min_value=2,
                max_value=10,
                value=3,
                help="åˆ†æçš„æœ€å°è·¯å¾„é•¿åº¦"
            )
        
        with col3:
            top_paths = st.slider(
                "æ˜¾ç¤ºè·¯å¾„æ•°é‡",
                min_value=5,
                max_value=20,
                value=10,
                help="æ˜¾ç¤ºæœ€å¸¸è§çš„è·¯å¾„æ•°é‡"
            )
    
    # æ‰§è¡Œè·¯å¾„åˆ†æ
    if st.button("ğŸš€ å¼€å§‹è·¯å¾„åˆ†æ", type="primary"):
        with st.spinner("æ­£åœ¨è¿›è¡Œè·¯å¾„åˆ†æ..."):
            try:
                raw_data = st.session_state.raw_data
                engine = st.session_state.path_engine
                
                # é‡æ„ç”¨æˆ·ä¼šè¯
                sessions = engine.reconstruct_user_sessions(
                    raw_data, 
                    session_timeout_minutes=session_timeout
                )
                
                # æŒ–æ˜å¸¸è§è·¯å¾„
                common_paths = engine.mine_common_paths(
                    sessions, 
                    min_length=min_path_length,
                    top_n=top_paths
                )
                
                st.session_state.path_results = {
                    'sessions': sessions,
                    'common_paths': common_paths
                }
                
                st.success("âœ… è·¯å¾„åˆ†æå®Œæˆ!")
                
            except Exception as e:
                st.error(f"âŒ è·¯å¾„åˆ†æå¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºè·¯å¾„åˆ†æç»“æœ
    if 'path_results' in st.session_state:
        results = st.session_state.path_results
        visualizer = st.session_state.advanced_visualizer
        
        st.markdown("---")
        st.subheader("ğŸ“Š è·¯å¾„åˆ†æç»“æœ")
        
        # è·¯å¾„ç»Ÿè®¡
        if 'sessions' in results:
            sessions = results['sessions']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»ä¼šè¯æ•°", f"{len(sessions):,}")
            with col2:
                avg_length = np.mean([len(s.get('path_sequence', [])) for s in sessions])
                st.metric("å¹³å‡è·¯å¾„é•¿åº¦", f"{avg_length:.1f}")
            with col3:
                unique_paths = len(set(tuple(s.get('path_sequence', [])) for s in sessions))
                st.metric("å”¯ä¸€è·¯å¾„æ•°", f"{unique_paths:,}")
        
        # ç”¨æˆ·è¡Œä¸ºæµç¨‹å›¾
        st.subheader("ğŸŒŠ ç”¨æˆ·è¡Œä¸ºæµç¨‹")
        try:
            # åˆ›å»ºç¤ºä¾‹æµç¨‹æ•°æ®
            flow_data = pd.DataFrame({
                'source': ['é¦–é¡µ', 'é¦–é¡µ', 'äº§å“é¡µ', 'äº§å“é¡µ', 'è´­ç‰©è½¦'],
                'target': ['äº§å“é¡µ', 'æœç´¢é¡µ', 'è´­ç‰©è½¦', 'è¯¦æƒ…é¡µ', 'ç»“ç®—é¡µ'],
                'value': [100, 50, 80, 30, 60]
            })
            
            flow_chart = visualizer.create_user_behavior_flow(flow_data)
            st.plotly_chart(flow_chart, use_container_width=True)
        except Exception as e:
            st.error(f"æµç¨‹å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # å¸¸è§è·¯å¾„åˆ—è¡¨
        if 'common_paths' in results:
            st.subheader("ğŸ” æœ€å¸¸è§è·¯å¾„")
            paths_df = pd.DataFrame(results['common_paths'])
            if not paths_df.empty:
                st.dataframe(paths_df, use_container_width=True)


def show_comprehensive_report_page():
    """æ˜¾ç¤ºç»¼åˆåˆ†ææŠ¥å‘Šé¡µé¢"""
    st.header("ğŸ“‹ ç»¼åˆåˆ†ææŠ¥å‘Š")
    
    # æŠ¥å‘Šé…ç½®
    with st.expander("ğŸ“Š æŠ¥å‘Šé…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            report_sections = st.multiselect(
                "é€‰æ‹©æŠ¥å‘Šç« èŠ‚",
                options=["æ•°æ®æ¦‚è§ˆ", "äº‹ä»¶åˆ†æ", "ç•™å­˜åˆ†æ", "è½¬åŒ–åˆ†æ", "ç”¨æˆ·åˆ†ç¾¤", "è·¯å¾„åˆ†æ"],
                default=["æ•°æ®æ¦‚è§ˆ", "äº‹ä»¶åˆ†æ", "ç•™å­˜åˆ†æ"]
            )
        
        with col2:
            export_format = st.selectbox(
                "å¯¼å‡ºæ ¼å¼",
                options=["HTML", "PDF", "JSON"],
                index=0
            )
    
    # ç”ŸæˆæŠ¥å‘Š
    if st.button("ğŸ“ ç”Ÿæˆç»¼åˆæŠ¥å‘Š", type="primary"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆç»¼åˆæŠ¥å‘Š..."):
            try:
                # æ±‡æ€»æ‰€æœ‰åˆ†æç»“æœ
                report_data = {
                    'data_summary': st.session_state.get('data_summary', {}),
                    'event_analysis': st.session_state.get('event_analysis_results', {}),
                    'retention_analysis': st.session_state.get('retention_results', {}),
                    'conversion_analysis': st.session_state.get('conversion_results', {}),
                    'segmentation_analysis': st.session_state.get('segmentation_results', {}),
                    'path_analysis': st.session_state.get('path_results', {})
                }
                
                st.session_state.comprehensive_report = report_data
                st.success("âœ… ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
                
            except Exception as e:
                st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºç»¼åˆæŠ¥å‘Š
    if 'comprehensive_report' in st.session_state:
        report = st.session_state.comprehensive_report
        
        st.markdown("---")
        
        # æ•°æ®æ¦‚è§ˆ
        if "æ•°æ®æ¦‚è§ˆ" in report_sections and 'data_summary' in report:
            st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
            summary = report['data_summary']
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ€»äº‹ä»¶æ•°", f"{summary.get('total_events', 0):,}")
            with col2:
                st.metric("ç‹¬ç«‹ç”¨æˆ·æ•°", f"{summary.get('unique_users', 0):,}")
            with col3:
                st.metric("äº‹ä»¶ç±»å‹æ•°", len(summary.get('event_types', {})))
            with col4:
                date_range = summary.get('date_range', {})
                days = (pd.to_datetime(date_range.get('end', '')) - pd.to_datetime(date_range.get('start', ''))).days
                st.metric("æ•°æ®å¤©æ•°", f"{days}å¤©")
        
        # å…³é”®æ´å¯Ÿ
        st.subheader("ğŸ’¡ å…³é”®æ´å¯Ÿ")
        insights = [
            "ç”¨æˆ·æ´»è·ƒåº¦åœ¨å·¥ä½œæ—¥è¾ƒé«˜ï¼Œå‘¨æœ«æœ‰æ‰€ä¸‹é™",
            "ç§»åŠ¨ç«¯ç”¨æˆ·å æ¯”é€æ¸å¢åŠ ï¼Œéœ€è¦ä¼˜åŒ–ç§»åŠ¨ä½“éªŒ",
            "æ–°ç”¨æˆ·ç•™å­˜ç‡åœ¨ç¬¬7å¤©å‡ºç°æ˜æ˜¾ä¸‹é™",
            "è´­ä¹°è½¬åŒ–æ¼æ–—åœ¨è´­ç‰©è½¦ç¯èŠ‚æµå¤±ç‡æœ€é«˜",
            "é«˜ä»·å€¼ç”¨æˆ·ç¾¤ä½“ä¸»è¦é›†ä¸­åœ¨25-35å²å¹´é¾„æ®µ"
        ]
        
        for insight in insights:
            st.info(f"â€¢ {insight}")
        
        # è¡ŒåŠ¨å»ºè®®
        st.subheader("ğŸ¯ è¡ŒåŠ¨å»ºè®®")
        recommendations = [
            "**ä¼˜åŒ–ç§»åŠ¨ç«¯ä½“éªŒ**: é’ˆå¯¹ç§»åŠ¨ç«¯ç”¨æˆ·å¢é•¿è¶‹åŠ¿ï¼Œä¼˜åŒ–ç§»åŠ¨ç«¯ç•Œé¢å’Œäº¤äº’",
            "**æ”¹å–„æ–°ç”¨æˆ·å¼•å¯¼**: åŠ å¼ºæ–°ç”¨æˆ·ç¬¬ä¸€å‘¨çš„å¼•å¯¼å’Œæ¿€åŠ±æœºåˆ¶",
            "**ä¼˜åŒ–è´­ç‰©è½¦æµç¨‹**: ç®€åŒ–è´­ç‰©è½¦åˆ°ç»“ç®—çš„æµç¨‹ï¼Œå‡å°‘ç”¨æˆ·æµå¤±",
            "**ç²¾å‡†è¥é”€**: é’ˆå¯¹é«˜ä»·å€¼ç”¨æˆ·ç¾¤ä½“åˆ¶å®šä¸ªæ€§åŒ–è¥é”€ç­–ç•¥",
            "**æå‡å‘¨æœ«æ´»è·ƒåº¦**: æ¨å‡ºå‘¨æœ«ä¸“å±æ´»åŠ¨å’Œä¼˜æƒ æ¥æå‡ç”¨æˆ·æ´»è·ƒåº¦"
        ]
        
        for rec in recommendations:
            st.success(rec)
        
        # å¯¼å‡ºæŠ¥å‘Š
        st.markdown("---")
        st.subheader("ğŸ“¥ æŠ¥å‘Šå¯¼å‡º")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            export_format_final = st.selectbox(
                "é€‰æ‹©å¯¼å‡ºæ ¼å¼",
                options=["JSON", "PDF", "Excel"],
                index=0,
                key="final_export_format"
            )
        
        with col2:
            include_raw_data = st.checkbox(
                "åŒ…å«åŸå§‹æ•°æ®",
                value=False,
                help="æ˜¯å¦åœ¨å¯¼å‡ºä¸­åŒ…å«åŸå§‹åˆ†ææ•°æ®"
            )
        
        with col3:
            custom_filename = st.text_input(
                "è‡ªå®šä¹‰æ–‡ä»¶å",
                value="",
                placeholder="ç•™ç©ºä½¿ç”¨é»˜è®¤æ–‡ä»¶å"
            )
        
        if st.button(f"ğŸ“¥ å¯¼å‡º{export_format_final}æŠ¥å‘Š", type="primary"):
            with st.spinner(f"æ­£åœ¨å¯¼å‡º{export_format_final}æ ¼å¼æŠ¥å‘Š..."):
                try:
                    # åˆå§‹åŒ–æŠ¥å‘Šå¯¼å‡ºå™¨
                    exporter = ReportExporter()
                    
                    # å‡†å¤‡æŠ¥å‘Šæ•°æ®
                    export_data = {
                        'metadata': {
                            'generated_at': datetime.now().isoformat(),
                            'report_sections': report_sections,
                            'data_summary': report.get('data_summary', {})
                        },
                        'executive_summary': {
                            'key_metrics': {
                                'total_events': report.get('data_summary', {}).get('total_events', 0),
                                'unique_users': report.get('data_summary', {}).get('unique_users', 0),
                                'event_types': len(report.get('data_summary', {}).get('event_types', {}))
                            },
                            'key_insights': insights,
                            'recommendations': recommendations
                        },
                        'detailed_analysis': {}
                    }
                    
                    # æ·»åŠ é€‰ä¸­çš„åˆ†æç»“æœ
                    if "äº‹ä»¶åˆ†æ" in report_sections and 'event_analysis' in report:
                        export_data['detailed_analysis']['event_analysis'] = report['event_analysis']
                    
                    if "ç•™å­˜åˆ†æ" in report_sections and 'retention_analysis' in report:
                        export_data['detailed_analysis']['retention_analysis'] = report['retention_analysis']
                    
                    if "è½¬åŒ–åˆ†æ" in report_sections and 'conversion_analysis' in report:
                        export_data['detailed_analysis']['conversion_analysis'] = report['conversion_analysis']
                    
                    if "ç”¨æˆ·åˆ†ç¾¤" in report_sections and 'segmentation_analysis' in report:
                        export_data['detailed_analysis']['user_segmentation'] = report['segmentation_analysis']
                    
                    if "è·¯å¾„åˆ†æ" in report_sections and 'path_analysis' in report:
                        export_data['detailed_analysis']['path_analysis'] = report['path_analysis']
                    
                    # å¦‚æœé€‰æ‹©åŒ…å«åŸå§‹æ•°æ®
                    if include_raw_data and st.session_state.get('raw_data') is not None:
                        # åªåŒ…å«æ•°æ®æ‘˜è¦ï¼Œé¿å…æ–‡ä»¶è¿‡å¤§
                        raw_data = st.session_state.raw_data
                        export_data['raw_data_summary'] = {
                            'total_records': len(raw_data),
                            'columns': list(raw_data.columns),
                            'sample_records': raw_data.head(5).to_dict('records')
                        }
                    
                    # ç”Ÿæˆæ–‡ä»¶å
                    if custom_filename:
                        filename = f"{custom_filename}.{export_format_final.lower()}"
                    else:
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"comprehensive_report_{timestamp}.{export_format_final.lower()}"
                    
                    output_path = f"reports/{filename}"
                    
                    # æ‰§è¡Œå¯¼å‡º
                    result = exporter.export_report(export_data, export_format_final.lower(), output_path)
                    
                    if result['status'] == 'success':
                        st.success(f"âœ… æŠ¥å‘Šå¯¼å‡ºæˆåŠŸ!")
                        st.info(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {result['file_path']}")
                        st.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {result['file_size'] / 1024:.1f} KB")
                        
                        # æä¾›ä¸‹è½½é“¾æ¥
                        try:
                            with open(result['file_path'], 'rb') as f:
                                file_data = f.read()
                            
                            st.download_button(
                                label=f"â¬‡ï¸ ä¸‹è½½{export_format_final}æŠ¥å‘Š",
                                data=file_data,
                                file_name=filename,
                                mime=get_mime_type(export_format_final.lower())
                            )
                        except Exception as e:
                            st.warning(f"ä¸‹è½½æŒ‰é’®åˆ›å»ºå¤±è´¥: {str(e)}")
                    else:
                        st.error(f"âŒ æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {result['message']}")
                        
                except Exception as e:
                    st.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹å‡ºé”™: {str(e)}")
    



def show_intelligent_analysis_page():
    """æ˜¾ç¤ºæ™ºèƒ½åˆ†æé¡µé¢"""
    st.header("ğŸš€ æ™ºèƒ½åˆ†æ - ä¸€é”®å®Œæ•´åˆ†æ")
    
    st.markdown("""
    ### åŠŸèƒ½è¯´æ˜
    æ™ºèƒ½åˆ†æåŠŸèƒ½ä½¿ç”¨ç³»ç»Ÿé›†æˆç®¡ç†å™¨ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œå®Œæˆå®Œæ•´çš„GA4æ•°æ®åˆ†æå·¥ä½œæµç¨‹ã€‚
    åŒ…æ‹¬äº‹ä»¶åˆ†æã€ç•™å­˜åˆ†æã€è½¬åŒ–åˆ†æã€ç”¨æˆ·åˆ†ç¾¤å’Œè·¯å¾„åˆ†æç­‰æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ã€‚
    """)
    
    # åˆ†æé…ç½®
    st.subheader("ğŸ“‹ åˆ†æé…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        analysis_types = st.multiselect(
            "é€‰æ‹©åˆ†æç±»å‹",
            options=[
                'event_analysis',
                'retention_analysis', 
                'conversion_analysis',
                'user_segmentation',
                'path_analysis'
            ],
            default=[
                'event_analysis',
                'retention_analysis', 
                'conversion_analysis'
            ],
            format_func=lambda x: {
                'event_analysis': 'ğŸ“Š äº‹ä»¶åˆ†æ',
                'retention_analysis': 'ğŸ“ˆ ç•™å­˜åˆ†æ',
                'conversion_analysis': 'ğŸ”„ è½¬åŒ–åˆ†æ',
                'user_segmentation': 'ğŸ‘¥ ç”¨æˆ·åˆ†ç¾¤',
                'path_analysis': 'ğŸ›¤ï¸ è·¯å¾„åˆ†æ'
            }.get(x, x)
        )
        
        enable_parallel = st.checkbox(
            "å¯ç”¨å¹¶è¡Œå¤„ç†",
            value=True,
            help="å¹¶è¡Œæ‰§è¡Œå¤šä¸ªåˆ†æä»»åŠ¡ä»¥æé«˜æ€§èƒ½"
        )
    
    with col2:
        max_workers = st.slider(
            "æœ€å¤§å¹¶è¡Œä»»åŠ¡æ•°",
            min_value=1,
            max_value=8,
            value=4,
            disabled=not enable_parallel
        )
        
        enable_caching = st.checkbox(
            "å¯ç”¨æ™ºèƒ½ç¼“å­˜",
            value=True,
            help="ç¼“å­˜åˆ†æç»“æœä»¥åŠ é€Ÿåç»­æ‰§è¡Œ"
        )
    
    # æ‰§è¡Œåˆ†æ
    st.subheader("ğŸ¯ æ‰§è¡Œåˆ†æ")
    
    if not analysis_types:
        st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ç§åˆ†æç±»å‹")
        return
    
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ", type="primary"):
            execute_intelligent_analysis(analysis_types, enable_parallel, max_workers, enable_caching)
    
    with col2:
        if st.button("ğŸ“Š æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€"):
            show_system_status()
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.workflow_results:
        show_workflow_results()


def execute_intelligent_analysis(analysis_types, enable_parallel, max_workers, enable_caching):
    """æ‰§è¡Œæ™ºèƒ½åˆ†æ"""
    
    # æ›´æ–°é›†æˆç®¡ç†å™¨é…ç½®
    integration_manager = st.session_state.integration_manager
    integration_manager.config.enable_parallel_processing = enable_parallel
    integration_manager.config.max_workers = max_workers
    integration_manager.config.enable_caching = enable_caching
    
    # åˆ›å»ºè¿›åº¦å®¹å™¨
    progress_container = st.container()
    
    with progress_container:
        st.subheader("âš™ï¸ æ™ºèƒ½åˆ†æè¿›åº¦")
        
        # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        metrics_container = st.empty()
        
        try:
            # å‡†å¤‡ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            upload_dir = Path("data/uploads")
            upload_dir.mkdir(parents=True, exist_ok=True)
            
            # ä»ä¼šè¯çŠ¶æ€è·å–åŸå§‹æ•°æ®å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            if st.session_state.raw_data is not None:
                temp_file_path = upload_dir / f"temp_analysis_{int(time.time())}.ndjson"
                
                # å°†DataFrameè½¬æ¢å›NDJSONæ ¼å¼
                with open(temp_file_path, 'w', encoding='utf-8') as f:
                    for _, row in st.session_state.raw_data.iterrows():
                        # é‡æ„åŸå§‹äº‹ä»¶æ ¼å¼
                        event_data = {
                            'event_date': row.get('event_date', ''),
                            'event_timestamp': row.get('event_timestamp', 0),
                            'event_name': row.get('event_name', ''),
                            'user_pseudo_id': row.get('user_pseudo_id', ''),
                            'user_id': row.get('user_id'),
                            'platform': row.get('platform', 'WEB'),
                            'device': row.get('device', {}),
                            'geo': row.get('geo', {}),
                            'traffic_source': row.get('traffic_source', {}),
                            'event_params': row.get('event_params', []),
                            'user_properties': row.get('user_properties', []),
                            'items': row.get('items', [])
                        }
                        f.write(json.dumps(event_data, ensure_ascii=False) + '\n')
                
                status_text.text("ğŸš€ å¯åŠ¨æ™ºèƒ½åˆ†æå·¥ä½œæµç¨‹...")
                progress_bar.progress(10)
                
                # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
                start_time = time.time()
                
                result = integration_manager.execute_complete_workflow(
                    file_path=str(temp_file_path),
                    analysis_types=analysis_types
                )
                
                end_time = time.time()
                total_time = end_time - start_time
                
                # æ›´æ–°è¿›åº¦
                progress_bar.progress(100)
                status_text.text("âœ… æ™ºèƒ½åˆ†æå®Œæˆ!")
                
                # æ˜¾ç¤ºæ‰§è¡ŒæŒ‡æ ‡
                with metrics_container.container():
                    col1, col2, col3, col4 = st.columns(4)
                    
                    execution_summary = result['execution_summary']
                    
                    with col1:
                        st.metric(
                            "æ€»æ‰§è¡Œæ—¶é—´",
                            f"{total_time:.2f}ç§’",
                            help="å®Œæ•´å·¥ä½œæµç¨‹çš„æ‰§è¡Œæ—¶é—´"
                        )
                    
                    with col2:
                        st.metric(
                            "æˆåŠŸåˆ†æ",
                            execution_summary['successful_analyses'],
                            help="æˆåŠŸå®Œæˆçš„åˆ†æä»»åŠ¡æ•°é‡"
                        )
                    
                    with col3:
                        st.metric(
                            "å¤„ç†æ•°æ®é‡",
                            f"{execution_summary['data_size']:,}",
                            help="å¤„ç†çš„äº‹ä»¶è®°å½•æ•°é‡"
                        )
                    
                    with col4:
                        processing_rate = execution_summary['data_size'] / total_time if total_time > 0 else 0
                        st.metric(
                            "å¤„ç†é€Ÿç‡",
                            f"{processing_rate:.0f}/ç§’",
                            help="æ¯ç§’å¤„ç†çš„è®°å½•æ•°é‡"
                        )
                
                # ä¿å­˜ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                st.session_state.workflow_results = result
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_file_path.exists():
                    temp_file_path.unlink()
                
                st.success("ğŸ‰ æ™ºèƒ½åˆ†ææˆåŠŸå®Œæˆ!")
                st.rerun()
                
            else:
                st.error("âŒ æ— æ³•è·å–åŸå§‹æ•°æ®ï¼Œè¯·é‡æ–°ä¸Šä¼ æ–‡ä»¶")
                
        except Exception as e:
            st.error(f"âŒ æ™ºèƒ½åˆ†æå¤±è´¥: {str(e)}")
            progress_bar.progress(0)
            status_text.text("âŒ åˆ†æå¤±è´¥")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'temp_file_path' in locals() and temp_file_path.exists():
                temp_file_path.unlink()


def show_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€ç›‘æ§")
    
    integration_manager = st.session_state.integration_manager
    
    # è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€
    health = integration_manager.get_system_health()
    
    # æ˜¾ç¤ºæ•´ä½“çŠ¶æ€
    col1, col2, col3 = st.columns(3)
    
    with col1:
        status_color = {
            'healthy': 'normal',
            'warning': 'inverse', 
            'critical': 'off'
        }.get(health['overall_status'], 'normal')
        
        st.metric(
            "ç³»ç»ŸçŠ¶æ€",
            health['overall_status'].upper(),
            delta_color=status_color
        )
    
    with col2:
        st.metric(
            "æ´»è·ƒå·¥ä½œæµç¨‹",
            health['active_workflows']
        )
    
    with col3:
        st.metric(
            "ç¼“å­˜é¡¹æ•°é‡",
            health['cache_size']
        )
    
    # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
    if health.get('current_metrics'):
        st.subheader("âš¡ æ€§èƒ½æŒ‡æ ‡")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            cpu_usage = health['current_metrics'].get('cpu_usage', 0)
            st.metric(
                "CPUä½¿ç”¨ç‡",
                f"{cpu_usage:.1f}%",
                delta=f"{cpu_usage - health.get('average_metrics', {}).get('cpu_usage', cpu_usage):.1f}%"
            )
        
        with col2:
            memory_usage = health['current_metrics'].get('memory_usage', 0)
            st.metric(
                "å†…å­˜ä½¿ç”¨ç‡", 
                f"{memory_usage:.1f}%",
                delta=f"{memory_usage - health.get('average_metrics', {}).get('memory_usage', memory_usage):.1f}%"
            )
        
        with col3:
            memory_available = health['current_metrics'].get('memory_available', 0)
            st.metric(
                "å¯ç”¨å†…å­˜",
                f"{memory_available:.1f}GB"
            )
    
    # æ˜¾ç¤ºå·¥ä½œæµç¨‹å†å²
    workflow_history = integration_manager.get_execution_history()
    if workflow_history:
        st.subheader("ğŸ“ˆ å·¥ä½œæµç¨‹å†å²")
        
        # åˆ›å»ºå†å²æ•°æ®è¡¨æ ¼
        history_data = []
        for record in workflow_history[-10:]:  # æ˜¾ç¤ºæœ€è¿‘10ä¸ª
            history_data.append({
                'å·¥ä½œæµç¨‹ID': record.get('workflow_id', 'N/A')[:20] + '...',
                'çŠ¶æ€': record.get('status', 'unknown'),
                'å¼€å§‹æ—¶é—´': record.get('start_time', 'N/A'),
                'åˆ†æç±»å‹': ', '.join(record.get('analysis_types', [])),
                'æ–‡ä»¶è·¯å¾„': Path(record.get('file_path', '')).name if record.get('file_path') else 'N/A'
            })
        
        if history_data:
            df = pd.DataFrame(history_data)
            st.dataframe(df, use_container_width=True)
    
    # ç³»ç»Ÿæ“ä½œ
    st.subheader("ğŸ”§ ç³»ç»Ÿæ“ä½œ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ§¹ æ¸…ç†ç¼“å­˜"):
            integration_manager._cleanup_cache()
            st.success("âœ… ç¼“å­˜å·²æ¸…ç†")
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç†å†…å­˜"):
            integration_manager._trigger_memory_cleanup()
            st.success("âœ… å†…å­˜å·²æ¸…ç†")
            st.rerun()
    
    with col3:
        if st.button("ğŸ”„ é‡ç½®çŠ¶æ€"):
            integration_manager.reset_execution_state()
            st.success("âœ… æ‰§è¡ŒçŠ¶æ€å·²é‡ç½®")
            st.rerun()


def show_workflow_results():
    """æ˜¾ç¤ºå·¥ä½œæµç¨‹ç»“æœ"""
    st.subheader("ğŸ“‹ åˆ†æç»“æœ")
    
    result = st.session_state.workflow_results
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ç»“æœæ¦‚è§ˆ", "ğŸ” è¯¦ç»†åˆ†æ", "ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨", "ğŸ“¥ å¯¼å‡ºæŠ¥å‘Š"])
    
    with tab1:
        show_results_overview(result)
    
    with tab2:
        show_detailed_analysis(result)
    
    with tab3:
        show_visualizations(result)
    
    with tab4:
        show_export_options(result)


def show_results_overview(result):
    """æ˜¾ç¤ºç»“æœæ¦‚è§ˆ"""
    st.write("### ğŸ“Š æ‰§è¡Œæ¦‚è§ˆ")
    
    execution_summary = result['execution_summary']
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "å·¥ä½œæµç¨‹ID",
            result['workflow_id'][:12] + "...",
            help=f"å®Œæ•´ID: {result['workflow_id']}"
        )
    
    with col2:
        st.metric(
            "æ€»æ‰§è¡Œæ—¶é—´",
            f"{execution_summary['total_execution_time']:.2f}ç§’"
        )
    
    with col3:
        st.metric(
            "æˆåŠŸåˆ†æ",
            f"{execution_summary['successful_analyses']}/{execution_summary['successful_analyses'] + execution_summary['failed_analyses']}"
        )
    
    with col4:
        st.metric(
            "æ•°æ®è§„æ¨¡",
            f"{execution_summary['data_size']:,} æ¡"
        )
    
    # åˆ†æç»“æœçŠ¶æ€
    st.write("### ğŸ“ˆ åˆ†ææ¨¡å—çŠ¶æ€")
    
    analysis_results = result['analysis_results']
    
    for analysis_type, analysis_result in analysis_results.items():
        with st.expander(f"{'âœ…' if analysis_result['status'] == 'completed' else 'âŒ'} {analysis_type.replace('_', ' ').title()}", 
                        expanded=analysis_result['status'] == 'completed'):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**çŠ¶æ€**: {analysis_result['status']}")
                st.write(f"**æ‰§è¡Œæ—¶é—´**: {analysis_result['execution_time']:.2f}ç§’")
                st.write(f"**æ´å¯Ÿæ•°é‡**: {len(analysis_result['insights'])}")
                st.write(f"**å»ºè®®æ•°é‡**: {len(analysis_result['recommendations'])}")
            
            with col2:
                if analysis_result['insights']:
                    st.write("**ä¸»è¦æ´å¯Ÿ**:")
                    for insight in analysis_result['insights'][:3]:
                        st.write(f"â€¢ {insight}")
                    
                    if len(analysis_result['insights']) > 3:
                        st.write(f"... è¿˜æœ‰ {len(analysis_result['insights']) - 3} ä¸ªæ´å¯Ÿ")


def show_detailed_analysis(result):
    """æ˜¾ç¤ºè¯¦ç»†åˆ†æ"""
    st.write("### ğŸ” è¯¦ç»†åˆ†æç»“æœ")
    
    analysis_results = result['analysis_results']
    
    # é€‰æ‹©è¦æŸ¥çœ‹çš„åˆ†æ
    selected_analysis = st.selectbox(
        "é€‰æ‹©åˆ†ææ¨¡å—",
        options=list(analysis_results.keys()),
        format_func=lambda x: x.replace('_', ' ').title()
    )
    
    if selected_analysis:
        analysis_result = analysis_results[selected_analysis]
        
        if analysis_result['status'] == 'completed':
            # æ˜¾ç¤ºæ´å¯Ÿ
            if analysis_result['insights']:
                st.write("#### ğŸ’¡ å…³é”®æ´å¯Ÿ")
                for i, insight in enumerate(analysis_result['insights'], 1):
                    st.write(f"{i}. {insight}")
            
            # æ˜¾ç¤ºå»ºè®®
            if analysis_result['recommendations']:
                st.write("#### ğŸ¯ è¡ŒåŠ¨å»ºè®®")
                for i, recommendation in enumerate(analysis_result['recommendations'], 1):
                    st.write(f"{i}. {recommendation}")
            
            # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
            if 'data_summary' in analysis_result:
                st.write("#### ğŸ“Š æ•°æ®æ‘˜è¦")
                data_summary = analysis_result['data_summary']
                
                summary_data = []
                for key, value in data_summary.items():
                    if isinstance(value, dict):
                        summary_data.append({
                            'å­—æ®µ': key,
                            'ç±»å‹': value.get('type', 'unknown'),
                            'æè¿°': str(value)[:100] + '...' if len(str(value)) > 100 else str(value)
                        })
                
                if summary_data:
                    df = pd.DataFrame(summary_data)
                    st.dataframe(df, use_container_width=True)
        
        else:
            st.error(f"âŒ åˆ†æå¤±è´¥: {analysis_result.get('error_message', 'æœªçŸ¥é”™è¯¯')}")


def show_visualizations(result):
    """æ˜¾ç¤ºå¯è§†åŒ–å›¾è¡¨"""
    st.write("### ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨")
    
    visualizations = result.get('visualizations', {})
    
    if not visualizations:
        st.info("ğŸ“Š æš‚æ— å¯è§†åŒ–å›¾è¡¨æ•°æ®")
        return
    
    # é€‰æ‹©è¦æŸ¥çœ‹çš„å¯è§†åŒ–
    viz_options = []
    for analysis_type, viz_data in visualizations.items():
        if viz_data:
            for viz_name in viz_data.keys():
                viz_options.append(f"{analysis_type} - {viz_name}")
    
    if viz_options:
        selected_viz = st.selectbox("é€‰æ‹©å›¾è¡¨", viz_options)
        
        if selected_viz:
            analysis_type, viz_name = selected_viz.split(' - ', 1)
            viz_data = visualizations[analysis_type][viz_name]
            
            # è¿™é‡Œå¯ä»¥æ ¹æ®å›¾è¡¨ç±»å‹æ˜¾ç¤ºç›¸åº”çš„å¯è§†åŒ–
            st.info(f"ğŸ“Š å›¾è¡¨æ•°æ®: {viz_name}")
            st.json(viz_data)  # ä¸´æ—¶æ˜¾ç¤ºJSONæ•°æ®ï¼Œå®é™…åº”è¯¥æ¸²æŸ“å›¾è¡¨
    else:
        st.info("ğŸ“Š æš‚æ— å¯ç”¨çš„å¯è§†åŒ–å›¾è¡¨")


def show_export_options(result):
    """æ˜¾ç¤ºå¯¼å‡ºé€‰é¡¹"""
    st.write("### ğŸ“¥ å¯¼å‡ºåˆ†ææŠ¥å‘Š")
    
    col1, col2 = st.columns(2)
    
    with col1:
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            options=['json', 'pdf', 'excel'],
            format_func=lambda x: {
                'json': 'JSON æ ¼å¼',
                'pdf': 'PDF æŠ¥å‘Š',
                'excel': 'Excel è¡¨æ ¼'
            }.get(x, x)
        )
        
        include_raw_data = st.checkbox(
            "åŒ…å«åŸå§‹æ•°æ®",
            value=False,
            help="åŒ…å«åŸå§‹æ•°æ®ä¼šå¢åŠ æ–‡ä»¶å¤§å°"
        )
    
    with col2:
        st.write("**å¯¼å‡ºå†…å®¹é¢„è§ˆ**:")
        st.write("â€¢ æ‰§è¡Œæ‘˜è¦")
        st.write("â€¢ åˆ†æç»“æœå’Œæ´å¯Ÿ")
        st.write("â€¢ è¡ŒåŠ¨å»ºè®®")
        st.write("â€¢ ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡")
        if include_raw_data:
            st.write("â€¢ åŸå§‹æ•°æ®")
    
    if st.button("ğŸ“¥ å¯¼å‡ºæŠ¥å‘Š", type="primary"):
        try:
            integration_manager = st.session_state.integration_manager
            workflow_id = result['workflow_id']
            
            # å¯¼å‡ºæŠ¥å‘Š
            file_path = integration_manager.export_workflow_results(
                workflow_id=workflow_id,
                export_format=export_format,
                include_raw_data=include_raw_data
            )
            
            # è¯»å–æ–‡ä»¶å†…å®¹ç”¨äºä¸‹è½½
            with open(file_path, 'rb') as f:
                file_data = f.read()
            
            # æä¾›ä¸‹è½½é“¾æ¥
            st.download_button(
                label=f"â¬‡ï¸ ä¸‹è½½ {export_format.upper()} æŠ¥å‘Š",
                data=file_data,
                file_name=Path(file_path).name,
                mime=get_mime_type(export_format)
            )
            
            st.success(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {Path(file_path).name}")
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()