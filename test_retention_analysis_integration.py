"""
ç•™å­˜åˆ†æå¼•æ“é›†æˆæµ‹è¯•

éªŒè¯RetentionAnalysisEngineçš„åŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from engines.retention_analysis_engine import RetentionAnalysisEngine
from tools.data_storage_manager import DataStorageManager


def create_retention_sample_data():
    """åˆ›å»ºç•™å­˜åˆ†æç¤ºä¾‹æ•°æ®"""
    print("åˆ›å»ºç•™å­˜åˆ†æç¤ºä¾‹æ•°æ®...")
    
    np.random.seed(42)
    events = []
    users = [f'user_{i}' for i in range(100)]
    
    # åˆ›å»º90å¤©çš„æ•°æ®ï¼Œæ¨¡æ‹ŸçœŸå®çš„ç”¨æˆ·ç•™å­˜æ¨¡å¼
    start_date = datetime.now() - timedelta(days=90)
    
    for user_id in users:
        # æ¯ä¸ªç”¨æˆ·çš„é¦–æ¬¡æ´»åŠ¨æ—¶é—´ï¼ˆåˆ†å¸ƒåœ¨å‰30å¤©ï¼‰
        first_activity = start_date + timedelta(days=np.random.randint(0, 30))
        
        # æ¨¡æ‹Ÿç”¨æˆ·ç•™å­˜æ¨¡å¼ï¼š
        # - 20%çš„ç”¨æˆ·æ˜¯é«˜ç•™å­˜ç”¨æˆ·ï¼ˆç•™å­˜ç‡0.7-0.9ï¼‰
        # - 30%çš„ç”¨æˆ·æ˜¯ä¸­ç­‰ç•™å­˜ç”¨æˆ·ï¼ˆç•™å­˜ç‡0.3-0.6ï¼‰
        # - 50%çš„ç”¨æˆ·æ˜¯ä½ç•™å­˜ç”¨æˆ·ï¼ˆç•™å­˜ç‡0.1-0.3ï¼‰
        user_type = np.random.choice(['high', 'medium', 'low'], p=[0.2, 0.3, 0.5])
        
        if user_type == 'high':
            base_retention = np.random.uniform(0.7, 0.9)
            decay_rate = 0.98  # æ…¢è¡°å‡
        elif user_type == 'medium':
            base_retention = np.random.uniform(0.3, 0.6)
            decay_rate = 0.95  # ä¸­ç­‰è¡°å‡
        else:
            base_retention = np.random.uniform(0.1, 0.3)
            decay_rate = 0.90  # å¿«è¡°å‡
            
        current_date = first_activity
        current_retention = base_retention
        day_offset = 0
        
        while current_date <= datetime.now() and day_offset < 60:
            # å†³å®šç”¨æˆ·æ˜¯å¦åœ¨è¿™ä¸€å¤©æ´»è·ƒ
            if np.random.random() < current_retention:
                # ç”¨æˆ·æ´»è·ƒï¼Œç”Ÿæˆ1-8ä¸ªäº‹ä»¶
                daily_events = np.random.randint(1, 9)
                
                for _ in range(daily_events):
                    event_time = current_date + timedelta(
                        hours=np.random.randint(0, 24),
                        minutes=np.random.randint(0, 60)
                    )
                    
                    event = {
                        'user_pseudo_id': user_id,
                        'event_name': np.random.choice([
                            'page_view', 'login', 'purchase', 'add_to_cart', 'search'
                        ], p=[0.4, 0.2, 0.1, 0.2, 0.1]),
                        'event_timestamp': int(event_time.timestamp() * 1000000),
                        'event_datetime': event_time,
                        'event_date': current_date.strftime('%Y%m%d'),
                        'platform': np.random.choice(['web', 'mobile'], p=[0.6, 0.4])
                    }
                    events.append(event)
            
            # ç•™å­˜æ¦‚ç‡éšæ—¶é—´é€’å‡
            current_retention *= decay_rate
            current_date += timedelta(days=1)
            day_offset += 1
            
    events_df = pd.DataFrame(events)
    print(f"åˆ›å»ºäº† {len(events_df)} æ¡äº‹ä»¶æ•°æ®ï¼Œæ¶‰åŠ {events_df['user_pseudo_id'].nunique()} ä¸ªç”¨æˆ·")
    
    # åˆ›å»ºç”¨æˆ·æ•°æ®
    users_data = []
    for user_id in users:
        user_events = events_df[events_df['user_pseudo_id'] == user_id]
        if not user_events.empty:
            user = {
                'user_pseudo_id': user_id,
                'platform': user_events['platform'].iloc[0],
                'device_category': np.random.choice(['desktop', 'mobile', 'tablet']),
                'geo_country': np.random.choice(['US', 'UK', 'CA', 'DE', 'FR']),
                'first_seen': user_events['event_datetime'].min(),
                'last_seen': user_events['event_datetime'].max(),
                'total_events': len(user_events)
            }
            users_data.append(user)
    
    users_df = pd.DataFrame(users_data)
    print(f"åˆ›å»ºäº† {len(users_df)} ä¸ªç”¨æˆ·æ•°æ®")
    
    return events_df, users_df


def test_user_cohort_building(engine, events_df):
    """æµ‹è¯•ç”¨æˆ·é˜Ÿåˆ—æ„å»º"""
    print("\n=== æµ‹è¯•ç”¨æˆ·é˜Ÿåˆ—æ„å»º ===")
    
    try:
        # æµ‹è¯•æœˆåº¦é˜Ÿåˆ—
        monthly_cohorts = engine.build_user_cohorts(
            events_df, 
            cohort_period='monthly',
            min_cohort_size=5
        )
        
        print(f"æœˆåº¦é˜Ÿåˆ—æ•°é‡: {len(monthly_cohorts)}")
        for cohort_period, user_ids in monthly_cohorts.items():
            print(f"  {cohort_period}: {len(user_ids)} ç”¨æˆ·")
            
        # æµ‹è¯•å‘¨åº¦é˜Ÿåˆ—
        weekly_cohorts = engine.build_user_cohorts(
            events_df,
            cohort_period='weekly',
            min_cohort_size=3
        )
        
        print(f"å‘¨åº¦é˜Ÿåˆ—æ•°é‡: {len(weekly_cohorts)}")
        
        # æµ‹è¯•æ—¥åº¦é˜Ÿåˆ—
        daily_cohorts = engine.build_user_cohorts(
            events_df,
            cohort_period='daily',
            min_cohort_size=1
        )
        
        print(f"æ—¥åº¦é˜Ÿåˆ—æ•°é‡: {len(daily_cohorts)}")
        
        print("âœ… ç”¨æˆ·é˜Ÿåˆ—æ„å»ºæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ ç”¨æˆ·é˜Ÿåˆ—æ„å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_monthly_retention_analysis(engine, events_df):
    """æµ‹è¯•æœˆåº¦ç•™å­˜åˆ†æ"""
    print("\n=== æµ‹è¯•æœˆåº¦ç•™å­˜åˆ†æ ===")
    
    try:
        result = engine.analyze_monthly_retention(events_df, max_months=6)
        
        print(f"åˆ†æç±»å‹: {result.analysis_type}")
        print(f"é˜Ÿåˆ—æ•°é‡: {len(result.cohorts)}")
        
        # æ˜¾ç¤ºæ•´ä½“ç•™å­˜ç‡
        print("æ•´ä½“ç•™å­˜ç‡:")
        for period, rate in result.overall_retention_rates.items():
            print(f"  ç¬¬{period}æœˆ: {rate:.3f} ({rate*100:.1f}%)")
            
        # æ˜¾ç¤ºé˜Ÿåˆ—è¯¦æƒ…
        print("\né˜Ÿåˆ—è¯¦æƒ…:")
        for i, cohort in enumerate(result.cohorts[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªé˜Ÿåˆ—
            print(f"  é˜Ÿåˆ— {cohort.cohort_period}:")
            print(f"    é˜Ÿåˆ—å¤§å°: {cohort.cohort_size}")
            print(f"    ç•™å­˜ç‡: {[f'{r:.3f}' for r in cohort.retention_rates[:4]]}")
            
        # æ˜¾ç¤ºæ‘˜è¦ç»Ÿè®¡
        print(f"\næ‘˜è¦ç»Ÿè®¡:")
        stats = result.summary_stats
        print(f"  æ€»é˜Ÿåˆ—æ•°: {stats.get('total_cohorts', 0)}")
        print(f"  æ€»ç”¨æˆ·æ•°: {stats.get('total_users', 0)}")
        print(f"  å¹³å‡é˜Ÿåˆ—å¤§å°: {stats.get('avg_cohort_size', 0):.1f}")
        print(f"  å¹³å‡ç•™å­˜ç‡: {stats.get('avg_retention_rate', 0):.3f}")
        
        print("âœ… æœˆåº¦ç•™å­˜åˆ†ææµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æœˆåº¦ç•™å­˜åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_weekly_retention_analysis(engine, events_df):
    """æµ‹è¯•å‘¨åº¦ç•™å­˜åˆ†æ"""
    print("\n=== æµ‹è¯•å‘¨åº¦ç•™å­˜åˆ†æ ===")
    
    try:
        result = engine.analyze_weekly_retention(events_df, max_weeks=8)
        
        print(f"åˆ†æç±»å‹: {result.analysis_type}")
        print(f"é˜Ÿåˆ—æ•°é‡: {len(result.cohorts)}")
        
        # æ˜¾ç¤ºæ•´ä½“ç•™å­˜ç‡
        print("æ•´ä½“ç•™å­˜ç‡:")
        for period, rate in list(result.overall_retention_rates.items())[:5]:
            print(f"  ç¬¬{period}å‘¨: {rate:.3f} ({rate*100:.1f}%)")
            
        print("âœ… å‘¨åº¦ç•™å­˜åˆ†ææµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ å‘¨åº¦ç•™å­˜åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_daily_retention_analysis(engine, events_df):
    """æµ‹è¯•æ—¥åº¦ç•™å­˜åˆ†æ"""
    print("\n=== æµ‹è¯•æ—¥åº¦ç•™å­˜åˆ†æ ===")
    
    try:
        result = engine.analyze_daily_retention(events_df, max_days=14)
        
        print(f"åˆ†æç±»å‹: {result.analysis_type}")
        print(f"é˜Ÿåˆ—æ•°é‡: {len(result.cohorts)}")
        
        # æ˜¾ç¤ºæ•´ä½“ç•™å­˜ç‡
        print("æ•´ä½“ç•™å­˜ç‡:")
        for period, rate in list(result.overall_retention_rates.items())[:8]:
            print(f"  ç¬¬{period}å¤©: {rate:.3f} ({rate*100:.1f}%)")
            
        print("âœ… æ—¥åº¦ç•™å­˜åˆ†ææµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ—¥åº¦ç•™å­˜åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_user_retention_profiles(engine, events_df, users_df):
    """æµ‹è¯•ç”¨æˆ·ç•™å­˜æ¡£æ¡ˆ"""
    print("\n=== æµ‹è¯•ç”¨æˆ·ç•™å­˜æ¡£æ¡ˆ ===")
    
    try:
        profiles = engine.create_user_retention_profiles(events_df, users_df)
        
        print(f"åˆ›å»ºäº† {len(profiles)} ä¸ªç”¨æˆ·ç•™å­˜æ¡£æ¡ˆ")
        
        # åˆ†ææµå¤±é£é™©åˆ†å¸ƒ
        risk_scores = [profile.churn_risk_score for profile in profiles]
        high_risk_users = sum(1 for score in risk_scores if score > 70)
        medium_risk_users = sum(1 for score in risk_scores if 30 <= score <= 70)
        low_risk_users = sum(1 for score in risk_scores if score < 30)
        
        print(f"æµå¤±é£é™©åˆ†å¸ƒ:")
        print(f"  é«˜é£é™©ç”¨æˆ· (>70): {high_risk_users} ({high_risk_users/len(profiles)*100:.1f}%)")
        print(f"  ä¸­é£é™©ç”¨æˆ· (30-70): {medium_risk_users} ({medium_risk_users/len(profiles)*100:.1f}%)")
        print(f"  ä½é£é™©ç”¨æˆ· (<30): {low_risk_users} ({low_risk_users/len(profiles)*100:.1f}%)")
        
        # æ˜¾ç¤ºå‡ ä¸ªç¤ºä¾‹æ¡£æ¡ˆ
        print(f"\nç¤ºä¾‹ç”¨æˆ·æ¡£æ¡ˆ:")
        for i, profile in enumerate(profiles[:3]):
            print(f"  ç”¨æˆ· {profile.user_id}:")
            print(f"    æ´»è·ƒå¤©æ•°: {profile.total_active_days}")
            print(f"    æµå¤±é£é™©: {profile.churn_risk_score:.1f}")
            print(f"    æ´»åŠ¨é¢‘ç‡: {profile.activity_pattern.get('activity_frequency', 0):.3f}")
            print(f"    æœ€è¿‘è¶‹åŠ¿: {profile.activity_pattern.get('recent_activity_trend', 'N/A')}")
            
        print("âœ… ç”¨æˆ·ç•™å­˜æ¡£æ¡ˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ ç”¨æˆ·ç•™å­˜æ¡£æ¡ˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_retention_insights(engine, events_df):
    """æµ‹è¯•ç•™å­˜åˆ†ææ´å¯Ÿ"""
    print("\n=== æµ‹è¯•ç•™å­˜åˆ†ææ´å¯Ÿ ===")
    
    try:
        # å…ˆè¿›è¡Œç•™å­˜åˆ†æ
        retention_result = engine.analyze_monthly_retention(events_df, max_months=6)
        
        # è·å–æ´å¯Ÿ
        insights = engine.get_retention_insights(retention_result)
        
        print("å…³é”®æŒ‡æ ‡:")
        key_metrics = insights.get('key_metrics', {})
        for metric, value in key_metrics.items():
            print(f"  {metric}: {value:.3f}")
            
        print(f"\nè¶‹åŠ¿åˆ†æ:")
        trends = insights.get('trends', {})
        for trend_name, trend_value in trends.items():
            print(f"  {trend_name}: {trend_value}")
            
        print(f"\næ”¹è¿›å»ºè®®:")
        recommendations = insights.get('recommendations', [])
        for i, rec in enumerate(recommendations[:3], 1):
            print(f"  {i}. {rec}")
            
        print(f"\né£é™©å› ç´ :")
        risk_factors = insights.get('risk_factors', [])
        for i, risk in enumerate(risk_factors[:3], 1):
            print(f"  {i}. {risk}")
            
        print("âœ… ç•™å­˜åˆ†ææ´å¯Ÿæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ ç•™å­˜åˆ†ææ´å¯Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_analysis_summary(engine):
    """æµ‹è¯•åˆ†ææ‘˜è¦"""
    print("\n=== æµ‹è¯•åˆ†ææ‘˜è¦ ===")
    
    try:
        summary = engine.get_analysis_summary()
        
        print("åˆ†ææ‘˜è¦:")
        print(f"  æ€»äº‹ä»¶æ•°: {summary.get('total_events', 'N/A')}")
        print(f"  ç‹¬ç«‹ç”¨æˆ·æ•°: {summary.get('unique_users', 'N/A')}")
        print(f"  æ•°æ®è·¨åº¦: {summary.get('data_span_days', 'N/A')} å¤©")
        print(f"  æ—¥æœŸèŒƒå›´: {summary.get('date_range', {}).get('start', 'N/A')} åˆ° {summary.get('date_range', {}).get('end', 'N/A')}")
        
        print(f"  ä¼°ç®—é˜Ÿåˆ—æ•°:")
        estimated = summary.get('estimated_cohorts', {})
        print(f"    æ—¥åº¦é˜Ÿåˆ—: {estimated.get('daily', 0)}")
        print(f"    å‘¨åº¦é˜Ÿåˆ—: {estimated.get('weekly', 0)}")
        print(f"    æœˆåº¦é˜Ÿåˆ—: {estimated.get('monthly', 0)}")
        
        print("âœ… åˆ†ææ‘˜è¦æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†ææ‘˜è¦æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ç•™å­˜åˆ†æå¼•æ“é›†æˆæµ‹è¯•...")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    events_df, users_df = create_retention_sample_data()
    
    # åˆ›å»ºå­˜å‚¨ç®¡ç†å™¨å¹¶å­˜å‚¨æ•°æ®
    print("\nè®¾ç½®å­˜å‚¨ç®¡ç†å™¨...")
    storage_manager = DataStorageManager()
    storage_manager.store_events(events_df)
    storage_manager.store_users(users_df)
    
    # åˆ›å»ºç•™å­˜åˆ†æå¼•æ“
    print("åˆå§‹åŒ–ç•™å­˜åˆ†æå¼•æ“...")
    engine = RetentionAnalysisEngine(storage_manager)
    
    # è¿è¡Œæµ‹è¯•
    test_results = []
    
    test_results.append(test_user_cohort_building(engine, events_df))
    test_results.append(test_monthly_retention_analysis(engine, events_df))
    test_results.append(test_weekly_retention_analysis(engine, events_df))
    test_results.append(test_daily_retention_analysis(engine, events_df))
    test_results.append(test_user_retention_profiles(engine, events_df, users_df))
    test_results.append(test_retention_insights(engine, events_df))
    test_results.append(test_analysis_summary(engine))
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    passed_tests = sum(test_results)
    total_tests = len(test_results)
    
    print(f"é€šè¿‡æµ‹è¯•: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç•™å­˜åˆ†æå¼•æ“å·¥ä½œæ­£å¸¸ã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        return False


if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)