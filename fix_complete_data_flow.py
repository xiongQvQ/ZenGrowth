#!/usr/bin/env python3
"""
å®Œæ•´ä¿®å¤æ•°æ®æµç¨‹é—®é¢˜
"""

import pandas as pd
from pathlib import Path
from tools.ga4_data_parser import GA4DataParser
from tools.data_storage_manager import DataStorageManager
from system.integration_manager import IntegrationManager, WorkflowConfig

def fix_complete_data_flow():
    """å®Œæ•´ä¿®å¤æ•°æ®æµç¨‹é—®é¢˜"""
    try:
        print("ğŸ”§ å®Œæ•´ä¿®å¤æ•°æ®æµç¨‹é—®é¢˜...")
        
        # 1. ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨
        data_file = Path("data/events_ga4.ndjson")
        if not data_file.exists():
            print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®...")
            import subprocess
            import sys
            subprocess.run([sys.executable, "generate_clean_data.py"], check=True)
        
        print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_file}")
        
        # 2. è§£ææ•°æ®
        parser = GA4DataParser()
        raw_data = parser.parse_ndjson(str(data_file))
        print(f"âœ… è§£æäº† {len(raw_data)} ä¸ªåŸå§‹äº‹ä»¶")
        
        # 3. æå–å’Œåˆå¹¶äº‹ä»¶æ•°æ®ï¼ˆä½¿ç”¨ä¿®å¤åçš„é€»è¾‘ï¼‰
        events_data = parser.extract_events(raw_data)
        user_data = parser.extract_user_properties(raw_data)
        session_data = parser.extract_sessions(raw_data)
        
        # å¤„ç†äº‹ä»¶æ•°æ®
        if isinstance(events_data, dict):
            all_events_list = []
            for event_type, event_df in events_data.items():
                if not event_df.empty:
                    all_events_list.append(event_df)
                    print(f"  æ·»åŠ  {event_type}: {len(event_df)} ä¸ªäº‹ä»¶")
            
            if all_events_list:
                combined_events = pd.concat(all_events_list, ignore_index=True)
                print(f"âœ… åˆå¹¶äº† {len(events_data)} ç§äº‹ä»¶ç±»å‹ï¼Œæ€»è®¡ {len(combined_events)} ä¸ªäº‹ä»¶")
            else:
                combined_events = pd.DataFrame()
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„äº‹ä»¶æ•°æ®")
        else:
            combined_events = events_data
        
        # 4. åˆ›å»ºå­˜å‚¨ç®¡ç†å™¨å¹¶å­˜å‚¨æ•°æ®
        storage_manager = DataStorageManager()
        storage_manager.store_events(combined_events)
        storage_manager.store_users(user_data)
        storage_manager.store_sessions(session_data)
        
        # 5. éªŒè¯å­˜å‚¨
        stored_events = storage_manager.get_data('events')
        if stored_events is None or stored_events.empty:
            print("âŒ æ•°æ®å­˜å‚¨å¤±è´¥")
            return False
        
        print(f"âœ… æ•°æ®å­˜å‚¨æˆåŠŸï¼Œäº‹ä»¶æ•°: {len(stored_events)}")
        
        # 6. æµ‹è¯•åˆ†æå¼•æ“
        print("ğŸ§ª æµ‹è¯•åˆ†æå¼•æ“...")
        from engines.event_analysis_engine import EventAnalysisEngine
        from engines.retention_analysis_engine import RetentionAnalysisEngine
        
        event_engine = EventAnalysisEngine(storage_manager)
        event_result = event_engine.analyze_events(stored_events)
        print(f"âœ… äº‹ä»¶åˆ†æ: {event_result.get('status', 'unknown')}")
        
        retention_engine = RetentionAnalysisEngine(storage_manager)
        retention_result = retention_engine.analyze_retention(stored_events)
        print(f"âœ… ç•™å­˜åˆ†æ: {retention_result.get('status', 'unknown')}")
        
        # 7. æµ‹è¯•é›†æˆç®¡ç†å™¨
        print("ğŸ”— æµ‹è¯•é›†æˆç®¡ç†å™¨...")
        config = WorkflowConfig(
            enable_parallel_processing=False,
            max_workers=2,
            timeout_minutes=5,
            enable_caching=True,
            auto_cleanup=True
        )
        
        integration_manager = IntegrationManager(config)
        
        # ç¡®ä¿é›†æˆç®¡ç†å™¨ä½¿ç”¨ç›¸åŒçš„å­˜å‚¨ç®¡ç†å™¨
        integration_manager.storage_manager = storage_manager
        
        # é‡æ–°åˆå§‹åŒ–åˆ†æå¼•æ“ä»¥ä½¿ç”¨æ­£ç¡®çš„å­˜å‚¨ç®¡ç†å™¨
        from engines.event_analysis_engine import EventAnalysisEngine
        from engines.retention_analysis_engine import RetentionAnalysisEngine
        from engines.conversion_analysis_engine import ConversionAnalysisEngine
        
        integration_manager.event_engine = EventAnalysisEngine(storage_manager)
        integration_manager.retention_engine = RetentionAnalysisEngine(storage_manager)
        integration_manager.conversion_engine = ConversionAnalysisEngine(storage_manager)
        
        # æµ‹è¯•å•ä¸ªåˆ†æ
        print("ğŸ§ª æµ‹è¯•é›†æˆç®¡ç†å™¨åˆ†æ...")
        try:
            single_result = integration_manager._execute_single_analysis('event_analysis')
            print(f"âœ… é›†æˆç®¡ç†å™¨äº‹ä»¶åˆ†æ: {single_result.status}")
        except Exception as e:
            print(f"âš ï¸ é›†æˆç®¡ç†å™¨äº‹ä»¶åˆ†æå¤±è´¥: {e}")
        
        try:
            retention_result = integration_manager._execute_single_analysis('retention_analysis')
            print(f"âœ… é›†æˆç®¡ç†å™¨ç•™å­˜åˆ†æ: {retention_result.status}")
        except Exception as e:
            print(f"âš ï¸ é›†æˆç®¡ç†å™¨ç•™å­˜åˆ†æå¤±è´¥: {e}")
        
        print("\\nğŸ‰ å®Œæ•´æ•°æ®æµç¨‹ä¿®å¤æˆåŠŸï¼")
        print("ç°åœ¨åº”ç”¨åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = fix_complete_data_flow()
    if success:
        print("\\nğŸš€ ç°åœ¨å¯ä»¥å¯åŠ¨åº”ç”¨äº†:")
        print("   streamlit run main.py")
    else:
        print("\\nâŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")